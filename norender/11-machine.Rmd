# Tidymodels og introduktion til maskin læring

```{r,warning=F,comment=F}
library(tidymodels) # metapackage for ML 
library(tidyverse) # metapackage for data manipulation and visulaisation
library(ranger) #install this, random forest
library(palmerpenguins)
library(kernlab)
library(ISLR)
```


## Læringsmålene

* introducerer testing/training koncept
* bruger tidymodel workflow til at lave linær regression (parsnip)
* bruge samme workflow til at lave RF (tune parameter) 
* tage RF og lave en AUC plot til at vurdere resultatet (yardstick)

## Purpose of chapter

Not to be a comprehensive guide to machine learning

The idea is to introduce a new workflow which you can use for modelling.

The workflow is a framework which is easy to expand as you learn new modelling methodotholgies.

It may seem like overkill for linear regression but it works particularly well for machine learning set-ups, where we can cut out a lot of steps (which are done internally by the package)

## Testing and training sets

Introduce what testing and training is, and what the purpose is

## Regression in the tidy model framework

Introduce the tidymodel framework with a very simple linear regression 


#mt cars

```{r}
set.seed(7834)

# Create a split object
mtcars_split <- initial_split(penguins %>%  drop_na(), prop = 0.75)

# Build training data set
mtcars_training <- mtcars_split %>% 
                  training()

# Build testing data set
mtcars_test <- mtcars_split %>% 
              testing()
```


Make a recipe

```{r}
mtcars_recipe <- recipe(body_mass_g ~ ., data = mtcars_training) %>% 
                step_YeoJohnson(all_numeric(), -all_outcomes()) %>% 
                step_normalize(all_numeric(), -all_outcomes()) %>% 
                step_dummy(all_nominal(), - all_outcomes())
```


select a model

```{r}
lm_model <- linear_reg() %>% 
            set_engine('lm') %>% 
            set_mode('regression')
```


<!-- ```{r} -->
<!-- prior_dist <- rstanarm::student_t(df = 1) -->
<!-- ``` -->


<!-- ```{r} -->
<!-- lm_model <-    -->
<!--   linear_reg() %>%  -->
<!--   set_engine("stan",  -->
<!--              prior_intercept = prior_dist,  -->
<!--              prior = prior_dist)  -->
<!-- ``` -->


Make a workflow

```{r}
mtcars_workflow <- workflow() %>% 
                  add_model(lm_model) %>% 
                  add_recipe(mtcars_recipe)
```

Run

```{r}
mtcars_fit <- mtcars_workflow %>% 
             last_fit(split = mtcars_split)
```

How good is the fit?

```{r}
mtcars_fit %>% collect_metrics()
```


```{r}
# Obtain test set predictions data frame
mtcars_results <- mtcars_fit %>% 
                 collect_predictions()
# View results
mtcars_results
```

```{r}
ggplot(data = mtcars_results,
       mapping = aes(x = .pred, y = body_mass_g)) +
  geom_point(color = '#006EA1', alpha = 0.25) +
  geom_abline(intercept = 0, slope = 1, color = 'orange') +
  labs(title = 'Linear Regression Results',
       x = 'Predicted mpg',
       y = 'Actual mpg') + theme_bw()
```



## Classification in the tidy model framework

Try fitting a random forest for classification

Can use the titanic dataset for this - to predict survival 

Don't go into details (and give disclaimer), but to give the framework

Make an AUC curve

### Titanic survival

Let’s start with the famous Titanic dataset. We need to predict if a passenger survived the sinking of the Titanic (1) or not (0). A dataset is provided for training our models (train.csv). Another dataset is provided (test.csv) for which we do not know the answer. We will predict survival for each passenger, submit our answer to Kaggle and see how well we did compared to other folks. The metric for comparison is the percentage of passengers we correctly predict – aka as accuracy.

First things first, let’s load some packages to get us started.


```{r,tidy=FALSE}
library(titanic)
titanic_clean <- titanic_train %>% # we take the titanic dataset
    select(-Cabin) %>% # select the bits we want
    drop_na() # then remove the NAs
```



```{r}
titanic <- titanic_clean
```

```{r}
titanic <- titanic %>% mutate(survived = as_factor(if_else(Survived == 1, "yes", "no"))) %>%   
            mutate(survived = relevel(survived, ref = "yes")) %>% # first event is survived = yes
             mutate(class = case_when(Pclass == 1 ~ "first",
                             Pclass == 2 ~ "second",
                             Pclass == 3 ~ "third"),
                              class = as_factor(class),
                              gender = factor(Sex),
                              port = factor(Embarked),
                              age = Age,
                              fare = Fare,
                              alone = if_else(SibSp + Parch == 0, "yes", "no")) %>%
 select(survived, class, gender, age, alone, port, fare) 

```

### Fit workflow on titanic data

```{r}
set.seed(7834)

# Create a split object
mtcars_split <- initial_split(titanic, prop = 0.75)

# Build training data set
mtcars_training <- mtcars_split %>% 
                  training()

# Build testing data set
mtcars_test <- mtcars_split %>% 
              testing()
```


```{r}
mtcars_recipe <- recipe(survived ~ ., data = mtcars_training) %>% 
                step_YeoJohnson(all_numeric(), -all_outcomes()) %>% 
                step_normalize(all_numeric(), -all_outcomes()) %>% 
                step_dummy(all_nominal(), - all_outcomes())
```


* Let's select a model

Her are two possible classification models, you can just use these interchangeably/pick one. Notice with the first there is an extra parameter. It is this step that has the largest difference according to which model you want to use.

```{r}
my_model_RF <- rand_forest(trees = 100) %>%
  set_engine("ranger") %>%
  set_mode("classification")
```

```{r}
my_model_GLM <- logistic_reg() %>%
  set_engine("glm") %>%
  set_mode("classification")
```

```{r}
my_model_SVM <- svm_rbf() %>%
  set_mode("classification") %>%
  set_engine("kernlab")
```


Beware that I just give the models without going into the details - they are just to show how you can classfy data with tidymodels. I suggest looking into glm and random forest a little more on your own before using it with your own data (but I don't expect you to know details for this course).

Let's run with both models, we can compare them later:

* Make a workflow

```{r}
mtcars_workflow_RF <- workflow() %>% 
                  add_model(my_model_RF) %>% 
                  add_recipe(mtcars_recipe)

mtcars_workflow_GLM <- workflow() %>% 
                  add_model(my_model_GLM) %>% 
                  add_recipe(mtcars_recipe)

mtcars_workflow_SVM <- workflow() %>% 
                  add_model(my_model_SVM) %>% 
                  add_recipe(mtcars_recipe)
```

Run

```{r}
mtcars_fit_RF <- mtcars_workflow_RF %>% 
             last_fit(split = mtcars_split)

mtcars_fit_GLM <- mtcars_workflow_GLM %>% 
             last_fit(split = mtcars_split)

mtcars_fit_SVM <- mtcars_workflow_SVM %>% 
             last_fit(split = mtcars_split)

```

## How good is the fit?

```{r}
mtcars_fit_RF %>% collect_metrics()
mtcars_fit_GLM %>% collect_metrics()
mtcars_fit_SVM %>% collect_metrics()
```


```{r}
# Obtain test set predictions data frame
mtcars_results <- mtcars_fit_RF %>% 
                 collect_predictions()
# View results
mtcars_results
```


```{r}
dagaa.roc = mtcars_results %>%
  yardstick::roc_curve(survived, 
                        .pred_yes) %>% autoplot()

dagaa.roc
#dagaa.roc %>% ggplot(aes(x=1-specificity,y=sensitivity)) + geom_point() + geom_abline(slope=1,intercept = 0,lty=2)
```


## Cross validation

```{r}
#cross_val_tbl <- vfold_cv(train_tbl, v = 10)
```






### Khan data (maybe for workshop)

```{r}
Khan_train <- bind_cols(
  y = factor(Khan$ytrain),
  as_tibble(Khan$xtrain)
)

Khan_test <- bind_cols(
  y = factor(Khan$ytest),
  as_tibble(Khan$xtest)
)
```


```{r}
mtcars_recipe <- recipe(y ~ ., data = Khan_train) %>% 
                step_YeoJohnson(all_numeric(), -all_outcomes()) %>% 
                step_normalize(all_numeric(), -all_outcomes()) %>% 
                step_dummy(all_nominal(), - all_outcomes())
```


```{r}
iris_ranger <- rand_forest(trees = 100) %>%
  set_engine("ranger") %>%
  set_mode("classification")
```

```{r}
mtcars_workflow <- workflow() %>% 
                  add_model(iris_ranger) %>% 
                  add_recipe(mtcars_recipe)
```

```{r}
mtcars_fit <- iris_ranger %>% fit(y ~ ., data=Khan_train)

mtcars_fit %>% augment(Khan_test) %>% conf_mat(truth = y, estimate = .pred_class)
mtcars_fit %>% augment(Khan_train) %>% conf_mat(truth = y, estimate = .pred_class)
```

