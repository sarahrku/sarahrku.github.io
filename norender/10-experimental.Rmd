# Emner fra eksperimental design

```{r,message=FALSE,comment=FALSE,warning=FALSE}
library(tidyverse)
library(broom)
```

## Inledning og læringsmålene

### Læringsmålene

I skal være i stand til at

* Beskrive randomimisation, replication and blocking
* Beskrive Simpson's paradox 
* Beskrive Anscombes quartet
* Tjekke efter batch effects med PCA

### Inledning til chapter

Formålet med dette chapter er - hvordan kan vi anvende de værktøj som vi har lært i kurset til at kigge nærmere på forskellige emner i eksperimental design. Det er slet ikke en grundig introduktion til eksperimental design, men nogle nyttige og også interesseret emner som godt viser vigtigheden af at lave hensigsmæssige visualiseringer. 

Forståelse af hvordan batch effekts påvirker en analyse er særligt vigtigt indenfor biologi, når mange store sekvensering projektor involverer data samlede eller sekvenseret over forskellige batches, sekvensering maskiner eller forskellige library forberelses metoder.  

### Video ressourcer

* Part 1: randomisation, replikation, blocking + confounding
    + Læse notaterne nedenfor

* Part 2: Simpson's paradox 

Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556581563
```{r,echo=FALSE}
library("vembedr")

embed_url("https://vimeo.com/556581563")
```

* Part 3: Anscombe's quartet 

Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556581540
```{r,echo=FALSE}
library("vembedr")

embed_url("https://vimeo.com/556581540")
```

* Part 4: Batch effects and principal component analysis 

Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556581521
```{r,echo=FALSE}
library("vembedr")

embed_url("https://vimeo.com/556581521")
```


## Baserende princip af eksperimental design 

### Randomisation and replication

Man laver et __eksperiment__ for at få svar på et bestemt spørgsmål, eller hypotese. Og man designer eksperimentet ud fra princip som gøre det gyldigt at fortolke resultaterne fra analysen af de resulterende data. For et eksperiment at være gyldigt skal det kunne demonstrere hensigtsmæssige __replikation__ og __randomisation__.

__Randomisation__ 

Resultaterne kan skyldes variabiliten i en faktor som ikke direkte er interessant i eksperimentet. Derfor bruger man randomisation til at få disse forskellige faktorer fordelte over de forskellige treatment grupper. Et eksempel kan være 'double-blinding' i kliniske eksperimenter - både lægen og patienten har ikke kenskab til, hvem der hører til de forskellige grupper, og så kan man undgår forskelsbehandling som kan påvirker resultaterne.

__Replikation__ 

Når man gentage eksperimentet flere gange - for eksempel ved at have flere patienter i hver treatment gruppe Det tillader os til at kunne beregne variabiliteten i de data, som er nødvendige for at konkludere om der er en forskel mellem de grupper. Man kan altså ikke generalisere resultater som er blevet målt på kun én person.


```{r, echo=FALSE,fig.width = 1,fig.height=1,comment=FALSE,warning=FALSE,out.width="100%",fig.cap="randomisation og replikation"}
# Bigger fig.width
library(png)
library(knitr)
include_graphics("plots/randomisation.png")
```


I ovenstående figur er der 6 replikater i hver gruppe "treatment" eller "control". I tilfældet "Good randomisation" er genstande som er taget ved tilfældet fra populationen vel matchet mellem de to grupper, mens i andet tilfældet "Poor randomisatin", kan man se, at farverne af genstandene er vel matchet indenfor samme grupper. Det gøre det derfor umuligt at fortæl, om en eventuelle forskel mellem "treatment" og "control" er i virkeligheden resultatet af farven i stedet for målingerne, at man gerne vil sammenligne.

__Confounding__

Figuren nedenfor illustratorer age som counfounding variable i et eksperiment hvor man prøver at forstå sammenhæng mellem aktivitet niveau og vægtøgning. Der ser umiddelbart ud til at være, at lave aktivitet niveauer (dependent variable) forklarer vægtøgning (indenpendt variable) men man er nødt til at tage ændre variabler ind i betragtning for at sikre, at sammenhængen ikke skyldes noget andet. For eksempel, gruppen med de høj aktivitetsniveau kunne bestå af yngre mennesker end gruppen med de lav aktivitetsniveauet, og deres alder kan påvirker deres vægtøgning (måske på grund af forskelligeheder i stress niveauer, kost osv.).

```{r, echo=FALSE,fig.width = 1,fig.height=1,comment=FALSE,warning=FALSE,out.width="60%"}
# Bigger fig.width
library(png)
library(knitr)
include_graphics("plots/confounding_illus.png")
```


__Blocking__ 

Man kan prøve at kontrollere for ekstra variabler som vi ikke er interesseret i gennem blocking. Man laver "blocking" ved først at identificere gruppe af individuelle som ligner hinanden så meget som muligt. Det kan være for eksempel at tre forskellige forsker var med til at lave et stor eksperiment med mange patienter og forskellige treatment grupper. Vi er interesseret i om der er forskelen mellem de treatment grupper, men ikke om der er en forskel mellem forskernes behandling af patienterne. Derfor vil vi gerne 'block' efter forsker - kontrollere for dem som en batch effect. Man kan også block efter fk. sex, for at sikre at forskellen i treatment grupper skyldes ikke forskelligheder mellem mænd og kvinder. Man laver "blocking" som del af en lineær model efter data er samlet, men det er nyttige at tænke over det fra starten. 

### Eksempel med datasættet `ToothGrowth` 

Et god eksempel på en god eksperimental design er datasættet `ToothGrowth`, som er baserende på marsvin - de fik forskellige kosttilskud og doser og så fik målte deres tænder.   

```{r}
data(ToothGrowth)
ToothGrowth <- as_tibble(ToothGrowth)
ToothGrowth <- ToothGrowth %>% mutate(dose = as.factor(dose))
summary(ToothGrowth)
```

Her kan man se, at for hver grupper (efter `supp` og `dose`) er der 10 marsvin - vi har således replikation over de grupper, og hver `supp` (supplement) har hver af de tre dose. Hvis vi for eksempel ikke var interesseret i `supp` men kun dose, så kan man 'block' efter `supp`for at afbøde forskelligheder i effekten af de to supplements i `supp`.

```{r,fig.width=4.5,fig.height=4}
ToothGrowth %>% dplyr::count(supp,dose) %>% 
  ggplot(aes(x=factor(dose),y=n,fill=factor(dose))) + 
    geom_bar(stat="identity") + 
    ylab("Number of guinea pigs") + 
    xlab("Dosage") +
    facet_grid(~supp) +
    theme_bw()
```

Man må dog passe på, fordi vi vide ikke om, hvordan de marsvin blev tilknyttet til de forskellige grupper. For eksempel, hvis male og female marsvin er ikke tilknyttet ved tilfælde, kan det opstå, at supp "OJ" og dose "0.5" har kun male guinea pigs og supp "OJ" med dose "1.0" har kun female guninea pigs. Så kunne vi ikke fortæl, om forskellen i dose "0.5" vs "1.0" er resultatet af de dose eller kønnet.

## Case studies: Simpson's paradox

(Se også videoressourcer Part 2).

Simpson's paradox opstå når man drager to modsætte konklusioner fra det samme datasæt - på den ene side når man kigger på de data samlede, og på den anden side når man tager nogle grupper i betragtning. Vi kan visualisere Simpson's paradox gennem eksemplet nedenfor - her har vi to variabler `x` og `y` som vi kan avende til at lave et scatter plot, samt nogle forskellige grupper indenfor variablen `group`.

```{r,comment=FALSE,message=FALSE,warning=FALSE}
#library(datasauRus)
simpsons_paradox <- read.table("https://www.dropbox.com/s/ysh3qpc7qv0ceut/simpsons_paradox_groups.txt?dl=1",header=T)
simpsons_paradox <- simpsons_paradox %>% as_tibble(simpsons_paradox)
simpsons_paradox
```

Hvis vi bare ignorere `group` og ser på de data samlet, kan vi se at der er en stærk positiv sammenhæng mellem x og y. Men når vi opdele efter de forskellige grupper, ved at skrive `colour = group`, få vi faktisk en negativ sammenhæng indenfor hver af de grupper. 

```{r,comment=FALSE,message=FALSE,warning=FALSE,fig.width=9,fig.height=4}
p1 <- simpsons_paradox %>% 
  ggplot(aes(x,y)) + 
  geom_point() +
  geom_smooth(method="lm",se=FALSE) +
  theme_classic()

p2 <- simpsons_paradox %>% 
  ggplot(aes(x,y,colour=group)) + 
  geom_point() +
  geom_smooth(method="lm",aes(group=group),colour="black",se=FALSE) +
  theme_classic()

library(gridExtra)
grid.arrange(p1,p2,ncol=2)
```

Simpson's paradoks sker mere ofte end man skulle tror, og derfor er det vigtigt at tænke over hvad for nogen ændre variabler man også er nødt til at tage i betragtning.

### Berkerly admissions

Det meste berømte eksempel af Simpson's Paradox drejer sig om optagelsen til universitetet i Berkely i 1973. Følgende table fra Wikipedia viser statistikker om antallet som ansøgt samt procenttallet som blev optaget overordnet i universitet efter kønnet. 

```{r, echo=FALSE,comment=FALSE,warning=FALSE,out.width="85%",tidy=FALSE}
# Bigger fig.width
library(png)
library(knitr)
include_graphics("plots/admissions.png")
```


Hvis vi lave et barplot af tallet, kan man se, at der er en højere procenttal af mænd end kvinder som blev optaget på universitet (som resulterede i en retsag mod universitet).

```{r,fig.height=2.5,fig.width=5}
admissions_all <- tibble("sex"=c("all","men","woman"),admitted=c("41","44","35"))

admissions_all %>% ggplot(aes(x=sex,y=admitted,fill=sex)) + 
  geom_bar(stat="identity") + 
  theme_minimal() + 
  ylab("Percent admitted") +
  scale_x_discrete(limits = c("woman","men","all")) +
  coord_flip()
```

Da man dog kiggede lidt nærmere på de samme tal, men opdelt efter de forskellige afdelinger i universitet, fik man en anderledes billede af situationen. I følgende table har vi optagelses tallene for mænd og kvinder i hver af de forskellige afdelinger (A til F).

<!-- optagelses statistik efter afdeling -->
```{r}
admissions_separate <- tribble(
  ~department,   ~all,   ~men,  ~women,
  #------------|-------|-------|--------#
  "A",            64,     62,      82,
  "B",            63,     63,      68,
  "C",            35,     37,      34,
  "D",            34,     33,      35,
  "E",            25,     28,      24,
  "F",             6,      6,       7
)
```

Man kan man se, at for de fleste af de afdelinger, er der ikke en signifikant forskel mellem mænd og kvinder, og i nogen tilfælde havde kvinder faktisk en større chance for at blive optaget.

<!-- lave et plot af de data opdelte efter afdeling -->
```{r,fig.height=4,fig.width=4}
admissions_separate %>% 
  pivot_longer(-department,names_to="sex",values_to="admitted") %>%
  ggplot(aes(x=department,y=admitted,fill=sex)) + 
  ylab("Percent admitted") +
  geom_bar(stat="identity",position = "dodge",colour="black") + 
  theme_minimal()
```

Hvad skyldes det her? Det viste sig, at kvinder havde en tendens til, at ansøge indenfor de afdelinger, som var sværeste at komme ind i. For eksempel, kan man se her, at department E har en relativt lav optagelses procent. Den samme afdelinger var dog en af dem, hvor langt flere kvinder ansøgt end mænd. 

<!-- lave et plot af ansøgelse statistik for afdeling E -->
```{r,fig.height=2.5,fig.width=5}
applications_E <- tibble("sex"=c("all","men","woman"),applications=c("584","191","393"))


applications_E %>% ggplot(aes(x=sex,y=applications,fill=sex)) + 
  geom_bar(stat="identity") + 
  theme_minimal() + 
  ylab("Number of applications to dep. E") +
  scale_x_discrete(limits = c("woman","men","all")) +
  coord_flip()
```


## Case studies: Anscombe's quartet

(Se også videoressourcer Part 3).

Anscombes quartet (ser også https://en.wikipedia.org/wiki/Anscombe%27s_quartet) er en meget nyttige og berømt eksempel som stammer fra 1973, og som forklarer vigitigheden af at få lavet en visualisering af datasættet. Vi kan få åbnet de data fra linket nedenfor - man har x værdier og y værdier som kan anvendes til at lave et scatter plot, og der er også `set`, det refererer til fire forskellige datasæt (derfor 'quartet').

```{r}
anscombe <- read.table("https://www.dropbox.com/s/mlt7crdik3eih9a/anscombe_long_format.txt?dl=1",header=T)
anscombe <- as_tibble(anscombe)
anscombe
```

Formålet med de data er, at man gerne vil fitte en lineær regression model for at finde den forventet y afhængig om x (husk `lm(y ~ x)`). Da vi har fire datasæt, kan man således opdele de data efter `set` og benytter rammen `nest` og `map` (se Chapter 7) til at fitte de fire lineær regression modeller. Vi anvender også `tidy` og `glance` for at få summary statistikker fra de fire modeller:

```{r}
my_func <- ~lm(y ~ x, data = .x)

tidy_anscombe_models <- anscombe %>% 
  group_nest(set) %>% 
  mutate(fit = map(data, my_func),
         tidy = map(fit, tidy),
         glance = map(fit, glance))
```

Man kan anvende `unnest` på den output fra `tidy` og kigge på den intercept og den slope af de fire modeller. Man kan se, at de to parametre er næsten identiske for de fire modeller:

```{r}
tidy_anscombe_models %>% unnest("tidy") %>% 
  pivot_wider(id_cols = "set",names_from = "term",values_from="estimate") 
```

Hvad med de andre parametre fra modellen - lad os kigge for eksempel på `r.squared` og `p.value` fra modellerne, som kan findes i output fra `glance`. Her kan vi igen se, at de er næsten identiske.

```{r}
tidy_anscombe_models %>% 
  unnest(cols = c(glance)) %>% 
  select(set, r.squared,p.value)
```

Hvad med korrelation? Også næsten den samme:

```{r}
my_func <- ~cor(.x$x,.x$y)

anscombe %>% 
  group_nest(set) %>% 
  mutate(cor = map(data, my_func)) %>% 
  unnest(cor) %>% 
  select(-data)
```

Kan man så konkludere, at de fire datasæt som underligger de forskellige modeller, er identiske? Vi laver et scatter plot af de fire datasæt (som vi faktisk skulle have gjort i starten af vores analyse).

```{r,fig.width=8,fig.height=8,message=FALSE,comment=FALSE}
anscombe %>% 
  ggplot(aes(x = x, y = y,colour=factor(set))) +
  geom_point() + 
  facet_wrap(~set) +
  geom_smooth(method = "lm", se = FALSE) + 
  theme_minimal()
```

De fire datasæt er meget forskellige. Vi ved, at de har alle samme den samme beste rette linjer, men de data er slet ikke den samme. Den første datasæt ser egnet til en lineær regression analyse men vi kan se i nummer to at der ikke engang er en linæer sammenhæng. Og de andre to har en outlier værdi, som gøre at den bedste rette linje passer ikke særlig god til de data.

## Using PCA to find batch effects

(Se også videoressourcer Part 4).

Man kan også anvende visualisering til at kigge lidt nærmere på eventuelle batch effekter i de data. Det er især vigtige i store eksperimenter, hvor dele af de data var samlet på forskellige tidspunkter, lokationer, eller af forskellige personer. Det er ofte tilfældet i sekvensering-basarede datasæt, at man ser batch effects, og det kan skyldes mange ting, bla.:

* Sekvensering dybelse
* Grupper samples lavet på forskellige tidspunkter af forskellige indivduelle
* Sekvensering maskiner - samples sekvenserne på forskellige maskiner eller 'lanes'. 

Lad os tage udgangspunkt i nogle genekspression sekvensering data lavet i mus.

```{r}
norm.cts <- read.table("https://www.dropbox.com/s/3vhwnsnhzsy35nd/bottomly_count_table_normalised.txt?dl=1")
coldata <- read.table("https://www.dropbox.com/s/el3sm9ncvzbq6xf/bottomly_phenodata.txt?dl=1")
coldata <- as_tibble(coldata)
norm.cts <- as_tibble(norm.cts,rownames="gene")
coldata <- as_tibble(coldata)
```

Jeg begynder ved at vælge kun rækker som har mindst 50 counts, for at undgå gener med lave ekspressionsniveauer. Det næste jeg gør er at transformere de data til log form. Her benytter jeg `map_df` over alle de numeriske kolonner - et strategi er at gemme kolonnen `gene`, fjerne den fra de data, anvende `map_df` for at lave de transformering og så tilføj `gene` som en kolon igen bagefter (OBS: der er mere effektiv måder at gøre det på - for eksempel ved at anvende `map_at`, som I er velkommen til at undersøge).

```{r}
#normalise and filter the data
norm.cts <- norm.cts %>% 
  filter(rowSums(norm.cts %>% select(-gene))>50) 

genes <- norm.cts %>% pull(gene)

norm.cts <- norm.cts %>% 
  select(-gene) %>%
  map_df(~log(.x+1)) %>% 
  mutate(gene=genes,.before=1)

norm.cts
```

Så der er omkring 10,000 genes i rækkerne og så 21 forskellige samples som spreder sig over kolonnerne. Vi har også nogle sample oplysninger - der er to foskellige strains af mus og også forskellige batches.

```{r}
coldata
```

Vi kan kigger på hvor mange af hver stain og batch vi har i de data:

```{r}
table(coldata$strain, coldata$batch)
```

Så kan man se, at både strain har repræsenteret tre eller fire samples i hver af de tre batches. Der er derfor _replication_ og da vi har fået repræsenteret hver kombination af strain og batch, kan man eventuaelle __block__ efter batch for at få fjernet dens effekt. Her vil vi bare gerne kigger efter batch effekts og ikke fjerner dem.

For at kigger på de batch effekts kan man via prinicpal component analysis. Husk at når man lave en principal compononent analysis, få men hvad der kaldes for den rotation matrix - det anvendes til at se hvor de forskellige samples ligger relative til hinhanden i de forskellige principal components - samples der ligner hinanden vises på samme sted på plottet.

```{r}
pca_fit <- norm.cts %>%
  select(where(is.numeric)) %>% # retain only numeric columns
  prcomp(scale = TRUE) # do PCA on scaled data
```

For at analysere sammenhænge mellem de forskellige variabler kan man kigger på den rotation matrix med funktionen tidy:

```{r}
rot_matrix <- pca_fit %>%
  tidy(matrix = "rotation") 
```

Vi vil gerne lave et plot af de rotation matrix, men første vil vi gerne tilføje de sample oplysninger med `left_join`, så at vi kan se de forskellige batches eller strains. Både datarammer har en kolon som hedder `column` som referer til de sample navne, så jeg forbinde efter `column` her.

```{r}
rot_matrix <- rot_matrix  %>% 
  left_join(coldata,by="column")
```

Anvende `pivot_wider` til at få den i wide form:

```{r}
rot_matrix_wide <- rot_matrix %>% 
  pivot_wider(names_from = "PC", names_prefix = "PC", values_from = "value")
rot_matrix_wide
```

Vi laver et plot af de første to principal components og giv farve og form efter de tre batches i de samples. Vi kan se, at vi har fået alle samples fra batch nummer 2 på samme sted i plottet.

```{r,fig.width=6,fig.height=4}
rot_matrix_wide %>%
  ggplot(aes(PC1,PC2,shape=factor(batch),colour=factor(batch))) + 
  geom_point(size=3) +
  theme_minimal()
```

Vi kan også give farver efter strain, hvor vi kan se at der nok er en forskellen mellem de to strains her.

```{r,fig.width=6,fig.height=4}
rot_matrix_wide %>%
  ggplot(aes(PC1,PC2,shape=factor(strain),colour=factor(strain))) + 
  geom_point(size=3) +
  theme_minimal()
```

Man kan også ser de data på en anden måde ved at lave boxplots for to første to principal comonponets opdelte efter batch. Vi få bekræftet vores observation at der er en stærk forskel mellem match 7 og de andre to batches langt den første principal component, og det er et problem som muligvis skal korrigeres før man laver yderligere analyser på de data.

<!-- lave boxplot af PC1 og PC2 opdelt efter batch-->
```{r,comment=FALSE,message=FALSE}
p1 <- rot_matrix_wide %>% 
  ggplot(aes(x=factor(batch),y=PC1,fill=factor(batch))) + geom_boxplot(show.legend = F) + geom_jitter(show.legend = F) + theme_minimal()

p2 <- rot_matrix_wide %>% 
  ggplot(aes(x=factor(batch),y=PC2,fill=factor(batch))) + geom_boxplot(show.legend = F) + geom_jitter(show.legend = F) + theme_minimal()

library(gridExtra)
grid.arrange(p1,p2,ncol=2)
```


__Nogle ide for hvordan man korrigere batch effekts (men ikke dækket i kurset):__ https://en.wikipedia.org/wiki/Batch_effect#Correction


## Problemstillinger


__0__) Quiz på Absalon - experimental

__1__) *Eksperimental design*

Jeg laver et eksperiment hvor patienter få en af tre forskellige kosttilskud. Der er 5 patienter i hver gruppe og jeg vil gerne se, om patienters energi niveau i gennemsnit er forskellige mellem de tre grupper. Alderne af de patienter i hver af de tre grupper er:

Gruppe 1: 18, 23, 31, 25, 19

Gruppe 2: 24, 29, 35, 21, 30

Gruppe 3: 43, 52, 33, 39, 40

* Hvad er problemet her med det eksperimental design? Lav boxplots for at viser fordelingen af de alders for hver af de tre grupper.
* Hvis man finder en signifikant forskel mellem de tre kosttilskud, kan man stoler på resultaterne?
* Hvad andre variabler end alder kunne skyldes en eventuelle forskel mellem de tre kosttilskud, og som måske skulle tages i betragtning?
* Hvad kan man gøre med den eksperiment design for at løse problemet?


```{r,echo=FALSE,eval=FALSE}
mytib <- tibble("group_1"=c(18,23,31,25,19),"group_2"=c(24,29,35,21,30),"group_3"=c(43,52,33,39,40))
mytib %>% pivot_longer(cols=everything()) %>%
  ggplot(aes(x=name,y=value,fill=name)) + geom_boxplot() + theme_minimal() + coord_flip()
```

__2__) *Simpson's paradoks* __Lung Cap data revisited__

<!-- Vi så også et eksempel på Simpson's paradox tidligere i kurset med datasættet LungCap. Her kan man se, at indenfor de forskellige alder grupper er der en tendens for, at rygere har en lavere lung kapacitet end ikke-rygere. Men da vi ser på datasættet samlet, fik vi den modsætte sammenhæng - i det hele taget har rygere en højere lung kapacitet i gennemsnit end ikke-rygere. -->

Indlæse `LungCapData`:

```{r}
LungCapData <- read.csv("https://www.dropbox.com/s/ke27fs5d37ks1hm/LungCapData.csv?dl=1")
LungCapData$Age.Group <- cut(LungCapData$Age,breaks=c(1,13,15,17,19),right=FALSE,include.lowest = TRUE)
levels(LungCapData$Age.Group) <- c("<13","13-14","15-16","17+")
```

* Lav boxplots med `smoke` på x-aksen og `LungCap` på y-aksen.
    + Notere hvilke gruppe den højeste lungkapacitet.

```{r,echo=FALSE,eval=FALSE}
ggplot(LungCapData, aes(x = Smoke,y = LungCap, fill=Smoke)) + 
  geom_boxplot() + 
  theme_minimal() + 
  geom_jitter()
```

* Lav samme plot men adskilte efter `Age.Group`.
* Beskriv, hvordan det er et eksempel på Simpson's Paradoks.
* Lav et boxplot med `Age` på y-aksen og `Smoke` på x-aksen for at støtte hvorfor man ser Simpson's Paradoks i de data.

```{r,echo=FALSE,eval=FALSE}
ggplot(LungCapData, aes(x = Smoke,y = LungCap, fill=Smoke)) + 
  geom_boxplot() + 
  theme_minimal() + 
  geom_jitter() +
  facet_grid(~Age.Group)
```
 

<!-- Det skylds, at der er rigtig mange i datasættet som hører til den yngste alders gruppe (med alder helt ned til 3), og de fleste af dem er ikke-rygere. Da de også have i gennemsnit en lavere lungkapacitet end dem der hører til de ældre grupper, så fik vi den falske konclusion at rygere har en bedre lungkapacitet. Vi kan se forskellen i den alder fordeling mellem rygere og ikke-rygere i nedenstående plot. -->


```{r,fig.width=4,fig.height=2, echo=FALSE,eval=FALSE}
LungCapData %>% 
  ggplot(aes(y=Age,x=Smoke,fill=Smoke)) + 
  scale_fill_manual(values = c("purple","steelblue")) +
  geom_boxplot(show.legend = FALSE) + 
  coord_flip() +
  theme_minimal()
```

<!-- Så kan vi se, at age er en counfounding variable i dette datasæt, og man er nødt til at tage den i betragtning hvis man skal virkelige forstå de sammenhænge som ekistere i datasættet. Her var det meget nyttigt at lave en visualisering af de data som i ovenstående plot - vi fik et hurtigt overblik over, hvad der sker både med hensyn til indenfor de forskellige alder grupper, og hvor mange personer nogenlunde er repræsenteret i hver af de grupper. -->

<!-- Hvad for et stategi kan man gøre for at undgå Simpson's paradox her? -->

<!-- * Opdele datasættet efter alder gruppe - det har vi gjorte her. -->
<!-- * Match hver rygere med en af den samme alder, som er ikke rygere. -->



__3__) *Anscombes analyse* Gentage Anscombes analyse med dinosaurus datasæt:

```{r,warning=FALSE,message=FALSE,comment=FALSE}
library(datasauRus)
data_dozen <- datasauRus::datasaurus_dozen
```

* Fit en lineær regression model for hver af de datasæt (anvende `group_by`, `nest` og `map` ramme), hvor man finde den forventet `y` afhængig om `x`.
* Anvende `tidy` og `glance` på resultaterne.

```{r,echo=FALSE,eval=FALSE}

my_func <- ~lm(y ~ x,data=.x)

data_dozen_fit <- data_dozen %>% 
  group_by(dataset) %>% 
  nest() %>%
  mutate(fit = map(data,my_func),
         fit_tidy = map(fit,tidy),
         fit_glance = map(fit,glance))
```

* Anvende resultaterne fra `tidy` til at kigge på den slope og intercept for de forskellige modeller.

```{r,echo=FALSE,eval=FALSE}
data_dozen_fit %>% 
  unnest(fit_tidy) %>% 
  pivot_wider(id_cols = dataset,names_from = term,values_from = estimate)
```

* Anvende også resultaterne fra `glance` til at kigge på den `r.squared` værdi og p-værdien.
* Er de de samme datasæt? Lave et scatter plot adskilte efter de forskellige datasæt. 
    + Hvordan ser de bedste rette linjer ud på de plots?

```{r,echo=FALSE,eval=FALSE}
data_dozen %>% 
  ggplot(aes(x=x,y=y,colour=dataset)) + 
  geom_point() + 
  facet_wrap(~dataset,ncol=3) + 
  geom_smooth(method="lm") +
  theme_bw()
```


__4__) Vi vil gerne tjekke for batch effects i følgende datasæt. Det er simuleret "single cell" sekvensering count data `cse50` samt med `batches` som angiver en batch for hver af de 500 cells i de datasæt.

```{r}
cse50 <- read.table("https://www.dropbox.com/s/o0wzojpcsekeg6z/cell_mix_50_counts.txt?dl=1")
batches <- read.table("https://www.dropbox.com/s/4t382bfgro46ka5/cell_mix_50_batches.txt?dl=1")
batches <- as_tibble(batches)
cse50 <- as_tibble(cse50)
```

  * __a__) Anvend `map_df` til at få transformeret de data til log scale (plus 1 først og tag log bagefter).
  
```{r,echo=FALSE,eval=FALSE}
cse50 <- map_df(cse50,~log(.x+1))
```
  
  * __b__) Lav PCA på dent transformeret datasæt.

```{r,echo=FALSE,eval=FALSE}
pca_fit <- as_tibble(cse50) %>%
  select(where(is.numeric)) %>% # retain only numeric columns
  prcomp(scale = TRUE) # do PCA on scaled data
```


  * __c__) Anvend din PCA resultater til at få den rotation matrix


```{r,echo=FALSE,eval=FALSE}
rot_matrix <- pca_fit %>%
  tidy(matrix = "rotation") 


rot_matrix
```

  
  * __c__) Forbinde oplysningerne fra datarammen `batches` med `left_join` til din rotation matrix.
      + Først tilføj en ny kolon der hedder "column", som er lig med `names(cse50)`.


```{r,echo=FALSE,eval=FALSE}
batch_data <- batches %>% mutate("column"=names(cse50))


rot_matrix <- rot_matrix  %>% 
  left_join(batch_data,by="column")
```


  * __d__) Anvend `pivot_wider` og lave et plot af den første to principal components, og angive farve efter `batch`.


```{r,echo=FALSE,eval=FALSE}
rot_matrix_wide <- rot_matrix %>% 
  pivot_wider(names_from = "PC", names_prefix = "PC", values_from = "value")

p1 <- rot_matrix_wide %>%
  ggplot(aes(PC1,PC2,shape=factor(batch),colour=factor(batch))) + 
  geom_point() +
  theme_minimal()

p1
```


  * __e__) Lav også boxplots for de første to prinpical components fordelt efter `batch`. 
      + Kommentere på eventuelle batch effekts i de data.


```{r,echo=FALSE,eval=FALSE}
p1 <- rot_matrix_wide %>% 
  ggplot(aes(x=factor(batch),y=PC1,fill=factor(batch))) + geom_boxplot(show.legend = F) + geom_jitter(show.legend = F) + theme_minimal()

p2 <- rot_matrix_wide %>% 
  ggplot(aes(x=factor(batch),y=PC2,fill=factor(batch))) + geom_boxplot(show.legend = F) + geom_jitter(show.legend = F) + theme_minimal()

grid.arrange(p1,p2,ncol=2)
```
