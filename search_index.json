[["index.html", "Analyse og visualisering af biologiske datasæt - 2022 Chapter 1 Grundlæggende R 1.1 Inledning til kapitel 1.2 RStudio 1.3 Working directory 1.4 R pakker 1.5 Hvor kommer vores data fra? 1.6 Beregninger i R 1.7 Dataframes 1.8 Descriptive statistics 1.9 Statistike tester 1.10 Problemstillinger", " Analyse og visualisering af biologiske datasæt - 2022 Sarah Rennie Last updated: 2022-05-28 Chapter 1 Grundlæggende R “Det er ikke, fordi noget er svært, at vi ikke tør, det er, fordi vi ikke tør, at noget er svært” - Seneca 1.1 Inledning til kapitel Her opsummerer jeg nogle grundlæggende R og statistik, der betragtes som forudsætninger i det nuværende kursus. Selvom vi i kurset skifter hurtigt over til den tidyverse-pakke løsning, som erstatter meget af funktionaliteten fra base-R, er det stadig vigtigt at have et grundlæggende kendskab til hvordan tingene fungerer i base-R - derfor hvis du har meget lidt erfaring med base-R anbefaler jeg, at du også bruger noget ekstra tid udover den første mødegange til at komme op på niveauet. For at bestå kurset er det ikke forventningen, at du kender til alle detaljer og teori bag de statistiske metoder, men at du kan anvende dem hensigtsmæssigt i praksis i R, samt fortolke resultaterne. Jeg giver masser af muligheder for at øve dig med at lave statistik hele vejen gennem kurset, og i selve eksamen stiller jeg ikke spørgsmål om metoder, der ikke bliver dækkede blandt de forskellige øvelser (herunder workshop opgaver). Jeg kommer også ind på lineær regression igen senere gennem forelæsningerne så vær ikke bekymret hvis du ikke har set det hele før. Se gerne også “Quiz - grundlæggende” på Absalon for at tjekke din forståelse og udfylde eventuelle huller i din viden (OBS: Quizzen er tilgængelig lidt inden starten af kurset). 1.2 RStudio Vi kommer fremadrettet til at være afhængig af RStudio til at lave blandt andet R Markdown dokumenter. Kendskab til R Markdown er emnet i vores næste lektion og jeg antager, at du ikke har benyttet det før. Det allerførste du skulle gør, hvis du ikke har installeret RStudio på din computer, er at downloade det gratis på nettet: https://www.rstudio.com/products/rstudio/download/#download Følg venligst RStudios egne anvisninger til at få det installeret. Bemærk, at installering af RStudio er ikke den samme som at have R installeret på din computer - man skal installere dem begge to (man kan bruge R uden RStudio men ikke omvendt. 1.2.1 De forskellige vinduer i RStudio Du kan læse følgende for at lære de fire forskellige vinduer i RStudio at kende: https://bookdown.org/ndphillips/YaRrr/the-four-rstudio-windows.html Her er et kort oversigt: Man skriver kode i Source (øverst til venstre) Man kører kode ved at tryk CMD+ENTER (eller WIN-KEY+ENTER) Koder køres ind i Console (som plejer at være nederst til venstre, selvom det er øverst til højere i billedet). Man kan også skrive koder direkte i Console, men det ikke anbefales generelt, når koden ikke bliver gemt. Environment - her kan man se blandt andet, alle objekter i Workspace. 1.3 Working directory Når man arbejder på et projekt, er det ofte nyttigt at vide, den working directory som R arbejder fra - det er den mappe, hvor R forsøger at åbne eller gemme filer fra, medmindre man angiver et andet sted. getwd() #se nuværende working directory list.dirs(path = &quot;.&quot;, recursive = FALSE) #se mappe indenfor working directory setwd(&quot;~/Documents/&quot;) #sætte en ny working directory (C:/Users/myname/Documents hvis man bruger Windows) Hvis man bruger Windows, husk at man kan skrive en path på følgende måde: #notrun setwd(&quot;C:/Users/myname/Documents&quot;) #enten med / setwd(&quot;C:\\\\Users\\\\myname\\\\Documents&quot;) #eller med \\\\ OBS: jeg bruger Mac, så hvis der er et vigtigt ting at man skal huske hvis man bruger en Windows computer, kan jeg også tilføje det her. Bemærk dog, at de allerfleste ting ved R programmering og tidyverse er ens uanset om man bruger Windows eller Mac. 1.4 R pakker R pakker er simpelthen en samling af funktioner (eller datasæt i nogle tilfælde), der udvider hvad er tilgængelige i base-R (den R man få, uden at indlæse en pakke). I R er der mange tusind R pakker (op mod 100,000), der er tilgængelige på CRAN (https://cran.r-project.org/). Indenfor det biologiske fag er der også mange flere pakker på Bioconductor (https://www.bioconductor.org/), og i nogle tilfælde kan R pakker også installeres direkte fra Github. I dette kursus arbejder vi rigtig meget med en pakke der hedder tidyverse. tidyverse er faktisk en samling af otte R pakker, som indlæses på en gang. Inden du indlæse pakken, skal du først sikre dig, at pakken er installeret på systemet ved følgende kommando: install.packages(&quot;tidyverse&quot;) Alle pakker på CRAN er installeret på samme måde. Når du faktisk gerne vil bruge en R pakke, skal du først indlæse den ved at bruge library(): library(tidyverse) ## ── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ── ## ✓ ggplot2 3.3.5 ✓ purrr 0.3.4 ## ✓ tibble 3.1.6 ✓ dplyr 1.0.8 ## ✓ tidyr 1.2.0 ✓ stringr 1.4.0 ## ✓ readr 2.1.2 ✓ forcats 0.5.1 ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ── ## x dplyr::filter() masks stats::filter() ## x dplyr::lag() masks stats::lag() Vi kommer til at arbejde med tidyverse pakker fra kapitel tre (vi starter med ggplot2 og så nogle af de andre pakke fra tidyverse fra kapitel fire), så det er en god idé at har tidyverse installeret allerede nu, når det nogle gange kan tage lidt tid til at installere eller opdatere de mange andre mulige pakker, der tidyverse er afhængig af. Vær opmærksom på, at der nogle gange opstår konflikter når det samme funktionnavn findes i flere pakker - for eksempel, funktionen filter() findes indenfor to forskellige pakker, nemlig dplyr og stats. Når du skriver filter() så ved R ikke, hvilke pakker du mener. I dette tilfælde kan du være gennemskueligt overfor den pakke, du gerne vil bruge ved at skrive dplyr::filter() eller stats:filter() i stedet for bare filter(). Som sidste kommentar, er det god praksis at indlæse alle pakker, der du benytter sig af, på toppen af din script, så at du hurtigt kan få overblik over, hvilke pakker, der skal indlæses til at få dine koder til at fungere. 1.5 Hvor kommer vores data fra? De forskellige datasæt, vi kommer til at arbejde med i kurset stammer fra mange forskellige steder. 1.5.1 Indbyggede datasæt I R er der mange indbygget datasæt som er meget brugbart for at vise koncepter, hvilket gøre dem især populært i undervisningsmateriale. Indbyggede datasæt er ofte tilgængligt indenfor mange pakker, men library(datasets) er den mest brugt (der er også mange indenfor library(ggplot2). For eksempel, for at indlæse datasættet, der hedder ‘iris,’ kan man bruge data(): library(datasets) data(iris) Så er en dataframe, der hedder ‘iris’ tilgængelige som en objekt i workspacen - se den “Environment” fane på højere side i RStudio, eller indtaste ls(), så bør du kunne se et objekt med navnet ‘iris.’ Man kan kun arbejde med objekter som er en del af workspacen. 1.5.2 Importering af data fra .txt fil Det er meget hyppigt, at man har sin data i formen af en .txt fil eller .xlsx fil på sin computer. Den nemmeste måde at få åbnet en .txt fil er ved at bruge read.table(), som i nedenstående: data &lt;- read.table(&quot;mydata.txt&quot;) #indlæse data filen mydata.txt som er i working directory head(data) Hvis datasættet har kolonner navne, der er skrevet ind i filen, så skal man huske at bruge header=T for at undgå, at den første række i datasættet bliver disse tekste i stedet for virkelige observationer. data &lt;- read.table(&quot;mydata.txt&quot;,header=T) #indlæse data filen mydata.txt som er i working directory head(data) 1.5.3 Importering af data fra Excel Der findes også en hjælpsom pakke, som hedder readxl, der kan indlæse Excel-ark direkte ind i R: library(readxl) data &lt;- read_excel(&quot;data.xlsx&quot;) data 1.5.4 Kaggle Hvis du gerne vil øve dig med statistike analyser (udover nuværende kursus), er Kaggle en fantastisk ressource til at finde forskellige datasæt. I rigtige mange tilfælde kan man også finde analyser some andre har lavet I R (også Python), hvilket kan inspirere jeres egen læring. Link hvis interesseret: https://www.kaggle.com/ 1.6 Beregninger i R Her er nogle helt grundlæggende koncepter når man arbejder med R. Du må selvfølgelige gerne springe sektionen over, hvis du allerede har meget erfaring med base R, men det kan være værd at tjekke, om der noget ting, der lige skal gennemgås. En god tilgang er bare at arbejde gennem problemstillingerne nedenfor, og bruger følgende notater som en reference. 1.6.1 Vectorer I R laver man en vector med c(), hvor man adskiller de forskellige elementer med en komma, som i nedenstående eksempel: a &lt;- c(1,2,3,4,5) #sæt objektet &#39;a&#39; til at være en vector af tal a ## [1] 1 2 3 4 5 Man er ikke begrænset til tal: c &lt;- c(&quot;cat&quot;,&quot;mouse&quot;,&quot;horse&quot;,&quot;sheep&quot;,&quot;dog&quot;) c ## [1] &quot;cat&quot; &quot;mouse&quot; &quot;horse&quot; &quot;sheep&quot; &quot;dog&quot; 1.6.2 datatyper Nar vi kommer til at arbejde med visualiseringer og data beardejdning er det vigtigt at have styr på datatyper i datasættet. For eksempel har vectoren c ovenpå typen character (forkortet chr) og ikke numeric (forkortet num): is.numeric(c) ## [1] FALSE is.character(c) ## [1] TRUE Her er en list overfor nogle af de vigtigste datatyper: Datatype Navn Beskrivelse int integer kun hel tal c(-1,0,1,2,3) lgl logical TRUE TRUE FALSE TRUE FALSE chr character c(\"Bob\",\"Sally\",\"Brian\",...) fct factor bestemte niveauer e.g. Species: c(\"setosa\",\"versicola\") dbl double Tal fk. c(4.3902, 3.12, 4.5) lst list blande forskellige data typer og specificere elementer med [[i]] [[1]] [1] c(\"red\",\"blue\") [[2]] [1] TRUE [[3]] [1] c(3,2.3,1.459) En datatype, der bør få særlig opmærksomhed er fct (factor). I følgende vector tea_coffee har vi tekst, men blandt de fem elementer er der kun to bestemte niveauer (nemlig “tea” og “coffee”). tea_coffee &lt;- c(&quot;tea&quot;,&quot;tea&quot;,&quot;coffee&quot;,&quot;coffee&quot;,&quot;tea&quot;) is.factor(tea_coffee) ## [1] FALSE tea_coffee ## [1] &quot;tea&quot; &quot;tea&quot; &quot;coffee&quot; &quot;coffee&quot; &quot;tea&quot; Vi vil derfor gerne fortælle R, at tea_coffee er ikke bare nogle tilfældig tekst men at der er en struktur med, så vi bruger funktionen as.factor for at lave den om til datatypen fct. tea_coffee &lt;- as.factor(tea_coffee) is.factor(tea_coffee) ## [1] TRUE tea_coffee ## [1] tea tea coffee coffee tea ## Levels: coffee tea Den ‘ekstra’ oplysninger man har ved at sige, at en variabel betragtes som factor bliver vigtigt når man arbejder med visualiseringer - for eksempel, hvis vi gerne vil lave et barplot hvor man gerne vil adskille søjlerne efter de to niveauer “tea” og “coffee” (visualiseringer er emnet fra kapitel 3). 1.7 Dataframes http://www.r-tutor.com/r-introduction/data-frame Mange af de ting, som vi laver i R tager udgangspunkten i dataframes (eller datarammer). mydf &lt;- data.frame(&quot;personID&quot;=1:5, &quot;height&quot;=c(140,187,154,132,165), &quot;age&quot;=c(34,31,25,43,29)) mydf ## personID height age ## 1 1 140 34 ## 2 2 187 31 ## 3 3 154 25 ## 4 4 132 43 ## 5 5 165 29 Man kan fa adgang til variabler i en dataframe ved at bruge det dollar tegn $. For eksempel giver følgende variablen personID fra dataframen mydf: mydf$personID ## [1] 1 2 3 4 5 Husk, at vores dataframe, ligesom et matrix (i R: matrix()) har to dimensioner - række og kolonner Forskellen mellem en matrix og en dataramme er, at datarammer kan indeholde mange forskellige data typer (herunder numeriske, faktorer, karakterer osv.), men matrix indeholder kun numeriske data. For eksempel i tilfældet af ovenstående dataframen er alle variabler numeriske, men vi kan godt tilføje en variabel som er ikke-numeriske: mydf$colour &lt;- c(&quot;red&quot;,&quot;blue&quot;,&quot;green&quot;,&quot;orange&quot;,&quot;purple&quot;) #make new variable which is non-numeric mydf ## personID height age colour ## 1 1 140 34 red ## 2 2 187 31 blue ## 3 3 154 25 green ## 4 4 132 43 orange ## 5 5 165 29 purple Nu er mydf er en dataframe, der blander forskellige datatyper, men følgende er en matrix matrix(c(1, 2, 3, 4, 5, 6), nrow=3, ncol=2) ## [,1] [,2] ## [1,] 1 4 ## [2,] 2 5 ## [3,] 3 6 og kan kun indeholde numeriske data, som kan bruges til at lave matematik operationer (matrix multiplikation osv.). I dette kursus beskæftiger os primært med dataframes (som bliver kaldt for tibbles i tidyverse). 1.7.1 Delmægder af dataframes Selvom vi kommer til at redefinere hvordan man laver delmængde når vi kommer til at arbejde med pakken tidyverse, er det alligevel vigtigt at forstå, hvordan man laver en delmængde i base-R, og det er et område, der ofte skaber forvirring blandt de uerfarne. Når man vil gerne har en bestemt delmængde af en vector, bruger man firkantet paranteser [ ]. Følgende kode giver mig de første to værdier fra vectoren a: a[1:2] ## [1] 1 2 Bemærk, at mens vectorer har kun en dimension, har dataframes to dimensioner. Når man skal lave en delmægde af en dataframe, skal man derfor fortælle R, hvilke række og hvilke kolonner skal være med. mydf[række indekser, kolonner indekser] #not run For eksempel, hvis vi gerne vil have den første to observationer med, samt kun den anden variabel, skriver man følgende: mydf[1:2, 2] #first two rows (observations), second column (variable) only ## [1] 140 187 Hvis vi vil beholde den første to observationer og samtlige variabler, kan den anden plads være tom: mydf[1:2, ] #first two rows, all columns ## personID height age colour ## 1 1 140 34 red ## 2 2 187 31 blue Jeg kan også angive et variabelnavn direkte: mydf[1:2,&quot;height&quot;] ## [1] 140 187 Man kan kigge på en subset af rækkerne i de data ved at mydf[mydf$height&gt;=165,] #alle rækker i datarammen med height = 165 eller over ## personID height age colour ## 2 2 187 31 blue ## 5 5 165 29 purple Her er en tabel af comparitiver, og jeg gengiver samme tabel når I kommer til at lave delmængde i tidyverse: comparitiv beskrivelse &lt; less than &gt; greater than &lt;= less than or equal to &gt;= greater than or equal to == equal to != not equal to &amp; and %in% in | or ! not Jeg mener, at %in% er særlig brugbart og er værd at lære: mydf[mydf$personID %in% c(1,3,5),] #alle personer med personID 1,3 eller 5 ## personID height age colour ## 1 1 140 34 red ## 3 3 154 25 green ## 5 5 165 29 purple Her er et eksempel på, hvordan man bruger udråbstegnet: personer med personID, der ikke er 1,3 eller 5: mydf[!(mydf$personID %in% c(1,3,5)),] #alle personer med personID 2 eller 4 ## personID height age colour ## 2 2 187 31 blue ## 4 4 132 43 orange 1.8 Descriptive statistics 1.8.1 Simulere data fra den normale fordeling Hvis du har bruge for at vide mere om den normale fordeling: http://www.r-tutor.com/elementary-statistics/probability-distributions/normal-distribution Man kan nemt lave sin egne ‘fake’ data ved at simulere det fra en fordeling, der vil typiske være den normale fordeling, idet den normale fordeling opstår mest hyppigt i den virkelige verden (husk den klassiske klokke-form). I R kan man bruge funktionen rnorm til at simulere data - først angiver man, hvor mange observationer man vil have, og dernæst den mean og standard deviation (sd), som er de to nødvendige parametre for at beskrive en normal fordeling x &lt;- rnorm(25,mean=0,sd=1) #standard normal distribution x #så har vi 25 værdier fra en normal distribution med mean=0 og standard deviation=1. ## [1] -0.71599556 -0.36651227 0.25331245 1.01166049 0.34039712 1.63101820 ## [7] -0.05717746 1.02605600 -0.97568264 -1.34081068 0.52976127 1.16968872 ## [13] -0.60718512 1.54746698 1.40688743 -0.54985222 0.53453001 -0.77478157 ## [19] -0.46713818 -0.47731571 -0.76739409 1.12778527 1.93338643 -0.23516766 ## [25] 0.35010790 I stedet for at kigge på alle værdier på én gang, vil vi måske hellere kigge kun på de første (eller sidste) værdier: head(x) #første 6 ## [1] -0.7159956 -0.3665123 0.2533124 1.0116605 0.3403971 1.6310182 tail(x) #sidste 6 ## [1] -0.4773157 -0.7673941 1.1277853 1.9333864 -0.2351677 0.3501079 x[1] #første værdi ## [1] -0.7159956 x[length(x)] #sidste data point ## [1] 0.3501079 Bemærk, at til forskellen af Python og mange andre programmering sprog, R bruger 1-baserende indicer - det betyder, at den første værdi er x[1] og ikke x[0] som i Python. 1.8.2 Measures of central tendency function Description mean() mean \\(\\bar{x}_{i} = \\frac{1}{n}\\sum_{i=1}^{n} x_{i}\\) median() median value max() maximum value min() minimum value var() variance \\(s^2 = \\frac{1}{n-1}\\sum_{i=1}^{n} (x_{i} - \\bar{x}_{i})^2\\) sd() standard deviation \\(s\\) Lad os afprøve dem på vores simulerede data: my_mean &lt;- mean(x) my_median &lt;- median(x) my_max &lt;- max(x) my_min &lt;- min(x) my_var &lt;- var(x) my_sd &lt;- sd(x) c(my_mean,my_median,my_max,my_min,my_var,my_sd) #print results ## [1] 0.2210818 0.2533124 1.9333864 -1.3408107 0.8707119 0.9331194 Man kan også lave et summary af dataen, som bestå af mange af de statistiker navnt ovenpå: summary(x) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## -1.3408 -0.5499 0.2533 0.2211 1.0261 1.9334 1.8.3 tapply() En meget brugbar funktion, som er værd at vide, er tapply(). data(iris) tapply(iris$Sepal.Length,iris$Species,mean) # ovenstående i kun en linje ## setosa versicolor virginica ## 5.006 5.936 6.588 Her tager vi en variabel der hedder Sepal.Length, opdeler den efter Species, og beregner mean for enhver af de tre arter i Species (setosa, versicolor og virginica). Man kan opnå det samme resultat ved at beregne mean for de tre Species hver for sig (en tilgang, der ikke opskaleres særlig godt!): # gennemsnit Sepal Length for Species setosa mean_setosa &lt;- mean(iris$Sepal.Length[iris$Species==&quot;setosa&quot;]) # gennemsnit Sepal Length for Species versicolor mean_versi &lt;- mean(iris$Sepal.Length[iris$Species==&quot;versicolor&quot;]) # gennemsnit Sepal Length for Species virginica mean_virgin &lt;- mean(iris$Sepal.Length[iris$Species==&quot;virginica&quot;]) c(mean_setosa,mean_versi,mean_virgin) ## [1] 5.006 5.936 6.588 Det er også værd at ved koncepten, fordi vi kommer til lære en lignende koncept i tidyverse (med group_by og summarise). 1.9 Statistike tester Her giver jeg et oversigt over nogle af de baserende tests man kan lave på data i R - det giver noget, du kan referere til senere hvis der er brug for det. Jeg går ikke i detaljer eller teorien af testerne (se dit tidligere kursus), men jeg forventer at I er i stand til at bruge dem på en hensigtsmæssigt måde i R, og fortolker resultaterne. Vær ikke bekymret hvis du ikke har set de hele før, jeg giver masser a muligheder for at øve statistik gennem forløbet. 1.9.1 Korrelation Måler sammenhængen mellem to normalfordelte variabler: \\(&gt;0\\) betyder, at der er en postiv sammenhæng \\(&lt;0\\) betyder, at der er en negativ sammenhæng \\(=0\\) betyder, at der er ingen sammenhængen mellem de to variabler data(cars) cor(cars$speed, cars$dist) ## [1] 0.8068949 Man kan teste om korrelationen er signifikant ved at bruge cor.test() cor.test(cars$speed, cars$dist) ## ## Pearson&#39;s product-moment correlation ## ## data: cars$speed and cars$dist ## t = 9.464, df = 48, p-value = 1.49e-12 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.6816422 0.8862036 ## sample estimates: ## cor ## 0.8068949 Så kan man se, at p-værdien er 0, der er under 0.05, så konkludere man, at der er en signifikant korrelation mellem de to variabler. 1.9.2 Test for uafhængighed (chi-sq test) Her undersøger man, om der er en sammenhæng mellem antal observationer i to forskellige kategorier. Se for eksempel følgende tabel, der viser antal kopi af en gen variant og to forskellige farver som phenotype (farve på en type blomst): 0 1 2 red 29 31 16 pink 11 16 24 Vi vil gerne vide, om phenotype er afhængig af genotype: \\(H_{0}:\\) antal gen copi og phenotype er uafhængie af hinanden VS \\(H_{1}:\\) antal gen copi og phenotype er afhængie af hinanden Testen går ud på, at man beregner forventede værdier (baserende på de totals under nullhypotesen af de er uafængige) og sammenligne forventede værdier med observerede værdier. Man laver testen i R ved at benytte funktionen chisq.test: chisq.test(dat) ## ## Pearson&#39;s Chi-squared test ## ## data: dat ## X-squared = 9.9516, df = 2, p-value = 0.006903 Her er p-værdien = 0.006903 &lt; 0.05, så vi forkaster nulhypotesen og konkluderer, at der er en afhængighed mellem de to variabler. Man kan også se fra rådatasættet, at der er langt flere røde blomster, der har ingen kopi af genet end der er røde blomster, der har to kopier af genet, og mønstret er omvendt i tilfældet af de lyserøde blomster. 1.9.3 1 sample t-test For at vise en 1-sample t-test, simulerer jeg noget data fra den normal fordeling med mean = 3. set.seed(290223) # bare for at få den samme resultat hver gang x &lt;- rnorm(10,mean = 3,sd = 1) Forestil dig, at du ikke helt stoler på funktionen rnorm() og gerne vil teste, om x virkelig kommer fra en normal fordeling med et gennemsnit (\\(\\mu\\)) på tre. Nulhypotesen og alternativ hypotesen (2-sidet test) er således: \\(H_{0}: \\mu = 3\\), VS \\(H_{1}: \\mu \\neq 3\\) For at lave testen i R, bruger man funktionen t.test() og angiver mu = 3 for at reflektere vores hypoteser: t.test(x,mu = 3) ## ## One Sample t-test ## ## data: x ## t = -1.1448, df = 9, p-value = 0.2818 ## alternative hypothesis: true mean is not equal to 3 ## 95 percent confidence interval: ## 2.169968 3.272231 ## sample estimates: ## mean of x ## 2.721099 Fra resultatet kan man se, at p-værdien er estimeret som 0.2818, og da den er &gt; 0.05 forkaster vi ikke nulhypotesen, og konkluderer at \\(\\mu = 3\\). Bemærkning: da vi simulerede vores data fra en normal fordeling med et gennemsnit på tre, vidste vi i forvejen at det korrekte svar er, at beholde nullhypotesen. Havde vi forkastet nullhypotesen, havde vi lavet en type I fejl - det vil sige, at vi forkaster nullhypotesen når det faktisk er sandt. 1.9.4 2-sample t-test Undersøger om der er en forskel i de gennemsnitlige værdier mellem to grupper - kan de to grupper betragtes til at stammer fra den samme normale fordeling? Hypoteserne er således (to-sidet): \\(H_{0}: \\mu_{1} = \\mu_{2}\\), VS \\(H_{1}: \\mu_{1} \\neq \\mu_{2}\\) I følgende kode simulere jeg to stikprøver, der kommer fra en normal fordeling med forskellige gennemsnitte og bruger funktionen t.test. Man kan angive at de to stikprøver har samme variance ved at skrive var.equal = T indenfor funktionen t.test: x &lt;- rnorm(10,3,1) y &lt;- rnorm(10,5,1) t.test(x,y,var.equal = T) ## ## Two Sample t-test ## ## data: x and y ## t = -5.4258, df = 18, p-value = 3.729e-05 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -2.700858 -1.193081 ## sample estimates: ## mean of x mean of y ## 2.783056 4.730025 Hvis man til gengæld ikke kan antage, at variansen er den samme i de to grupper: x &lt;- rnorm(10,3,1) y &lt;- rnorm(10,5,3) #større variance t.test(x,y,var.equal = F) #var.equal=F er &#39;default&#39; så man behøver ikke at specifere ## ## Welch Two Sample t-test ## ## data: x and y ## t = -2.0238, df = 11.77, p-value = 0.0663 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -3.9077927 0.1483728 ## sample estimates: ## mean of x mean of y ## 2.757436 4.637146 Bemærk at hvis man kan antage at variancen er den samme, så har man mere power (kræft) til at kalde en virkelig forskel for signifikant. 1.9.5 Paired t-test En paired t-test bruges når man for eksempel har målinger for den samme sæt personer i hver stikprøve, og man gerne vil teste om forskellen i værdier mellem de to stikprøver er signifikant. For eksempel hvis vi har “before” og “after” målinger for den samme 10 individer: set.seed(320) before &lt;- rnorm(10,3,1) after &lt;- rnorm(10,6,2) t.test(before,after,paired=T) #specificy paired data ## ## Paired t-test ## ## data: before and after ## t = -9.3296, df = 9, p-value = 6.356e-06 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -5.415186 -3.301613 ## sample estimates: ## mean of the differences ## -4.358399 t.test(before-after,mu=0) #exactly the same result ## ## One Sample t-test ## ## data: before - after ## t = -9.3296, df = 9, p-value = 6.356e-06 ## alternative hypothesis: true mean is not equal to 0 ## 95 percent confidence interval: ## -5.415186 -3.301613 ## sample estimates: ## mean of x ## -4.358399 1.9.6 ANOVA (variansanalyse) Har man flere grupper i stedet for to, kan man bruge ANOVA (analysis of variance eller variansanalyse). For en kategorisk variabel med \\(k\\) grupper, er nul/alternativhypotesen: \\(H_{0}: \\mu_{1} = \\mu_{2} = \\ldots = \\mu_{k}\\) \\(H_{1}:\\) ikke alle middelværdier er enes #simulere data til 3 forskellige grupper fra den normale fordeling med standard afvigelse af 3 group1 &lt;- rnorm(50,10,3) group2 &lt;- rnorm(55,10,3) group3 &lt;- rnorm(48,5,3) #data må være i en dataramme, med den ene kolon = vores værdier, og den anden kolon = grupper y &lt;- c(group1,group2,group3) x &lt;- c(rep(&quot;G1&quot;,50),rep(&quot;G2&quot;,55),rep(&quot;G3&quot;,48)) mydf &lt;- data.frame(&quot;group&quot;=x,&quot;value&quot;=y) Til at udføre testen bruger man funktionen lm. Det er en forkortelse for “linear model” og kan bruges til at bygge op forskellige modeller. Her angiver vi en model, således at hver group (G1, G2 og G3 fra variablen x) har sin egen middelværdi (variablen value), hvilket er modellen under alternativhypotesen: mylm &lt;- lm(value~group,data=mydf) #H1 model Under nullhypotesen har alle grupper den samme middelværdi og vi behøver derfor ikke at have variablen group en del af modellen. Vi betegner situationen i modellen ved at skrive 1, der betyder at de forventede værdier for den afhængige variabel value er bare dens middelværdi: mylm_null &lt;- lm(value~1,data=mydf) #H0 model For at sammenligne de to modeller benytter vi funktionen anova (efter analysis of variance): anova(mylm_null,mylm) ## Analysis of Variance Table ## ## Model 1: value ~ 1 ## Model 2: value ~ group ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 152 2215.4 ## 2 150 1509.9 2 705.55 35.047 3.245e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 P-værdien er (&lt;0.05), så nulhypotesen er forkastet til fordel af alternativhypotesen, altså modellen, hvor hver gruppe har sin egen middelværdi. Bemærk at det er til trods af, at to af de tre grupper kommer fra en normal fordeling med præcis de samme middelværdier (det er nok, at den trejde gruppe har en ænderledes middelværdi). 1.9.7 Lineær regression OBS: se også video i forbindelse med Rmarkdown (næste emne), hvor jeg gennemgå lineær regression med R Formål: måler (en retningsbestemt) relation mellem to kontinuerte variabler. I simpel lineær regression svarer det til, at man gerne vil finde den rette linje gennem punkterne, der bedste beskriver relationen. Eksempel - datasættet mtcars, response (afgængig) variabel er mpg og predictor (uafhængig) variabel er wt. Man skriver relationen i R som mpg ~ wt og benytter lm()(lm(mpg~wt,data=mtcars)): mylm &lt;- lm(mpg ~ wt, data=mtcars) # build linear regression model mylm ## ## Call: ## lm(formula = mpg ~ wt, data = mtcars) ## ## Coefficients: ## (Intercept) wt ## 37.285 -5.344 Vores “Coefficients” beskriver den bedste rette linje: Skæringen (intercept): 37.285 Hældningskoefficient (slope): -5.344 Det betyder, at hvis vægten wt af en bil stiger med 1, så stiger mpg ved -5.344 (det vil sige at mpg reduceres med 5.344). 1.9.8 R-squared coefficient of determination Den \\(R^2\\) eller “forklaringsgraden” (coefficeint of determination) har til formål at forklare, hvor godt vores lineær model passer til de data. For eksempel hvor meget af variansen i mpg forklares af variablen wt? Hvis det er tæt på 1 - så er der en meget tæt relation (hvis man kender vægten, så vide man også mpg med stor sikkerhed) Hvis det er tæt på 0 - så er relationen svag - høj sandsynlighed for, at der er andre variabler der bedre kan forklare variansen i mpg. I ovenstående model, kan man se den \\(R^2\\) værdi med summary(mylm). summary(mylm) ## ## Call: ## lm(formula = mpg ~ wt, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.5432 -2.3647 -0.1252 1.4096 6.8727 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 37.2851 1.8776 19.858 &lt; 2e-16 *** ## wt -5.3445 0.5591 -9.559 1.29e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.046 on 30 degrees of freedom ## Multiple R-squared: 0.7528, Adjusted R-squared: 0.7446 ## F-statistic: 91.38 on 1 and 30 DF, p-value: 1.294e-10 Det fortæller os, at \\(R^2\\) = 0.7528. 1.9.9 Antagelser - lineær regression Normalfordelte residualer Residualer har samme spredning (varianshomogenitet) Uafhængighed Fit er linæer Koden plot(mylm,which=c(1)) angiver residualer vs predikterede (fitted) værdier - de skal være tilfældigt fordelt over plottet og prikkernes varians skal være nogenlunde konstant langt x-aksen (det giver, at den røde linje er flade). plot(mylm,which=c(1)) Med koden plot(mylm,which=c(2)) kan man tjekke antagelsen på en normal fordeling. Punkterne skal være nogenlunde tæt på den diagonale linje. plot(mylm,which=c(2)) 1.9.10 Multiple lineær regression Her kan man tilføje flere variabler i vores model formel. mylm_disp &lt;- lm(mpg ~ wt + disp, data=mtcars) # build linear regression model summary(mylm_disp) ## ## Call: ## lm(formula = mpg ~ wt + disp, data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -3.4087 -2.3243 -0.7683 1.7721 6.3484 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 34.96055 2.16454 16.151 4.91e-16 *** ## wt -3.35082 1.16413 -2.878 0.00743 ** ## disp -0.01773 0.00919 -1.929 0.06362 . ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.917 on 29 degrees of freedom ## Multiple R-squared: 0.7809, Adjusted R-squared: 0.7658 ## F-statistic: 51.69 on 2 and 29 DF, p-value: 2.744e-10 Her kan man se, at med tilføjelsen af variablen disp, er \\(R^2\\) steget til 0.7809. Bemærk, at jo flere variabler man tilføjer til modellen, jo større bliver \\(R^2\\)-værdien. Den adjusted \\(R^2\\) værdi er lavere fordi den prøver at tage højde for kompleksiteten af modellen (hvor mange parametre der er). Variablen disp er faktisk ikke selv signifikant når der er taget højde for variablen wt (p-værdien 0.0636 - tjek, at du selv kan finde værdien i resultatet). Hvis en af de uafhængige variabler er kategorisk bruger man funktionen anova til at teste den overordnet effekt af den variabel. For eksempel har variablen cyl 3 mulige værdier (niveauer) - 4, 6 og 8. Vi kan inddrage variablen i vores model: –&gt; mylm_cyl &lt;- lm(mpg ~ wt + factor(cyl), data=mtcars) # build linear regression model summary(mylm_cyl) ## ## Call: ## lm(formula = mpg ~ wt + factor(cyl), data = mtcars) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.5890 -1.2357 -0.5159 1.3845 5.7915 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 33.9908 1.8878 18.006 &lt; 2e-16 *** ## wt -3.2056 0.7539 -4.252 0.000213 *** ## factor(cyl)6 -4.2556 1.3861 -3.070 0.004718 ** ## factor(cyl)8 -6.0709 1.6523 -3.674 0.000999 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.557 on 28 degrees of freedom ## Multiple R-squared: 0.8374, Adjusted R-squared: 0.82 ## F-statistic: 48.08 on 3 and 28 DF, p-value: 3.594e-11 Man kan ikke se den overordnet effekt af cyl fra den ovenstående summary men man kan teste den med anova: anova(mylm,mylm_cyl) ## Analysis of Variance Table ## ## Model 1: mpg ~ wt ## Model 2: mpg ~ wt + factor(cyl) ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 30 278.32 ## 2 28 183.06 2 95.263 7.2856 0.002835 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Så kan man se, at cyl er signifikant. 1.10 Problemstillinger Lav quizzen og ellers vælg øvelser efter egen erfaring: 2-8 er meget grundlæggende og de fleste kan springer over hvis nogenlunde tryg med base-R 9-15 anbefaler jeg til alle som en god måde at tjekke viden på 16-20 øver hvordan man andre statistiske teste i R - regression kommer jeg ind på igen senere men det hjælper hvis du er tryg med brugen af funktionen lm til at lave modeller i ANOVA/simpel lineær regression (se også video og problemstillingerne i morgen). 1.10.1 Quiz - Basics 1) Se quiz i Absalon, der hedder “Quiz - Basics.” 1.10.2 Grundlæggende R 2) (helt baserende viden) Åbn en ny fil i Rstudio ved at trykke på “File” &gt; “New File” &gt; “R script.” Køre følgende kode en linje ad gangen og tjek, du kan forstå outputtet. Husk at den nemmeste måde at køre kode er ved at trykke CMD+ENTER (Mac) eller WIN-KEY+ENTER (Windows). 2+2 2*2 x &lt;- 4 x &lt;- x+2 sqrt(x) sqrt(x)^2 rnorm(10,2,2) log10(100) y &lt;- c(1,4,6,4,3) class(y) class(c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;)) mean(y) sd(y) seq(1,13,by=3) 3) (helt baserende viden) Køre følgende kode til at åbne nogle af de indbygget datasæt, som vi bruger i kurset. * Prøve head(), nrow(), summary() osv. * Prøve også fk. ?cars for at se en beskrivelse. data(iris) data(cars) data(ToothGrowth) data(sleep) head(chickwts) data(trees) #se her for andre: library(help = &quot;datasets&quot;) 4) (baserende plots) Jeg giver nogle muligheder for datasættet “iris.” Afprøve funktionerne for nogle af de andre ovenstående indbygget datasæt, som du indlæst. plot(iris$Sepal.Length,iris$Sepal.Width) hist(iris$Sepal.Width) boxplot(iris$Sepal.Length~iris$Species) Man kan også gøre plotterne lidt pænere ved at give dem en titel/aksen-navne osv. Prøve ?plot for at se nogle muligheder, og tilføje ylab, xlab, main (titel) i én af plotterne. Leg også med col (farver). Bemærk dog, at vi kommer til at ændre måden at lave plotter på når vi starter ggplot2. 5) (dataframes) Brug datasættet cars (data(cars)) til at: Lav et scatter plot med speed på x-aksen og dist på y-aksen Tilføj en ny kolon med følgende kode: cars$fast &lt;- cars$speed&gt;15 Brug mean på den nye variabel til at finde ud af proportionen af biler, der er hurtige Beregn gennemsnitsværdien af variablen dist for hurtige biler og ikke-hurtige biler hver for sig (brug funktionen tapply). Gem resultatet med &lt;-. Brug barplot til at lave et plot af den gennemsnitlige dist for hurtige og ikke-hurtige biler. 6) (dataframes) Lav en ny dataframe (funktionen data.frame()) med tre kolonner som hedder “navn,” “alder” og “yndlings_farve” (find bare selv på værdierne). Sørge for, at den har 4 rækker. mydf &lt;- data.frame(&quot;navn&quot;= c(&quot;alice&quot;,&quot;freddy&quot;, ... ), &quot;alder&quot; = c(...), ...) #not run, slette &quot;...&quot; og skrive videre dim(mydf) # fire række og tre kolonner mydf 7) (dataframes) Tilføj en ny variabel random til ovenstående dataframe, hvor værdierne kommer fra en normal fordeling med et gennemsnit på 5 og sd på 1 (bruge funktionen rnorm). mydf$random &lt;- #?? 8) (delmængder af dataframes) Åbn datasættet “ToothGrowth” med følgende kode: data(&quot;ToothGrowth&quot;) ?ToothGrowth Find delmængden af datasættet således at diet (variablen supp) er “OJ” og længden (variablen len) er større end 15. newdf &lt;- ToothGrowth[#skrive her til at lave subset af observationerne,] Hvor mange rækker er der i den nye dataframe newdf? Hvor mange unikke værdier er der i variablen dose (brug funktionen unique) ? Find delmængden af datasættet ToothGrowth, hvor variablen dose er 0.5 eller 1.5 (hint: brug %in% eller |) og supp er “VC.” Beregn den gennemsnitlige længde for observationerne i delmængden. 1.10.3 Kort analyse med reaktionstider 9) (indlæse data) Åbn en fil, der sidder i Absalon og hedder “reactions.txt” ved at bruge funktionen read.table() (kalde det for data). Husk at tjekke, om selve filen har variabelnavne og bruge således header=T hvis nødvendigt. data &lt;- ... #replace ... 10) (factor variabler) Variablerne subject og time indlæses som henholdvis data type ‘int’ (heltal) og “chr” (character) men de skal hellere være ‘factor’ variabler. Lav dem om til facktor variabler. #gør subject til en faktor data$subject &lt;- as.factor(data$subject) ## gør den samme her for time: Hvor mange niveauer er der i hver af de to variabler? 11) (delmængde af dataframe) Lav to delmængder af ovenstående datasæt - én til alle observationer fra tidspunktet “before” (brug koden data$time ==\"before\" til at udvælge rækkerne fra dataframe) og én til alle observationer fra tidspunktet “after.” RT_before &lt;- data[#skrive her , ] RT_after &lt;- #skrive her Brug RT_before og lav en delmængde der viser alle observationer fra tidspunktet “before” med en rekationstid af mindst 800. Hvor mange personer opfylder kriteren? RT_before_mindst800 &lt;- #skrive her 12) (mean og tapply) Benyt funktionen mean til at beregne den gennemsnitlige reaktionstid (variablen RT) til “before” og “after” hver for sig (brug ovenstående delmængder). Prøv også at anvende funktionen tapply på det oprindelige datasæt data til at beregene samme middelværdi med mindre kode. tapply(#skrive her,#skrive her,#skrive her) Er reaktionstiderne blevet hurtigere eller langsommere i gennemsnit? 13) (beregn forskellen og mean) Bemærk, at datasættet er ‘paired’ - målingerne er lavet på de præcis samme personer både “before” og “after.” Opret en vector diff, der er ændringen i reaktionstiderne mellem personerne “before” og “after.” Beregn den gennemsnitlige forskel i rekationstiderne. diff &lt;- #change in reaction time between before and after mean(diff) Tjek tegnet stemmer overens med din konklusion fra 11) - hvis den er positiv, så betyder det, at reaktionstiderne er blevet langsommere. 14) (lav t-test i R) Lav en t-test (funktionen t.test) for at teste hypotesen at den gennemsnitslige forskel i reaktionstiderne mellem “before” og “after” er anderledes end 0. t.test(#skrive her..) Find følgende i outputtet fra R: Hvor er test-statistik t? Hvor er p-værdien? Hvad er alternativhypotesen? 15) Skriv en kort sætning med din konklusion. 1.10.4 Ekstra øvelser med statistik tests 16) (Chi-sq) Kør følgende kode til at få en tabel (selve koden er ikke vigtigt): mytable &lt;- structure(c(80L, 97L, 372L, 136L, 87L, 119L), .Dim = 3:2, .Dimnames = structure(list( c(&quot;First&quot;, &quot;Second&quot;, &quot;Third&quot;), c(&quot;Died&quot;, &quot;Survived&quot;)), .Names = c(&quot;Class&quot;, &quot;Survival&quot;)), class = &quot;table&quot;) mytable ## Survival ## Class Died Survived ## First 80 136 ## Second 97 87 ## Third 372 119 Tabellen omhandler personer ombord skibet ‘Titanic’ (der sank den 15. april 1912 efter et sammenstød med et isbjerg 600 km sydøst for Halifax, Nova Scotia i Canada). Tabellen angiver hvor mange passagerer tilhørte de tre klass (førsteklass, andenklass, trejdeklass), delte efter overlevelsesudfald (døde eller overlevede tragedien). Benyt funktionen chisq.test() på tabellen. Hvad er nulhypotesen? Overlevelsesudfald er uafhængig af klass Er testen signifikant? p-value &lt; 2.2e-16 - ja Er passagerernes klass så uafhængige af deres chance for at overleve tragedien? Jeg forkaster nulhypotesen og konkluderer de to variabler afhængige af hinanden Hvilken klass havde den bedste chance for at overleve? Førsteklass = meget højere chance Vi kommer til at arbejde meget mere med datasættet Titanic i emnet Tidyverse - dag 1! 17) (Korrelation analyse) Åbn datasættet trees og lav et scatter plot med variablen Girth på x-aksen og variablen Volume på y-aksen. data(trees) summary(trees) Anvend funktionen cor.test for at teste, om der er en signifikant korrelation mellem de to variabler. Brug method = \"pearson\" (det er dog faktisk default) cor.test(???, ???,method=&quot;pearson&quot;) Hvad er korrelationen mellem Girth og Volume? Hvad er p-værdien? Er den signifikant? 18) (ANOVA) OBS: hvis du føler dig utryg med funktionen lm() - der kommer en video om det i morgen (i forbindelse med emnet Rmarkdown). Kør følgende kode til at lave variansanalyse, der tester hulhypotesen hvor den gennemsnitlige værdi af variablen Sepal.Width er ens for hver af de tre arter (variablen Species) fra datasættet iris: data(iris) #model under H0: no difference according to group variable Species (1 just means &quot;fit overall mean&quot;) model_h0 &lt;- lm(Sepal.Width ~ 1, data=iris) #model under H1: each level of group variable Species has its own mean model_h1 &lt;- lm(Sepal.Width ~ Species, data=iris) #compare two models - significant p-value equates to choosing H1 model anova(model_h0,model_h1) ## Analysis of Variance Table ## ## Model 1: Sepal.Width ~ 1 ## Model 2: Sepal.Width ~ Species ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 149 28.307 ## 2 147 16.962 2 11.345 49.16 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Kig på outputtet: Hvilken model reflekterer nulhypotesen? Hvilken model reflekterer alternativhypotesen? Hvor er p-værdien? Er der en signifikant forskel i den gennemsnitlige Sepal.Width efter de forskellige Species? Brug funktionen tapply for at finde ud af, hvad er den middelværdi Sepal.Width til hver af de tre arter. 19) (ANOVA) Lav en lignende analyse på datasættet chickwts for at svare på spørgsmålet: Er der en forskel i den gennemsnitlige vægt (variablen weight) efter fodertypen (variablen feed)? Med andre ord er vægt afhængig af fodertypen? data(chickwts) Valgfri - vi gennemgår også lineær regression i morgen og du kan altid komme tilbage senere hvis du har bruge for det 20) (Lineær regression) Brug lm til at lave en simpel lineær regression, således at respons variablen Volume er afhængig af variablen Girth (datasæstet trees). mylm &lt;- lm(???, data=trees) Brug summary på din model for at finde følgende værdier: Hvad er r.squared? (multiple) Er variablen Girth signifikant? Hvad er ligningen på den bedste rette linje (husk formen y = ax + b)? 21) (Kort intro til multiple lineær regression) Tag ovenstående model og tilføj variablen Height som en ekstra prediktær (uafhængig) variabel i modellen med en “+” tegn: mylm_height &lt;- lm(??? ~ ??? + ???, data=trees) summary(mylm_height) Bemærk at det ikke betyder, at de to variabler skal lægges sammen, men at vi gerne vil have både variablerne i modellen som uafhængig variabler (med andre ord er Volume afhængig af både Girth og Height). Benyt summary på modellen og prøv at finde følgende: Hvad er den den (multiple) r.squared værdi? Hvor meget ændre den (multiple) r.squared værdi i forhold til modellen med kun variablen Girth? Er Volume signifikant afhængig af Height (efter at man har taget højde for Girth)? Brug funktionen anova til at sammenligne modellen uden Height med modellen med Height anova(#model without height,#model with height) Bemærk, at i dette tilfælde er p-værdien fra ANOVA samme p-værdi fra summary(mylm_height). "],["rmarkdown.html", "Chapter 2 Introduktion til R Markdown 2.1 Hvad er R Markdown? 2.2 Installere R Markdown 2.3 Videodemonstrationer 2.4 Oprette et nyt dokument i R Markdown 2.5 Skrive baseret tekst 2.6 Knitte kode 2.7 Kode chunks 2.8 R beregninger indenfor teksten i dokument (‘inline code’) 2.9 Working directory 2.10 Matematik 2.11 Problemstillinger 2.12 Færdig for i dag og næste gang 2.13 Ekstra links", " Chapter 2 Introduktion til R Markdown I dag begynder vi at arbejde med R Markdown. Selve emnet er relativt kort og er designet til, at du kan komme i gang med at bruge R Markdown i praksis, men notaterne referere også til nogle ekstra muligheder så du kan indrette dit dokument efter eget ønske. Der er to videoer - én er en ‘quick-start guide’ for at komme i gang, og den anden viser en simpel lineær regression i R Markdown - har du ikke brug for lidt genopfriskning, kan man også se mere om funktionaliten i R Markdown. Efter quizzerne og problemstillinger er der en worksheet, hvor du kan øve dig videre med de typer opgaver vi kommer til at se i workshopperne. Fra næste gang (fredag) skifter vi emnet til visualiseringer i ggplot2, og vi arbejder naturligvis i R Markdown fremadrettet. 2.1 Hvad er R Markdown? R Markdown er både en nem og fleksibel måde at arbejde med R til projekter på. Her kan du kombinere din R-kode, output og tekst i samme dokument, og derudover fremviser et pænt HTML dokument fra det, som potentielt kan deles med andre. Jeg anbefaler at du bruger R Markdown til alle opgaverne i kurset og ved eksamen forventer jeg at du afleverer et HTML dokument til mig med din “knittede” kode fra din analyse. 2.2 Installere R Markdown R Markdown er, ligesom R, gratis og ‘open source.’ Den fungerer indenfor RStudio and kan installeres ved at bruge den følgende kommando: install.packages(&quot;rmarkdown&quot;) 2.3 Videodemonstrationer Jeg har lavet to videoer som kan ses her: Video 1: Jeg viser hvordan man laver et nyt dokument i R Markdown hvordan man skriver tekst ind i dokumentet hvordan man bruger “knit” til at lave et HTML-dokument hvordan man opretter og kører kode chunks Link her hvis det ikke virker nedenunder: https://vimeo.com/702416505 Video 2: Jeg viser en kort lineær regression analyse: Indlæse datasæt og lave plot af datasættet Lynhurtig gennemgåelse af ligningen for rette linje Hvordan man anvender funktionen lm() til at fitte en lineær model Fortolkelse af resultaterne Link her hvis det ikke virker nedenunder: https://vimeo.com/701240044 2.4 Oprette et nyt dokument i R Markdown Man åbner et nyt rmarkdown dokument ved at trykke “New” &gt; “New File” &gt; “New R Markdown….” Man kan også trykke på “+” knappen øverst til venstre hjørne. Hvordan man åbner et nyt R Markdown dokument Dernæst angiver man en titel (det kan ændres senere hvis der er bruge for det) og bekræfter, at outputtet kommer i HTML form. I kurset arbejdes der kun med HTML dokumenter, men man har også andre muligheder, som du er velkommen til at afprøve (PDF/Word/Shiny osv…). Hvordan man åbne et nyt R Markdown dokument 2.4.1 YAML Den første sektion af dokument skrives i hvad der kaldes for ‘YAML.’ (Dette står for ‘YAML Ain’t Markup Language’). Hvordan man åbner et nyt R Markdown dokument Det indeholder oplysninger om dokumentet, og her kan man specificere forskellige muligheder - fk. titel, forfatter, output-type (fks. HTML eller PDF), dato, osv. I de fleste tilfælde nøjes vi med at bruge standard indstillinger, men hvis man gerne vil lære mere om de forskellige muligheder med YAML, kan man læse her: https://bookdown.org/yihui/rmarkdown/html-document.html eller se en liste af muligheder her på dette cheatsheet: https://www.rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf 2.4.2 Globale options Der er også tekst som ser ud som følgende: Hvordan man åbner et nyt R Markdown dokument Med funktionen opts_chunk$set() kan man specificere de globale indstillinger, som styrer hvordan det færdige dokument ser ud. I dette tilfælde er de fleste parametre angivet som ‘default’ (da de ikke er nævnt eksplicit), og echo er den eneste der har noget angivet. Hvis echo er TRUE, så betyder det, at når man “knitter” sin kode (processen, der få et HTML dokument frem, se nedenfor), så kan man også se koden, der blev kørt, samt dens output, i det færdige HTML dokument, der kommmer frem. 2.5 Skrive baseret tekst Her er nogle brugbare muligheder for at skrive tekst i opgaverne eller rapporter: *italic* **bold** _italic_ __bold__ italic bold italic bold 2.5.1 Headers Man kan også lave sektioner: # Header 1 ## Header 2 ### Header 3 Caption for the picture. 2.5.2 liste * Item 1 * Item 2 + Item 2a + Item 2b Item 1 Item 2 Item 2a Item 2b 2.6 Knitte kode Man bruger Knit for at gengive filen i HTML form. Når man trykker på knappen Knit, bliver samtlige koder i filen kørt og et HTML dokument fremvises. Bemærk, at koderne bliver kørt på ny hver gang man knitter, uden hensyn til hvad du har i din nuværende workspace i RStudio. Det betyder, at hvis du eksempelvis har pakken tidyverse indlæst på din computer men har glemt at skrive library(tidyverse) eksplicit på toppen af dit dokument, så får du en fejlmeddelelse hvis du bruger tidyverse-baserede funktioner nogle steder. 2.7 Kode chunks Man skriver selve R kode indenfor hvad der kaldes for “chunks.” Man kan oprette en ny chunk på flere måder - enten ved at trykke på den Insert a new code chunk knap ovenpå, eller ved at trykke Cmd+Option+I på tastaturet (hvis man bruger MAC) eller Ctrl+Alt+I (hvis man bruger Windows). Det er værd at huske den keyboard-shortcut - det sparer meget tid efter egen erfaring! Her er et eksempel af en chunk: # This is a chunk, let&#39;s write som R code x &lt;- 1 x + 1 ## [1] 2 For at køre en chunk, trykker man på den grønne pile øverste i højre hjørne på selve chunk (der hedder Run Current Chunk når du holder musen over den). Resultatet kan ses lige nedenunder, som i ovenstående. Bemærk, at når du arbejde med dit R Markdown dokument er det generelt hurtigere at bruge den grønne pile / Run Current Chunk i stedet for at knitte hele dokumentet hver gang man vil køre kode. Det er fordi her kører man kun den enkel chunk i stedet for hele dokumentet på ny (herunder indlæsning af pakker og eventuelle store filer), som er tilfældet med Knit. 2.7.1 Et godt råd når man arbejder med chunks Til længere opgaver er det god praksis at sikre jævnligt, at man kan få et HTML dokument frem ved at knitte, selvom du kører din chunks lokalt mens du udvikler din kode - det vil sige, at du ikke få en alvorlig fejlmeddelelse, der forhindre din koder at knitte. Det er dit ansvar at sikre, at din kode fungerer som helhed og du kan dermed producere et HTML dokument med din løsninger. 2.7.2 Chunk indstillinger I R Markdown er der mange muligheder for at styre hver eneste chunk i dit dokument - hvordan skal R håndtere koden med hensyn til evaluering og præsentering (især med hensyn til tabeller og plotter) af en bestemt chunk i dit dokument? Det kommer meget an på, hvem du gerne vil viser dit dokument til. For eksempel, i nuværende kursusnotater vil jeg gerne have generelt, at du ser alle min kode (en global indstilling), men nogle gange vil jeg foretrækker noget andet - en chunk som viser noget jeg ikke vil have kørt, eller ændre på størrelsen af et plotte i en bestemt chunk. For eksempel, en chunk med indstillingen eval=FALSE ser sådan ud (fjerne # symbol) #```{r,eval=FALSE} # #``` Her er nogle muligheder (sektionen “Embed code with knitr syntax”): https://www.rstudio.com/wp-content/uploads/2016/03/rmarkdown-cheatsheet-2.0.pdf Her er seks populær muligheder som jeg har kopiret fra nettet: include = FALSE prevents code and results from appearing in the finished file. R Markdown still runs the code in the chunk, and the results can be used by other chunks. echo = FALSE prevents code, but not the results from appearing in the finished file. This is a useful way to embed figures. message = FALSE prevents messages that are generated by code from appearing in the finished file. warning = FALSE prevents warnings that are generated by code from appearing in the finished. fig.cap = \"...\" adds a caption to graphical results. eval = FALSE does not evaluate the code 2.8 R beregninger indenfor teksten i dokument (‘inline code’) I nogle tilfælde vil man køre R kode “inline,” det vil sige, direkte indenfor teksten, ekempelvis indenfor en sætning. Dette gøres ved at skrive på følgende måde: Her er min `kode` Ovenstående ser sådan ud når skrevet direkte indenfor teksten: Her er min kode I dette tilfælde, er der ikke noget R kode som er blevet kørt. Hvis man vil køre R kode indenfor teksten skriver man (for eksempel): De gennemsnitlige antal af observationer er `r mean(c(5,7,4,6,3,3))` Ovenstående ser sådan ud når skrevet direkte indenfor teksten: De gennemsnitlige antal af observationer er 4.6666667 Og bemærk, at hvis man glemmer ‘r,’ så bliver koden ikke kørte: De gennemsnitlige antal af observationer er `mean(c(5,7,4,6,3,3))` giver: De gennemsnitlige antal af observationer er mean(c(5,7,4,6,3,3)) Brugen af kode inline kan være en kæmpe fordel når man gerne vil skrive noget om an analyse, hvor man referere til forskellige statistik beregninger som man har beregnet i R (eksempelvis en middelværdi eller p-værdi). Hvis man skriver eller kopier et tal direkte og datasættet eller analysemetoden ændre sig på en eller anden grund, så bliver beregningerne indenfor teksten ikke opdateret, og så risikerer man at have en fejl i den endelige rapport. Bruger man inline code, så er beregningerne opdateret automatiske, uden at tænke over det. 2.9 Working directory Bemærk at den måde man sætter en working directory er ændleredes i R Markdown i forhold til base-R. Hvis man bruger setwd() i en chunk, sætter man kun den working directory i den pågælende chunk og ikke i de efterfølgende chunks. I R Markdown er standarden (default), at din working directory er mappen som du gemmer din .Rmd fil. Hvis du genre vil bruge noget andet, kan du tilføje knitr::opts_knit$set(root.dir = '/tmp') til din globale indstillinger chunk på toppen af din fil, hvor '/tmp' skal ændres til din ønskede mappe. ```{r, setup, include=FALSE} knitr::opts_knit$set(root.dir = &#39;/tmp&#39;) ``` 2.10 Matematik Man kan også skrive matematik (Latex) i R Markdown - eksempelvis $\\int_0^5 x^2 dx$ vil ser ud som \\(\\int_0^5 x^2 dx\\) i dit HTML dokument. Jeg forventer ikke at du lære Latex men det er af og til brugbart - for eksempel en rette linje ligning er $y = 3.4x + 2.1$ giver \\(y = 3.4x + 2.1\\) eller en hypotese: $H0: \\mu = 0$ giver \\(H0: \\mu = 0\\). Det er op til dig hvor meget du bruger matematik måde i dine egne dokumenter. 2.11 Problemstillinger Der er en kort quiz i Absalon, som hedder “Quiz - R Markdown.” Lav et nyt R Markdown dokument i RStudio. Prøve at lave en list og nogle overskrifter i forskellige størrelser. Nu tryk på Knit knappen og tjek at et HTML-dokument fremvises på din skærm. Rediger på titlen (den er en del af din YAML-header oppe på toppen af din fil) - kald dit dokument for “My first R Markdown document,” og tryk på Knit igen for at se ændringen i dit HTML dokument. Opret en ny R-chunk, og tilføj noget kode, eksempelvis x &lt;- rnorm(20,1,2) #make a sample of normally distributed data plot(x) husk shortcut CMD+OPT+I eller CTRL+WIN+I når man oprette en chunk (det sparer tid) tryk på den grønne pile prøve også at køre en linjen ad gangen med CMD+Enter/CTRL+Enter lav flere chunks med adskillige kode som du vælger tryk på knit og bemærk, at det tager længere tid at knit hver eneste gang man ændre noget, end når man bare kører chunks individ indenfor dit dokument Tryk på “hjulen”-knappen i øverste højre hjørne af en af din chunks og prøv at ændre på de forskellige chunk indstillinger. Tryk på ‘knit’ for at se, hvad der sker. Hver gang du knitter, du lave et HTML dokument. Nu prøv at lave en andet type dokument i stedet for - erstatte html_document med word_document i YAML (toppen af din .Rmd fil) Se her for endnu flere muligheder: https://bookdown.org/yihui/rmarkdown/output-formats.html Tilføj følgende chunk til dit dokument og tryk på “knit.” Få du en fejlmedelse? data(mtcars) mtcars %&gt;% filter(cyl==6) Bemærk, at du får en fejlmeddelse fordi, du endnu ikke har indlæst den påkrævet pakke til at få koden til at virke. Det kan ske, selvom du måske har indlæste pakken i Console eller i Packages tab. Først prøve at køre “library(tidyverse)” indenfor Console og dernæst prøve at knitte dit dokument igen - du får stadig en fejmeddelse. Tilføj library(tidyverse) øverst i din chunk. Nu bør dit dokument knitte. Erstat linjen output: html_document med følgende i din YAML metadata oppe i toppen af din .Rmd fil: output: html_document: code_folding: hide Knit og se hvad, der sker. Erstat hide med show og kig på forskellen. Brug $ $ til at skrive en ligning ind i teksten i din .Rmd fil. Prøv for eksempel $\\bar{x}_{i} = \\frac{1}{n}\\sum_{i=1}^{n} x_{i}$ og knitte dit dokument for at tjekke, om du får formlen til middelværdien. (Worksheet) Ind på Absalon har jeg lagt en R Markdown (.Rmd) fil som hedder “R Markdown opgave,” som du kan bruge til at starte med at arbejde med R Markdown baserede opgaver. Det kombinerer koncepter fra det forudgående kapitel om de grundlæggende ting i R og statistik. 2.12 Færdig for i dag og næste gang Husk at sende mig eventuelle spørgsmål, som jeg kan svare på enten direkte eller i forelæsning næste gang. Næste gang begynder vi at arbejde vi med R-pakken ggplot2, der bruges til at lave høj kvalitet visualiseringer fra datasæt. 2.13 Ekstra links Her er en ‘quick tour’ https://rmarkdown.rstudio.com/authoring_quick_tour.html Handy R Markdown Cheatsheet: RStudio has published numerous cheatsheets for working with R, including a detailed cheatsheet on using R Markdown! The R Markdown cheatsheet can be accessed from within RStudio by selecting Help &gt; Cheatsheets &gt; R Markdown Cheat Sheet. "],["visual1.html", "Chapter 3 Visualisering - ggplot2 dag 1 3.1 Inledning og videoer 3.2 Transition fra base R til ggplot2 3.3 Vores første ggplot 3.4 Lidt om ggplot2 3.5 Specificere etiketter og titel 3.6 Ændre farver 3.7 Ændre tema 3.8 Forskellige geoms 3.9 Troubleshooting 3.10 Problemstillinger 3.11 Næste gang", " Chapter 3 Visualisering - ggplot2 dag 1 3.1 Inledning og videoer Dette kapitel giver en introduktion til hvordan man visualiserer data med R-pakken ggplot2. 3.1.1 Læringsmålene for dag 1 I skal være i stand til at: Forstå hvad “Grammar of Graphics” betyder og sammenhængen med den ggplot2-pakke Lære at bruge funktionen ggplot og den relevante geoms (geom_point(), geom_bar(), geom_histogram(), geom_boxplot(), geom_density()) Lave en ‘færdig’ figur med en titel og korrekte etiketter på akserne Begynde at arbejde med farver og temaer 3.1.2 Hvad er ggplot2? De fleste i kurset har anvendt funktionen plot(), der er den standard base-R funktion til at lave et plot. Man kan godt blive ved med at lave plotter i base-pakken, men det er ofte meget tidskrævende så snart man gerne vil lave noget mere indviklet eller pænere. En alternativ løsning er pakken ggplot2, som står for “grammar of graphics” (se nedenunder for nærmere forklaring). ggplot2 er den meste populær pakke fra tidyverse, og som vi kommer til at se i dette kapitel, har den en ret logisk tilgang, hvor man opbygger et plot i forskellige komponenter. Det kan virke uoverskueligt i første omgang, men er faktisk meget intuitiv når man er vant til det. Det nyttige i at lære ggplot2 kan også ses når man begynder at integrere de øvrige tidyverse pakker fra kapitel 4. 3.1.3 Brugen af materialerne Jeg har optaget videoer hvor jeg viser nogle ‘quick-start’ type eksempler indenfor min RStudio. Videoerne er ikke designet til at indeholde alle detaljer, men til at fungere som udgangspunkt til at kunne komme i gang med øvelserne. Vær opmærksom på, at alle koder i videoerne findes også i kursusnotaterne, hvis du selv vil afprøve dem. Jeg anbefaler at du bruger kursusnotaterne som en reference gennem kurset når man arbejder på opgaverne, og vær også opmærksom på, at jeg nogen gange introducerer nye ting i selve øvelserne. 3.1.4 Video ressourcer I video 1 demonstrerer jeg, hvordan man lave sit første plot med ggplot2. Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/701245598 I video 2 dækker vi boxplots. Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/701245695 I video 3 demonstrerer jeg barplots. Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/704025240 Video 4: Histogram og density plots Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/703699213 3.2 Transition fra base R til ggplot2 Vi starter som udgangspunkt med base-R og viser, hvordan man laver et lignende plot med ggplot2. Til dette formål bruger vi det indbyggede datasæt, der hedder iris. Det er et meget berømt datasæt, og det er næsten sikkert, at du støder ind (eller har stødt ind) i det mange gange uden for dette kursus, enten på nettet eller i forbindelse med andre kurser som handler om R. Datasættet var oprindeligt samlet af statistikker og biologer Ronald Fisher i 1936 og indeholder 50 stikprøver, der dækker forskellige målinger, for hver af tre arter af planten iris (Iris setosa, Iris virginica og Iris Versicolor). Som vi også så i grundlæggende R, kan man indlæse et indbyggede datasæt med hjælp af funktionen data(). data(iris) Først vil vi have et overblik over datasættet. Til at gøre dette bruger vi summary(): summary(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Min. :4.300 Min. :2.000 Min. :1.000 Min. :0.100 ## 1st Qu.:5.100 1st Qu.:2.800 1st Qu.:1.600 1st Qu.:0.300 ## Median :5.800 Median :3.000 Median :4.350 Median :1.300 ## Mean :5.843 Mean :3.057 Mean :3.758 Mean :1.199 ## 3rd Qu.:6.400 3rd Qu.:3.300 3rd Qu.:5.100 3rd Qu.:1.800 ## Max. :7.900 Max. :4.400 Max. :6.900 Max. :2.500 ## Species ## setosa :50 ## versicolor:50 ## virginica :50 ## ## ## Forestil, at vi gerne vil lave et plot, som viser sammenhængen mellem længden og bredden af sepal (bægerblad), eller specifikt er vi interesseret i kolonnerne iris$Sepal.Length og iris$Sepal.Width. Lad os starte med at visualisere variablerne i base-R, ved at bruge plot: plot(iris$Sepal.Length, iris$Sepal.Width) Man kan gøre det meget pænere eksempelvis ved at bruge forskellige farver til at betegne de forskellige arter, eller ved at give en hensigtsmæssig overskrift eller aksenavne. 3.3 Vores første ggplot Vi vil imidlertid fokusere på at lave et lignende plot med pakken ggplot2. Hvis man ikke allerede har gjort det, så husk at indlæse pakken i R for at få nedenstående koder til at virke. #install.packages(&quot;ggplot2&quot;) #hvis ikke allerede installeret library(ggplot2) For at lave et plot med ggplot2 tager man altid udgangspunkt i funktionen ggplot(). Først specificerer vi vores data - altså at vi gerne vil bruge dataframe iris. Dernæst angiver vi indenfor funktionen aes() (som sidder indenfor ggplot()), at x-aksen skal være Sepal.Length og y-aksen Sepal.Width. Det ser sådan ud: ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) Koden fungerer, men bemærk at plottet er helt blank og derfor ikke særligt brugbart. Men der er blevet lavet et grundlag (se aksenavne osv.). Det er blank fordi vi endnu ikke har fortalt, hvilken plot type det skal være - for eksempel søljediagram/barplot, histogram, punktplot/scatter plot (jeg vælge de engelske begreber herfra for at skabe den bedste sammenhæng med koden). Vi vil gerne bruge et scatter plot, som i ggplot2 er angivet af funktionen geom_point(). Vi forbinder derfor funktionen geom_point() til den ggplot() funktion, vi allerede har specificeret. Husk altid, at man bruger + til at forbinde de to “komponenter” (altså ggplot() og geom_point()) af plottet (ellers få vi fortsat et blank plot). Koden er således: ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) + geom_point() Bemærk, at vi ikke har skrevet noget indeni de runde parenteser i funktionen geom_point(). Det betyder, at vi accepterer alle standard eller ‘default’ parametre, som funktionen tager. Hvis vi vil have noget andet end de standard parametre, kan vi godt specificere det. For eksempel kan vi gøre punkterne lidt større end ved standard (prøve at tjekke ?geom_point() for at se en list overfor de mulige parametre, man kan justere på): ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) + geom_point(size=3) Vi har nu et plot, som vi kan sammenligne med det ovenstående plot, vi lavet i base-pakken. Ligesom i base-pakken vil vi gerne tilføje nogle ting for at gøre vores plot til vores færdige figur.. Her i ggplot2 gøres det ved at tilføje flere komponenter ovenpå, med brugen af +, ligesom vi gjorde da vi tilføjede geom_point() til ggplot(). Første vil jeg gerne skrive nogle orde om ggplot2 generelt, og filosofien bag. 3.4 Lidt om ggplot2 3.4.1 Syntax Som vi har lige set, ggplot() tager altid udgangspunkt i en dataframe, som vi specificerer først. I ggplot() indeholder den dataframe variablerne vi skal bruge til at få lavet figuren. Til at gøre det til noget mere konkret, lad os sammenligne koden mellem base-pakken og ggplot() til vores iris data. I base-R angav vi direkte vektorer iris$Sepal.Length og iris$Sepal.Width som parametre x og y, der tager henholdsvis første og andens-plads i funktionen plot(). Til gengæld i ggplot(), specificerer man først den hele dataramme i den første plads, og så bagefter med brugen af aes() angav vi hvordan x-aksen og y-aksen ser ud. #baseplot solution plot(iris$Sepal.Length, iris$Sepal.Width) #ggplot2 solution ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) + geom_point() En anden fordel af ggplot2() er, at man kan blive ved med at forbedre plottet ved at tilføje ting ovenpå det plot, som vi allerede har lavet, i hvad man kan beskriver som en lagring tilgang. Det gøres intuitiv ved brugen af “+.” Man kan derfor starte med noget simpelt, og derefter opbygge det til noget mere kompleks. Dette er uafhængig af den type plot, vi laver. 3.4.2 Hvad betyder egentlig grammar of graphics? Den gg i ggplot2 står for grammar of graphics, og filosofien er at der skal defineres en sætningsstruktur til de figurer, man laver. Med andre ord består vores figur af forskellige komponenter, som man forbinder med “+.” Her er en beskrivelse af de forskellige komponenter til at opbygge et plot: Data: Datarammer tager altid udgangspunkt Aesthetics: Variabler til x-aksen eller y-aksen, farve, form eller størrelse Scale: Scalere værdier eller representere flere værdier Geometries: Eller geoms - hvad type plot skal vi lave - fk. bars, points, lines osv. Statistics: Tilføj fk. mean, median, quartile som beskrive data Facets: Lave subplots baserende på flere dimensioner Coordinate system: Transformerer akser, ændrer afstanden for de viste data 3.4.3 Globale versus lokale æstetik De fleste tilfælde bruger vil funktionen aes() indenfor ggplot(), med betydningen, at variablerne specificeret indenfor aes() gælder globalt over alle komponenter i plottet. Man kan faktisk også skrive aes() lokale indenfor selve geom funktion, som i følgende: ggplot(iris) + geom_point(aes(x=Sepal.Length, y=Sepal.Width)) Vi får det samme plot som før, men det er kun geom_point() der er påvirket af specificeringen indenfor aes(). I simpel situationer som ovenpå er der ingen forskel, men når man har mange forskellige komponenter i spil, så kan det nogle gange give mening at bruge lokale æstetik. 3.5 Specificere etiketter og titel Vi tager udgangspunkt i plottet, vi lavet i ovenstående og prøver at gøre det bedre ved at tilføje nye etiketter og en titel. I ggplot kan man opdatere y-akse og x-akse etiketter ved at bruge henholdsvis ylab og xlab: ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) + geom_point(size=3) + xlab(&quot;Sepal Length&quot;) + ylab(&quot;Sepal Width&quot;) Vi tilføjer en titel med funktionen ggtitle(): ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width)) + geom_point(size=3) + xlab(&quot;Sepal Length&quot;) + ylab(&quot;Sepal Width&quot;) + ggtitle(&quot;Scatter plot of Sepal Width vs Sepal Length&quot;) 3.6 Ændre farver I ggplot2 kan man bruge “automatisk” farver for at skelne imellem de tre forskellige Species i datasættet iris. I næste lektion dækker jeg hvordan man kan være mere fleksibel ved at sætte farver manuelt, men ofte vil vi bare bruge som udgangspunkt den nemme løsning og eventuelle rette op på det bagefter med en ny komponent, hvis der er behov for det. Vi skriver color=Species indenfor aes(), som i følgende. Bemærk, at der kommer en ‘legend’ med, der fortæller os, hvilken art få hvilken farve. ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width,color=Species)) + geom_point(size=3) + xlab(&quot;Sepal Length&quot;) + ylab(&quot;Sepal Width&quot;) + ggtitle(&quot;Scatter plot of Sepal Width vs Sepal Length&quot;) 3.7 Ændre tema Det standard tema har en grå baggrund og “grid” linjer, men vi kan godt vælge noget andet. For eksempel kan man tilføje theme_minimal() som i nedenstående. Her får vi en hvid baggrund i stedet for, mens vi får stadig grid linjer. Man kan afprøve forskellige temaer (for eksempel theme_classic(), theme_bw()), og se, hvilket tema fungerer bedst i det enkelt plot. ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width,color=Species)) + geom_point(size=3) + xlab(&quot;Sepal Length&quot;) + ylab(&quot;Sepal Width&quot;) + ggtitle(&quot;Scatter plot of Sepal Width vs Sepal Length&quot;) + theme_minimal() Her er nogle eksempler på mulige temaer du kan bruge i dine plotter (det er dog generelt op til dig). tema theme_grey() theme_classic() theme_bw() theme_dark() theme_minimal() theme_light() Se også her hvis du er interesseret i flere temaer: https://r-charts.com/ggplot2/themes/ 3.8 Forskellige geoms Indtil videre har vi kun arbejdet med geom_point() for at lave et scatter plot, men det kan være at vi gerne vil lave noget andet. Her gennemgår jeg følgende “geoms”: geom plot geom_point() scatter plot geom_bar() barplot geom_boxplot() boxplot geom_histogram() histogram geom_density() density For at lave disse geoms, skal man tillægge funktionen til den ggplot() kommando med +, ligesom vi gjorde med geom_point(). Der kan dog være for nogle plot-typer specifikke overvejelser, som er værd at vide inden man selv bruger dem. 3.8.1 Boxplot (geom_box) For at lave et boxplot af Sepal.Length opdelt efter Species, angiver vi Species på x-aksen og Sepal.Length på y-aksen. Vi vil også have, at hver art få sin egen farve, så bruger vi fill=Species. ggplot(data=iris, aes(x=Species, y=Sepal.Length,fill=Species)) + geom_boxplot() + ylab(&quot;Sepal Length&quot;) + ggtitle(&quot;Boxplot&quot;) + theme_minimal() Lave punkter ovenpå Det kan ofte være nyttigt at plotte de egentlige data punkter ovenpå boxplottet, så I kan se både fordelingen i de data samt de rå data. En løsning er at benytte geom_point() ved at tilføje det som komponent over vores eksisterende kode. ggplot(data=iris, aes(x=Species, y=Sepal.Length,fill=Species)) + geom_boxplot() + geom_point() + ylab(&quot;Sepal Length&quot;) + ggtitle(&quot;Boxplot with points overlayed&quot;) + theme_minimal() Man kan dog se, at det ikke er særlig informativ, da alle punkter er på den samme lodrette linje. Hvis vi har mange punkter med samme eller næsten samme værdier, så kan vi ikke se de fleste af dem i plottet. En bedre løsning er at indføre noget tilfældighed i punkterne langt x-aksen, så at man mere tydelige kan se dem. Det er kaldes for “jitter” og man specificerer jitter ved at bruge geom_jitter i stedet for geom_point. ggplot(data=iris, aes(x=Species, y=Sepal.Length,fill=Species)) + geom_boxplot() + geom_jitter() + ylab(&quot;Sepal Length&quot;) + ggtitle(&quot;Boxplot with jitter&quot;) + theme_minimal() Jeg kan vi også specificere alpha, som indføre gøre punkterne gennemsigtige, for at gøre dem mindre markant. Man kan også ændre på width som kontrollerer deres spredning langt x-axsen. ggplot(data=iris, aes(x=Species, y=Sepal.Length,fill=Species)) + geom_boxplot() + geom_jitter(alpha=0.5,width=0.2) + ylab(&quot;Sepal Length&quot;) + ggtitle(&quot;Boxplot with jitter and transparency&quot;) + theme_minimal() Fjerne legend hvis unødvendige Man kan se, at når man specificerer farver, få man en legend på højre side af plotte. I dette tilfælde er det faktisk ikke nødvendige, da man kan se uden legend hvad de tre boxplots refererer til. Defor fjerner vi den fra plottet ved at bruge theme(legend.position=\"none\"). ggplot(data=iris, aes(x=Species, y=Sepal.Length,fill=Species)) + geom_boxplot() + geom_jitter() + ylab(&quot;Sepal Length&quot;) + ggtitle(&quot;Boxplot with jitter and no legend&quot;) + theme(legend.position=&quot;none&quot;) 3.8.2 Barplot (geom_bar) Med ggplot() kan man representere data i et bar plot ved at bruge geom_bar(). I følgende vil vi gerne tælle op de antal observationer for hver art (variable Species), og visualiser dem således som søjler. Indenfor geom_bar() specificerer vi således stat=\"count\". Vi bruger også fill=Species her for at lave en forskellige farve automatiske for hver af de tre arter. Bemærk, at det var color=Species i det forudgående plot når vi anvendte geom_point(). Det er fordi, color bruges for punkter og linjer, mens fill er til større regioner bliver udfyldt, såsom bars og histograms. ggplot(iris, aes(x=Species,fill=Species)) + geom_bar(stat = &quot;count&quot;) + ggtitle(&quot;Number of observations by species&quot;) + theme_minimal() Barplot: stack vs dodge Hvis man har flere katagoriske variabler, kan man lave barplots på forskellige måder. Da der er en ekstra katagorisk variabel i datasættet, laver jeg én, der hedder Sepal.Group, der skelne imellem Long og Short værdier af variablen Sepal.Length. Her specificerer jeg bare (med funktionen ifelse()), at hvis Sepal.Length er længere end den gennemsnitlige Sepal.Length, så er det betragtet Long, ellers er det Short, som i følgende: iris$Sepal.Group &lt;- ifelse(iris$Sepal.Length&gt;mean(iris$Sepal.Length), #test &quot;Long&quot;, #if TRUE &quot;Short&quot;) #if FALSE Når jeg laver en barplot med de to variabler, tilføjer jeg Sepal.Group med fill, og ggplot splitter antal observationer efter Sepal.Group med farver som repræsenterer Sepal.Group, og tilføjer en tilsvarende legend. ggplot(iris, aes(x=Species, fill=Sepal.Group)) + geom_bar(stat = &quot;count&quot;) + ggtitle(&quot;Number of observations by species&quot;) + theme_minimal() Mange gange foretrækker man at få bars som stå ved siden af hinanden. Det kan vi specificere med blot at tilføje position=\"dodge\" ind i geom_bar(). ggplot(iris, aes(x=Species, fill=Sepal.Group)) + geom_bar(stat = &quot;count&quot;, position = &quot;dodge&quot;) + ggtitle(&quot;Number of observations by species&quot;) + theme_minimal() Som ekstra for at vise fleksibiliten i pakken ggplot2: jeg kan ikke lide at bredden af søjlen til arten setosa i ovenstående plot har bredden som er to gange større end de andre søjler (fordi der er ingen observationer i setosa som har “Long” i variablen Sepal.Group). Jeg Gogglede mig frem til en løsning på det: ggplot(iris, aes(x=Species, fill=Sepal.Group)) + geom_bar(stat = &quot;count&quot;, position = position_dodge2(preserve = &quot;single&quot;)) + ggtitle(&quot;Number of observations by species&quot;) + theme_minimal() 3.8.3 Histogram (geom_histogram) En histogram bruges til at få overblik over hvordan data fordeler sig. I ggplot2 kan man lave en histogram med geom_histogram(). Den x-akse variabel skal være en ‘continuous’ variabel. Her specificerer vi, at vi gerne vil have et histogram for hver Species. ggplot(data=iris, aes(x=Sepal.Length, fill=Species)) + geom_histogram() + xlab(&quot;Sepal Length&quot;) + ggtitle(&quot;Iris histogram&quot;) + theme_minimal() Man kan også gøre det nemmere at skelne imellem de tre arter ved at sætte alpha=0.5 indenfor geom_histogram og ved at angive en linje farve som mulighed inden for geom_histogram(). ggplot(data=iris, aes(x=Sepal.Length, fill=Species)) + geom_histogram(alpha=0.5,color=&quot;black&quot;) + xlab(&quot;Sepal Length&quot;) + ggtitle(&quot;Iris histogram&quot;) + theme_minimal() 3.8.4 Density (geom_density) Med en density plot, ligesom med en histogram, kan man se fordelingen, de data har, i formen af en glat (eller “smooth”) kurv. ggplot(data=iris, aes(x=Sepal.Length, color=Species)) + geom_density() + xlab(&quot;Sepal Length&quot;) + ggtitle(&quot;Density plot&quot;) + theme_minimal() Density plot med fill og gennemsigtig farver Vi kan angive en værdi for alpha indenfor geom_density(). Den parameter alpha specificerer gennemsigtigheden af de density kurver i plottet. ggplot(data=iris, aes(x=Sepal.Length, fill=Species)) + geom_density(alpha=0.5) + xlab(&quot;Sepal Length&quot;) + ggtitle(&quot;Density plot with alpha=0.5&quot;) + theme_minimal() Tilføje middelværdi linjer Vi bruger funktionen tapply() til at beregne middelværdier af Sepal.Length for hver af de tre Species. Vi kan derefter tilføje dem som lodrette linjer to vores plot. Her bruger vi geom_vline() (OBS det er geom_hline() hvis man vil have en vandret linje) og fortæller, at xintercept skal vare lig med de middelværdier, som vi har beregnet. Parameteren lty=2 betyder, at vi vil gerne have en “dashed” linje. means &lt;- tapply(iris$Sepal.Length,iris$Species,median) ggplot(data=iris, aes(x=Sepal.Length, color=Species)) + geom_density(alpha=0.5) + xlab(&quot;Sepal Length&quot;) + ggtitle(&quot;Density plot with alpha=0.5&quot;) + geom_vline(xintercept = means,lty=2) + theme_minimal() 3.9 Troubleshooting Her er en lille list over nogle ting, der forårsager en fejl når man kører kode med ggplot2. Jeg tilføjer også andre ting som opstå i vores lektion :). ggplot(data=iris, aes(....)) : husk her data=iris er korrekt og ikke Data=iris (R skelner mellem store og små bogstaver). Man kan også undlade at bruge data= og skrive bare iris i stedet for. Forkert stavning - dobbelt tjek, at du har stavet variabler eller funktioner navne korrekt. Glemte + symbol - for at forbinde komponenterne i plottet, skal man huske at tilføje + i slutningen af en linje og så skrive de næste komponent bagefter (man behøver ikke at skrive hver komponent på en ny linje med det gøre det nemmere at læse koden). Skrev %&gt;% symbol i stedet for + - de øvrige pakker fra tidyverse bruger %&gt;%. Glemte parentes: her har man glemt den sidste parentes: skal være fill=Species)) og ikke fill=Species). Man får bare en + fordi R forventer at du fortsætter med at skrive mere kode. &gt; ggplot(data=iris, aes(x=Sepal.Length, fill=Species) + fill og colour - indenfor aes() refererer fill til at man fylder fk. bars eller regioner med farver, og colour referere til farven af linjer eller punkter. 3.10 Problemstillinger 1) Quiz på Absalon - den hedder Quiz - ggplot2 part 1. OBS: Husk at lave følgende øvelser i R Markdown. Det er god praksis at sikre, at jeres dokument knitter - i selve eksamen afleverer du et html dokument. Lav et nyt R Markdown dokument og fjern de eksempel koder. Husk at oprette en ny chunk ved at trykke på “Insert” new chunk\", eller bruge shortcut-kommandoen CMD+ALT+I eller CTRL+ALT+I. Jeg anbefaler, at I oprette en ny chunk for hver plot, I laver. Vi bruger datasættet der hedder diamonds. Huske at først indlæse de data:* data(diamonds) Her er beskrivelsen af diamonds: Prices of over 50,000 round cut diamonds: a dataset containing the prices and other attributes of almost 54,000 diamonds. Se også ?diamonds for en beskrivelse af de variabler. 2) Bruge datasættet diamonds til at lave et scatter plot (geom_point()): caret på x-aksen price på y-aksen Så at du har noget at sammenligne med, skal dit plot se sådan ud: 3) Tilføj nogle komponenter til dit plot fra 2). En x-akse label (xlab()) og en y-akse label (ylab()) En titel (ggtitle()) Et tema som hedder theme_bw() Husk at forbinde komponenterne med + og skrive de nye komponenter på deres egen linje. Det skal se sådan ud: 4) Ændre temaet af dit plot til theme_classic() eller theme_minimal() i stedet for theme_bw() og kig på resultatet. Hvis man (måske ved uheld) skriver ind to temaer på samme tid (for eksempel + theme_bw() + theme_classic()) - hvilket tema får man så i plottet? Valgfri ekstra: her er nogle flere tema man kan prøve: https://ggplot2.tidyverse.org/reference/ggtheme.html* 5) Lav det samme plot som i 3), og skriv color=color indenfor aes(). Den første color refererer til punkt farver og den anden til variablen color i dataframen. Det skal se sådan ud: Nu fjern color=color fra funktionen aes() og i stedet tilføj aes(color=color) i funktionen geom_point(). Får du samme resultat? Bemærk at det er lige meget om man bruger britisk eller amerikansk stavning i ggplot2 - fk. colour eller color indenfor aes() giiver samme resultat. 6) Brug stadig diamonds, til at lave et boxplot: cut på x-aksen (giv x-aksen label Cut) price på y-aksen (giv y-aksen label Price of diamond) bruge fill til at give forskellige farver til de mulige værdier af cut. bruge temaet theme_bw() Det skal se sådan ud: Hvordan ser det ud, hvis man bruger colour i stedet for fill? Eller hvis man giver begge to? 7) Lav følgende ekstra ændringer til din boxplot fra ovenstående: Tilføj geom_jitter() til din boxplot fjern legend ved at tilføj theme(legend.position=\"none\") Man kan også tilføj show.legend=FALSE til både geom_boxplot() og geom_jitter() i stedet for - prøv det i stedet for at bruge theme(legend.position=\"none\"). Er det nok at tilføje show.legend=FALSE til kun én af de to geoms? Det skal se sådan ud: Man kan også prøve at forbedre plottet ved at give nogle indstillinger ind i geom_jitter(), for eksempel kan man prøve geom_jitter(size=.2,color=\"grey\",alpha=0.5) for at gøre punkter mindre overbelastende i plottet (eller kan man overvejer at fjerne dem). Leg med de tre indstilling size,color og alpha og ser på forskellen. Her er en note om alpha: Alpha refers to the opacity of a geom. Values of alpha range from 0 to 1, with lower values corresponding to more transparent colors. https://ggplot2.tidyverse.org/reference/aes_colour_fill_alpha.html Prøv at skifte rækkefølgerne af geom_jitter() og geom_boxplot() i dit plot kommando og se - gøre det en forskel til hvordan plottet ser ud? 8) Lav en barplot med indstillingen stat=\"count\": Variable clarity på x-aksen Forskellige farver til den gruppe-variable cut Specificer position=\"dodge\" for at få bars ved siden af hinanden Brug også indstillingen colour=\"black\" og notater effekten Tilføj et tema 9) Lav en histogram Variable depth på x-aksen Forskellige farver efter cut Brug indstilling alpha til at ændre gennemsigtigheden af søljerne Giv søjlerne en sort ramme Tilføj et tema osv. Det ser sådan ud: Nu får du en advarsel - gør hvad advarselen siger og ændre på indstillingen bins indenfor geom_histogram(). 10) Lav en density Man kan se, at det er svært at sammenligne fordelingerne i ovenstående histograms I din histogram kode fra 9) erstatte geom_histogram med geom_density Er det nu nemmere at sammenligne fordelingerne efter de forskellige niveauer af cut? Tilføj lodrette linjer med beregnede median værdier af variablen depth for hver af de cuts fra variablen cut. Hint: tapply til at beregne median, geom_vline til at lave lodrette linjer 11) Bare ekstra øvelse: Lege frit med at lave andre plots fra diamonds med ggplot2. Eksempelvis Boxplots med carat opdelte efter clarity Barplots for de forskellige farver (variable color) Et scatter plot af depth vs price. I alle tilfælde tilføje akse-labs, en titel, et tema osv. 3.11 Næste gang Efter at have lavet de problemstillinger skal man kunne se, at der er rigtig meget fleksibilitet involveret med at lave et plot med ggplot2. I morgen går vi videre med andre plot typer, og hvordan man fk. sætte farver manuelt. "],["visual2.html", "Chapter 4 Visualisering - ggplot2 dag 2 4.1 Indledning og videoer 4.2 Koordinat systemer 4.3 Mere om farver og punkt former 4.4 Annotations (geom_text) 4.5 Adskille plots med facets (facet_grid/facet_wrap) 4.6 Gemme dit plot 4.7 Problemstillinger 4.8 Ekstra links", " Chapter 4 Visualisering - ggplot2 dag 2 4.1 Indledning og videoer I nuværende emne udvider du værktøjskassen af kommandoer i pakken ggplot2 for at tillade større fleksibilitet og appel i dine visualiseringer. Jeg anbefaler, at du ser videoerne inden undervisningstimerne og bruger notaterne som en slags reference samtidig at du arbejder med problemstillingerne. 4.1.1 Læringsmålene I skal være i stand til at: Arbejde fleksibelt med koordinat systemer - transformering, modificering og “flipping” af x- og y-aksen. Udvide brugen af farver og form. Tilføje tekst direkte på plottet med geom_text(). Bruge facet_grid() eller facet_wrap() til at adskille plots efter en katagorisk variabel. Gemme dit færdigt plot i en fil. library(ggplot2) #husk 4.1.2 Video ressourcer Video 1: Koordinat systemer (2021) Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/544201985 Video 2: Farver og punkt former (2021) Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/544218153 Video 3: Labels - geom_text() og geom_text_repel() (2021) Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/544226498 Video 4 - Facets Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/704140333 4.2 Koordinat systemer Her arbejder vi videre med koordinater i pakken ggplot2. 4.2.1 Zoom (coord_cartesian(), expand_limits()) Man kan bruge funktionen coord_cartesian() til at zoome ind på et bestemt område i plottet. Indenfor coord_cartesian() angives xlim() og ylim(), som specificerer de øvre og nedre grænser langt henholdsvis x-aksen og y-aksen. Man kan også bruge xlim() og ylim() udenom coord_cartesian(), men i dette tilfælde bliver punkterne, som ikke kan ses i plottet (fordi deres koordinater ligger udenfor de angivne grænser), smidt væk (med en advarsel). Med coord_cartesian() beholder man til gengæld samtlige data, og man får således ikke en advarsel. I følgende ses vores oprindeligt scatter plot: ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width,color = Species)) + geom_point() + theme_minimal() Og her anvender jeg funktionen coord_cartesian() med xlim() og ylim() indenfor til at zoome ind på et ønsket område på plottet. ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width,color = Species)) + geom_point() + coord_cartesian(xlim = c(4,6), ylim = c(2.2,4.5)) + theme_minimal() Du kan også zoome ud ved at bruge expand_limits(). For eksempel hvis jeg gerne vil have punkterne \\(x = 0\\) og \\(y = 0\\) (c(0,0), eller “origin”) med i selve plottet: ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width,col=Species)) + geom_point() + expand_limits(x = 0, y = 0) + theme_minimal() Det kan være brubart i situationer hvor man, eksempelvis har flere etiketter omkring punkterne i selve plottet, som bedre kan ses hvis man tillader lidt ekstra plads i plottets område. 4.2.2 Transformering af akserne - log, sqrt osv (scale_x_continuous). Nogle gange kan det være svært at visualisere nogle variabler på grund af deres fordeling. Er der mange outliers i variablen så er de fleste punkter samlede i et lille område i plottet. Transformering med enten log eller sqrt på x-aksen og/eller y-aksen er især en populær tilgang, så de data kan ses på en mere informativ måde. ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width,col=Species)) + geom_point(size=3) + scale_x_continuous(trans = &quot;log2&quot;) + scale_y_continuous(trans = &quot;log2&quot;) + theme_minimal() Man kan også prøve fk. “sqrt” i stedet for “log2.” Formålet er, at hvis de data fordeler sig mere ‘normalt,’ kan man nemmere visualiser det i et plot - en måde til at gøre der er ved at transformere de data med “sqrt” eller “log2.” Bemærk at det er til forskel fra at man transformere selve data som bruges i plottet. Jeg kan for eksempel få samme resultat ved at ændre på datasættet forud for at anvende ggplot2 - her behøver jeg ikke at bruge scale_x_continuous(trans = \"log2\") for at opnår samme resultat, men notater at tallerne på akserne reflektere de transformeret data og ikke de oprindelige værdier. Den beslutninger man tager her kommer an på, hvad man gerne vil opnå med analysering af de data. iris$Sepal.Length &lt;- log2(iris$Sepal.Length) iris$Sepal.Width &lt;- log2(iris$Sepal.Width) ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width,col=Species)) + geom_point(size=3) + theme_minimal() 4.2.3 Flip coordinates (coord_flip) Vi kan bruge coord_flip() til at spejler x-aksen på y-aksen og omvendt (det svarer til, at man drejer plottet ved 90 grader). Se følgende eksempel, hvor jeg først opretter variablen Sepal.Group, laver en barplot og anvender coord_flip for at få vandrettet søjler. #Sepal.Group defineret som i går iris$Sepal.Group &lt;- ifelse(iris$Sepal.Length&gt;mean(iris$Sepal.Length),&quot;Long&quot;,&quot;Short&quot;) ggplot(iris,aes(x=Species,fill=Sepal.Group)) + geom_bar(stat=&quot;count&quot;,position=&quot;dodge&quot;,color=&quot;black&quot;) + coord_flip() + theme_minimal() Man kan ændre på rækkefølgen af de tre Species ved at bruge funktionen scale_x_discrete() og angiver den nye rækkefølge med indstillingen limits: ggplot(iris,aes(x=Species,fill=Sepal.Group)) + geom_bar(stat=&quot;count&quot;,position=&quot;dodge&quot;,color=&quot;black&quot;) + coord_flip() + scale_x_discrete(limits = c(&quot;virginica&quot;, &quot;versicolor&quot;,&quot;setosa&quot;)) + theme_minimal() 4.3 Mere om farver og punkt former Der er flere måder at specificere farver på i ggplot2. Man kan nøjes med den automatiske løsning, som er hurtigt (og effektiv i mange situationer), eller man kan bruge den manuelle løsning, som tager lidt mere tid at indkode men er brugbar hvis man gerne vil lave et plot til at præsentere til andre. 4.3.1 Automatisk farver Vi så sidste emnet at man automatisk kan bede om forskellige farver, ved at benytte colour=Species indenfor aes() i den ggplot() funktion. #automatisk løsning ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, colour=Species)) + geom_point() + theme_minimal() 4.3.2 Manuelle farver Hvis man foretrækker at bruge sine egne farver, kan man det ved at benytte funktionen scale_colour_manual(). Her angiver jeg stadig colour=Species indenfor aes() men så angiver jeg hvilke bestemte farver de forskellige arter skal få indenfor scale_colour_manual med indstillingen values. #manuelt løsning ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, colour=Species)) + scale_colour_manual(values=c(&quot;purple&quot;, &quot;yellow&quot;,&quot;pink&quot;)) + geom_point() + theme_minimal() En faktastisk pakke er RColorBrewer. Pakken indeholder mange forskellige “colour palettes,” det vil sige grupper af farver, der passer godt med hinanden. Man kan således slippe for at selv samle et godt kombination der passer til plottet. Nogle af de colour palettes tager også i betragtning, eksempelvis hvis man er farveblind, eller om man vil have en farvegradient eller et sæt diskrete farver som ikke ligner hinanden. I følgende indlæser jeg pakken RColorBrewer og anvender funktionen scale_colour_brewer med indstillingen palette=\"Set1\": #install.packages(&quot;RColorBrewer&quot;) library(RColorBrewer) #manuelt løsning ggplot(iris, aes(x=Sepal.Length, y=Sepal.Width, colour=Species)) + scale_colour_brewer(palette=&quot;Set1&quot;) + geom_point() + theme_minimal() Bemærk at både scale_color_maual() og scale_color_brewer() sætter farver af punkter og linjer, mens i en boxplot eller barplot sammenhænge, bruger man scale_fill_manual() eller scale_fill_brewer(). For eksempel i følgende vil jeg gerne sætte farver på de opfyldte områder i en boxplot: ggplot(iris,aes(x=Species,y=Sepal.Length,fill=Species)) + geom_boxplot() + scale_fill_brewer(palette=&quot;Set2&quot;) + theme_minimal() Her er en oversigt over de fire funktioner. fuktion beskrivelse scale_fill_manual(values=c(\"firebrick3\",\"blue\")) manuelle farver til boxplots og barplots osv. scale_color_maual(values=c(\"darkorchid\",\"cyan4\")) manulle farver til punkter og linjer osv. scale_fill_brewer(palette=\"Dark2\") RColourBrewer løsning til boxplots/barplots/osv. scale_color_brewer(palette=\"Set1\") RColourBrewer løsning til punkter og linjer osv. Der er også andre muligheder hvis man har behov for dem - for eksempel for kontinuitet data kan man prøve at google efter scale_fill_gradient. Farver i RColourBrewer Her er en nyttig reference, der viser de forskellige farver tilgængelige i pakken RColourBrewer. Mulige colour palettes tilgængelige i RColourBrewer 4.3.3 Punkt former Ligesom man kan lave forskellige farver, kan man også lave forskellige punkt former. Vi starter med den automatiske løsning ligesom vi gjorde med farver. Når det er en variable vi angiver, skal variablenavnet skrives indenfor aes(). Her, da shape er en parameter som er meget specifik til geom_point, vælger jeg at skrive en ny aes() indenfor geom_point() i stedet for indenfor funktionen ggplot(). Husk, at i funktionen ggplot() specificerer man globale ting som gælder for hele plot, og i funktionen geom_pont() angiver man ting som gælder kun for geom_point(). Se følgende eksempel: ggplot(data=iris, aes(x = Sepal.Length, y = Sepal.Width)) + scale_color_brewer(palette=&quot;Set2&quot;) + geom_point(aes(shape=Species)) + theme_minimal() Så har jeg fået både en farve og en punkt form til hver art i variablen Species. Sætte punkt form manuelt Hvis vi ikke kan lide de tre punkt former vi få automatisk, kan vi ændre dem ved at bruge scale_shape_manual - her vælger jeg values=c(1,2,3), men der er en reference nedenunder, hvor I kan se, de mappings mellem de numeriske tal og de punkt former, så at I kan vælger jeres egne. ggplot(data=iris, aes(x = Sepal.Length, y = Sepal.Width, colour=Species)) + geom_point(aes(shape=Species)) + scale_color_brewer(palette=&quot;Set2&quot;) + scale_shape_manual(values=c(1,2,3)) + theme_minimal() Reference for punkt former 4.4 Annotations (geom_text) 4.4.1 Tilføje labeller direkte på plottet. Man kan bruge geom_text() til at tilføje tekst på punkterne direkte på plottet. Her skal man fortælle, hvad for nogle tekst skal være på plottet - her specificerer vi navne på biler fra datasættet mtcars. Plottet er en scatter plot mellem variabler mpg og wt. data(mtcars) mtcars$my_labels &lt;- row.names(mtcars) #take row names and set as a variable ggplot(mtcars,aes(x=mpg,y=wt)) + geom_point() + geom_text(aes(label=my_labels)) + theme_minimal() For at gøre det nemmere at læse kan man også fjerne selve punkterne: ggplot(mtcars,aes(x=mpg,y=wt)) + #geom_point() + geom_text(aes(label=my_labels)) + theme_minimal() Teksten på plottet er stadig meget svært at læse. En god løsning kan være at bruge R-pakken ggrepel, som i følgende. 4.4.2 Pakken ggrepel for at tilføje tekst labeller #install.packages(ggrepel) #installere hvis nødvendeigt For at anvende pakken ggrepel for det mtcars datasæt, erstatter man bare geom_text() med geom_text_repel(): library(ggrepel) ggplot(mtcars,aes(x=mpg,y=wt)) + geom_point() + geom_text_repel(aes(label=my_labels)) + theme_minimal() ## Warning: ggrepel: 9 unlabeled data points (too many overlaps). Consider ## increasing max.overlaps Så kan vi se, at nu er der ingen navne som sidder lige overfor hinanden, fordi ggrepel() har været dygtig nok til at placerer dem tæt på deres tilhørende punkter, og ikke ovenpå hinanden. Man kan også se her, at der er nogle punkter, hvor funktionen har tilføjet en linje for at gøre det klart, hvilken punkt teksten referer til. I ovenstående har jeg fået en advarsel. Jeg prøver hvad jeg er blevet bedt om - og fortæller, at jeg vil have max.overlaps = 20. library(ggrepel) ggplot(mtcars,aes(x=mpg,y=wt)) + geom_point() + geom_text_repel(aes(label=my_labels),max.overlaps = 20) + theme_minimal() Så kan du se, at jeg ikke længere få en advarsel, og der tilhører tekst til alle punkterne nu. 4.4.3 Tilføje rektangler i regioner af interesse (annotate) Hvis man gerne vil fremhæve et bestemt område i plottet, kan man bruge funktionen annotate(). Prøve at selv regne ud, hvad de indstillinger indenfor annotate() gå ud på i følgende eksempel: ggplot(mtcars,aes(x=mpg,y=wt)) + geom_point() + geom_text_repel(aes(label=my_labels)) + annotate(&quot;rect&quot;,xmin=18,xmax=23,ymin=2.5,ymax=3,alpha=0.2,fill=&quot;orange&quot;) + theme_minimal() ## Warning: ggrepel: 9 unlabeled data points (too many overlaps). Consider ## increasing max.overlaps Man kan også benytte den samme funktion til at tilføje nogle tekst på et bestemt sted: ggplot(mtcars,aes(x=mpg,y=wt)) + geom_point() + geom_text_repel(aes(label=my_labels)) + annotate(&quot;rect&quot;,xmin=18,xmax=23,ymin=2.5,ymax=3,alpha=0.2,fill=&quot;orange&quot;) + annotate(&quot;text&quot;,x=25,y=2.75,label=&quot;Cars of interest&quot;,col=&quot;orange&quot;) + theme_minimal() ## Warning: ggrepel: 9 unlabeled data points (too many overlaps). Consider ## increasing max.overlaps 4.5 Adskille plots med facets (facet_grid/facet_wrap) En stor fordel af at bruge ggplot er evnen til at benytte funktionerne facet_grid() og facet_wrap() til at adskille efter en kategorisk variabel over flere plotter. I følgende kode viser jeg et density plot, hvor de tre kurver der tilhører de tre arter ligger oven på hindanen i det samme plot: ggplot(iris,aes(x=Sepal.Length,fill=Species)) + geom_density(alpha=0.5) + theme_minimal() Med funktionen facet_grid() eller facet_wrap() bruger vi ~ (tilde) tegn til at angive hvordan vi gerne vil visualisere de forskellige plots - skal man opdele dem over rækker (variablerne venstre til ~) eller over kolonner (variabler højre til ~)? #notrun variable(s) to split into row-wise plots ~ variables(s) to split into column-wise plots Ovenstående density plots af Sepal.Length kan adskilles på Species, således at man får tre plots med en kolon til hver af de tre arter: ggplot(iris,aes(x=Sepal.Length,fill=Species)) + geom_density(alpha=0.5) + facet_grid(~Species) + #split Species into different column-wise plots theme_minimal() Man kan gøre det over rækkerne (man skal dog husk at bruge en “.” efter “~” for at betegne at man kun vil adskille plots over rækkerne, mens kan af en eller anden grund kan man dropper “.” hvis man kun vil adskiller over kolonner som i ovenstående). ggplot(iris,aes(x=Sepal.Length,fill=Species)) + geom_density(alpha=0.5) + facet_grid(Species~.) + #split Species into different column-wise plots theme_minimal() Her angives Sepal.Group~Species, der betyder, at plotterne bliver adskilt efter både Sepal.Group og Species - Sepal.Group over rækkerne, og Species over kolonnerne: ggplot(iris,aes(x=Sepal.Length,fill=Species)) + geom_density(alpha=0.5) + facet_grid(Sepal.Group~Species) + #split Species into different column-wise plots theme_minimal() Bemærk forskellen mellem facet_grid() og facet_wrap(): #same plot, replace facet_grid with facet_wrap ggplot(iris,aes(x=Sepal.Length,fill=Species)) + geom_density(alpha=0.5) + facet_wrap(Sepal.Group~Species) + theme_minimal() I facet_grid() bliver man tvunget til at få en “grid” layout. Vi har således 6 plotter i en 2 x 3 grid (2 niveauer til variablen Sepal.Group og 3 niveauer til variablen Species), og det sker selvom den ene af dem har ikke noget data ind i - der findes altså ikke nogle observationer hvor Species er “Setosa” og Sepal.Group er “Long,” men vi får et plot alligevel for at bevare strukturen. Med facet_wrap() bliver plotterne uden data droppet og i dette tilfælde får man 5 plotter i hvad der kaldes for en “ribbon.” Med facet_wrap() kan man også fortælle at vi gerne vil have plotterne over 1 row (nrow = 1 eller ncol = 5): ggplot(iris,aes(x=Sepal.Length,fill=Species)) + geom_density(alpha=0.5) + facet_wrap(Sepal.Group~Species,nrow = 1) + theme_minimal() Til sidste kan det være at jeg gerne vil “befrie” skalen på y-akserne - på den måde har ikke alle plotter den samme maksimum y-værdi og de enkelte plotter benytter i stedet egne værdierne til at bestemme skalerne. Det kan være brugbart hvis man inddrager forskellige målinger men vær dog opmærksom på vhad der bedste giver mening - hvis man direkte vil sammenligne to af plotterne så er det bedre at de dele samme y-akse skale. #same plot, replace facet_grid with facet_wrap ggplot(iris,aes(x=Sepal.Length,fill=Species)) + geom_density(alpha=0.5) + facet_wrap(Sepal.Group~Species,ncol = 5,scales = &quot;free&quot;) + theme_minimal() Jeg håber at det er klart, at funktionerne er meget brugbart, og mens de opnår stort set samme ting, er der små forskel mellem dem, der er værd at husk. 4.6 Gemme dit plot Her bruger vi R Markdown til at lave et rapport som indeholder vores plots, men det også kan være at man gerne vil gemme sit plot som fil på computeren. Til at gemme et plot kan man bruge kommandoen ggsave(): ggsave(myplot, &quot;myplot.pdf&quot;) Figuren vil blive gemt i din working directory (eller den mappe, du har din .Rmd fil). Filtypen .pdf kan erstattes med andre formater, for eksempel .png eller jpeg osv. Hvis man gerne vil tage sit plot og redigerer på det (fk. Adobe Illustrater eller Inkscape), vil jeg anbefaler, at du bruge .pdf. Man må gerne ændre højden og bredden på det gemt plot med width og height: ggsave(myplot, &quot;myplot.pdf&quot;, width = 4, height = 4) 4.7 Problemstillinger Problem 1) Lav quiz - “Quiz - ggplot2 part 2” Problem 2) (Factorer og plots) a) Åbn datsættet mtcars og lav en barplot: Bruge variablen cyl på x-aksen og give forskellige farver efter den samme variabel. Virker din kode? Kig på x-aksen. Variablen er numerisk men skal fortolkes som en factor. Lav variablen om til en factor (eller bare skriv as.factor(cyl) i selve plottet) og lave dit plot igen. b) Opdel søjlerne ved at angive farver efter variablen gear i dit plot (søjlerne skal sidde ved siden af hinanden). Vær OBS om hvordan R fortolker variablen. I følgende problemer arbejder vi med datasættet Palmer Penguins. Pakken palmerpenguins skal installeres hvis du ikke har brugt datasættet før. Data beskrivelse: The palmerpenguins data contains size measurements for three penguin species observed on three islands in the Palmer Archipelago, Antarctica. #install.packages(&quot;palmerpenguins&quot;) #køre hvis ikke allerede installeret library(palmerpenguins) library(ggplot2) library(tidyverse) head(penguins) FALSE # A tibble: 6 × 8 FALSE species island bill_length_mm bill_depth_mm flipper_length_… body_mass_g sex FALSE &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;fct&gt; FALSE 1 Adelie Torge… 39.1 18.7 181 3750 male FALSE 2 Adelie Torge… 39.5 17.4 186 3800 fema… FALSE 3 Adelie Torge… 40.3 18 195 3250 fema… FALSE 4 Adelie Torge… NA NA NA NA &lt;NA&gt; FALSE 5 Adelie Torge… 36.7 19.3 193 3450 fema… FALSE 6 Adelie Torge… 39.3 20.6 190 3650 male FALSE # … with 1 more variable: year &lt;int&gt; Man kan altid anvende ?penguins for at se flere detaljer om variablenavner. Vi skal starte med at rydde op lidt i datasættet. Køre følgende for at fjerne al rækker som har NA (manglende) værdier: penguins &lt;- drop_na(penguins) Problem 3) Manuelt farver og punkter a) Lav en scatter plot med ggplot: bill_length_mm på x-aksen bill_depth_mm på y-aksen give hver species sin egen farve (automatisk løsning) sætte et tema b) Lav følgende ændringer til det plot: Ændr farver manuelt - prøv både at angive farver med scale_color_manual og afprøve også løsningen med pakken RColorBrewer (husk at installere/indlæse pakken hvis nødvendigt). Angiv at der skal være forskellige punkt former for hver art i variablen species. Prøv også at vælge nogle punkt former fra listen og specificer dem manuelt. Figure 4.1: Min løsning Problem 4) Coordinate systemer Tag overstående scatter plot fra 3) og a) brug coord_cartesian() så at man fanger kun en bill længde (variablen bill_length_mm) mellem 40 og 50, og en bill depth (variablen bill_depth_mm) mellem 16 og 19. b) brug pakken ggrepel (husk at installere/inlæse) og tilføj navnerne af de forskellige øer som tekst direkte på plottet c) lav en delmængde af dataframen penguins efter samme kriterier som a) og specificer din nye dataframe som parameteren data indenfor geom_text_repel-funktionen. Det undgår, at tekst bliver plottet for punkterne udenfor området angivet med coord_cartesian()). ## Warning: ggrepel: 14 unlabeled data points (too many overlaps). Consider ## increasing max.overlaps Figure 4.2: Min løsning Problem 5) Histogram med facets Lav en histogram: Variablen flipper_length_mm på x-aksen Anvend facet_grid for at adskille dit plot i tre efter variablen species Giv også en forskellige farve til hver art i species Hvis nødvendigt ændr parameteren bins til noget andet indenfor geom_histogram(). Her er min løsning: ggplot(data=penguins,aes(x=flipper_length_mm,fill=species)) + geom_histogram(bins = 30, alpha=0.5, colour=&quot;black&quot;) + scale_fill_brewer(palette = &quot;Set1&quot;) + ggtitle(&quot;Histogram of flipper length according to species&quot;) + facet_grid(~species) + xlab(&quot;Flipper length (mm)&quot;) + theme_minimal() Problem 6) a) Lave et density plot af body_mass_g. Anvend funktionen facet_grid til at opdele i til tre plots efter species Brug også fill til at opdele densities indenfor de tre plots efter variablen sex Gør dine density plots gennemsigtige Skrive en sætning om forskellen i body_mass_g mellem “females” og “males.” b) Nu udvikl din facet_grid kommando til at adskille plots yderligere således at du har en “grid” struktur med de forskellige øer (variablen island) på rækkerne og de tre arter (variablen spieces) på kolonnerne. c) Kan du forklare hvorfor der er blank plotter i din grid? Eksperimenter med facet_wrap i stedet for facet_grid. Problem 7) Coordinate systemer Lav en barplot af counts for species opdelte efter sex. Anvend en ‘coordinate flip’ for at få den til at være vandrette/horizontal. Vælg nogle farver - jeg benytter palette = \"Accent\" fra den RColorBrewer løsning Ændr rækkefølgen af de tre søjler, således at arten med de meste observationer er på toppen og arten med den færrest er på bunden. Prøv også scale_y_reverse() og kig på resultatet. Her er min løsning Figure 4.3: Min løsning Problem 8) Lav boxplots af body_mass_g opdelt efter species. Tilføj “jitter” punkter ovenpå boxplots. Specificer nogle farver manuelt for både boxes og punkterne (en farve til hver art) Giv det en hensigtsmæssig titel og nogle akser-labels Tilføj en ny variabel island_binary til penguins, som er “Biscoe” hvis island er ‘Biscoe’ og “not Biscoe” hvis ikke. Adskille plotterne ved at opdele efter island_binary. Ekstra: prøv ?geom_violin som erstatning for geom_boxplot. Problem 9) Annotations og linjer. a) Lav et scatter plot af bill_length_mm vs bill_depth_mm. Anvend hensigtsmæssigt titel/labels/tema Anvend forskellige farver for de tre species. Tjek funktionen ?annotate og bruge den med geom=\"text\" og hensigtsmæssigt x- og y-akse værdier til at tilføje species navne som tekst direkte på plottet (se eksempel nedenfor for at se, hvad jeg mener). Udforsk hvordan man gøre teksten større, som jeg har gjort i min løsning. Fjern legend med show.legend = FALSE indenfor geom_point() Her er min løsning: b) Vi vil gerne tilføje nogle lodrette og vandrette linjer til plottet, som viser middelværdierne af variablerne for de tre arter Først brug tapply til at beregne de gennemsnitlige værdier for henholdsvis bill_length_mm og bill_depth_mm opdelte efter species (gem dem som henholdsvis mean_length og mean_depth) Brug mean_length og mean_depth til at tilføje linjer til plottet med den relevante funktion. c) Udfordring Kan du gøre linjerne til samme farver som punkterne af deres pågældende art (se min løsning nedenunder)? Hint: tage udgangspunkt i følgende dataframe, der bruger din beregnede værdier: mydf &lt;- data.frame(&quot;species&quot;=names(mean_length),&quot;mlength&quot;=mean_length,&quot;mdepth&quot;=mean_depth) mydf ## species mlength mdepth ## Adelie Adelie 38.82397 18.34726 ## Chinstrap Chinstrap 48.83382 18.42059 ## Gentoo Gentoo 47.56807 14.99664 Angiv parameteren data til at være ovenstående dataframe i geom_vline() og brug lokal aethestiks (aes()) til at angive parametre til linjerne. Gør samme for geom_hline() Specificer også “dashed” linjer Her er min løsning: Figure 4.4: min løsning Problem 10) Ekstra. Kig på “cheatsheet” til ggplot2 (Tryk på “Help” &gt; “Cheatsheets” og vælg en til ggplot2) og afprøve nogle af de ting, som ikke var dækket i kurset indtil videre! Gerne lad mig høre hvis du synes der er eventuelle noget meget nyttig for dig, som er ellers blevet glemt i notaterne. 4.8 Ekstra links R Graphics cookbook https://r-graphics.org/ "],["data.html", "Chapter 5 Bearbejdning dag 1 5.1 Hvad er Tidyverse? 5.2 Video ressourcer 5.3 Oversigt over pakker 5.4 Principper med ‘tidy data’ 5.5 Lidt om tibbles 5.6 Transition fra base til tidyverse 5.7 Bearbejdning af data: dplyr 5.8 Visualisering: bruge som input i ggplot2 5.9 Misc funktioner som er nyttige at vide 5.10 Problemstillinger 5.11 Kommentarer", " Chapter 5 Bearbejdning dag 1 5.1 Hvad er Tidyverse? Tidyverse er en samling af pakker i R, som man bruger til at bearbejde datasæt. Formålet er ikke nødvendigvis at erstatte funktionaliteten af base-pakken, men til at bygge på den. Som vi kommer til at se i detaljer, tidyverse deler faktisk meget af den samme tankegang bag ggplot2 - men i stedet for at bruge + til at bygge komponenter op i et plot, bruger man %&gt;% (udtales ‘pipe’) til at tilknytte de forskellige funktioner til hinanden. Most common tidyverse packages Læringsmålene til i dag I skal være i stand til at: Beskrive generelle hvad R-pakken Tidyverse kan benyttes til. Beskrive en tibble og genkende når et datasæt er betragtet som “tidy.” Benytte nogle vigtige Tidyverse-verbs til at bearbejde data (filter(),select(), mutate(), rename(), arrange(), recode()). Bruge %&gt;% til at forbinde Tidyverse-verber sammen og at overføre data til et plot. 5.2 Video ressourcer Begynd ved at læse “Principper med ‘tidy data’” og ‘Lidt om tibbles’ nedenunder, og så se følgende videoer. Video 1 - rydde op i datasættet titanic med select() og drop_na() Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/706266697 Video 2 - tidyverse verber: select og filter Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/705136725 Video 3 - flere tidyverse verber Lave en ny kolon med mutate() Ændre variabelnavne med rename() Ændre på værdierne med recode() Ændre rækkefølgen af observationerne med arrange() Bruge tidyverse kommandoer som input i ggplot2() Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/706266885 5.3 Oversigt over pakker Lad os starte med at indlæse pakken tidyverse. Vær opmærksom på, at har du ikke pakken på din computer, kan det tage lidt tid at installere - det er pga. de mange pakke der tidyverse er afhængig af, der enten skal også installeres eller opdateres. Hvis har pakken installeret men oplever problemer tjek om du har det seneste versioner af pakkerne og R på dit system. #install.packages(&quot;tidyverse) library(tidyverse) Du kan se, at det faktisk er ikke kun én, men otte pakke som er blevet indlæst. Man kan godt indlæse alle pakke individuelt ved at bruge fk. library(dplyr), men det er meget bekvemt at indlæse alle på samme tid med brugen af library(tidyverse). Her er nogle beskrivelser af de pakker: pakke korte beskrivelse readr indlæse data ggplot2 plot data tibble lave “tibbles” - tidyverse’s svar på datarammer (data.frame). tidyr skifte imellem data forms (fk. ‘long’ &gt; ‘wide’ format, eller omvendt) purrr functional programming, gentalelse dplyr manipulere tibbles - beholde delmængder, skabe nye variabler, beregne oversigtsstatistikker osv. stringr manipulere strings (ikke brugt i dette kursus) forcats FOR CATegorical data (factors); håndtere faktor variabler Man kan også indlæse alle pakke individuelt ved at bruge fk. library(dplyr), men det er meget bekvemt bare at indlæse alle på samme tid med brugen af library(tidyverse). 5.4 Principper med ‘tidy data’ Idéen bag tidyverse er, at hvis alle datasæt følger præcis den samme struktur, så er det enkelt datasæt ligefrem at bearbejde til præcis som vi gerne vil have det. Datasæt som har den struktur hedder “tidy data.” For at betragte et datasæt som “tidy,” må det opfylde tre kriterie: Hver variabel i datasættet har sin egen kolonne Hver observation i datasættet har sin egen række Hver værdi i datasættet få sin egen cell Iris er et godt eksempel af tidy data: data(iris) head(iris) ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3.0 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5.0 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa Hver variabel (Sepal.Length, Sepal.Width, Petal.Length, Petal.Width og Species) har sin egen kolon, og hver observation (e.g. 1,2,3, osv.) har sin egen række. Derudover har hver cell sin egen data værdi og det er dermed meget klart at læse og forstå dataframen ved øjnene. Principper af tidy data Det er tilfældet, at de fleste af datasæt i dette kursus hører til “tidy data,” især i disse notater, hvor vi benytter en del af indbygget datasæt. Nogle gange kan det dog være, at vi er nødt til at gøre noget, til at lave et datasæt om til en “tidy datasæt.” R-pakker dplyr og tidyr er velegnet til at hjælpe med at transformere et datasæt til en, der er “tidy,” og bagefter kan man forsætte i den sædvanlige måde med at analyse datasættet. Bemærk at bare fordi et datasæt er “tidy,” betyder det ikke nødvendigvis, at det er klart til at analysere, for der kan godt være, at man har bruge for at bearbejde videre på det første - igen med pakkerne dplyr og tidyr. 5.5 Lidt om tibbles En tibble er det tidyverse svar på en data.frame fra base-R. De ligner hinanden meget og derfor behøver man ikke tænk for meget over forskellen, men der er nogle opdateret aspekter i en tibble - for eksempel bruger en tibble ikke row.names, og når man visualiserer en tibble i R Markdown, få man lidt ekstra oplysninger, såsom dimensioner og data typer. Bemærk, at de fleste tidyverse funktioner fungerer lige så godt uanset om man har en tibble eller en data.frame. Bemærk, at jeg vedligeholder ordet ‘dataframe’ indenfor almindelig tekst. Man kan lave sin egen tibble på samme måde som en data.frame. tibble(x=1:3,y=c(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;)) ## # A tibble: 3 × 2 ## x y ## &lt;int&gt; &lt;chr&gt; ## 1 1 a ## 2 2 b ## 3 3 c Man kan også lave en tribble, som er den samme som en tibble men har en lidt anderledes måde at indsætte data på. For eksempel er følgende tilsvarende til den overstående tibble: tribble(~x, ~y, 1, &quot;a&quot;, 2, &quot;b&quot;, 3, &quot;c&quot;) ## # A tibble: 3 × 2 ## x y ## &lt;dbl&gt; &lt;chr&gt; ## 1 1 a ## 2 2 b ## 3 3 c Man kan lave en data.frame om til en tibble som i følgende: as_tibble(iris) ## # A tibble: 150 × 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 5.1 3.5 1.4 0.2 setosa ## 2 4.9 3 1.4 0.2 setosa ## 3 4.7 3.2 1.3 0.2 setosa ## 4 4.6 3.1 1.5 0.2 setosa ## 5 5 3.6 1.4 0.2 setosa ## 6 5.4 3.9 1.7 0.4 setosa ## 7 4.6 3.4 1.4 0.3 setosa ## 8 5 3.4 1.5 0.2 setosa ## 9 4.4 2.9 1.4 0.2 setosa ## 10 4.9 3.1 1.5 0.1 setosa ## # … with 140 more rows De fleste tidyverse koder fungerer lige så godt uanset om man har en tibble eller en data.frame. 5.6 Transition fra base til tidyverse Jeg introducerer tidyverse gennem et meget berømt datasæt som hedder titanic - det er ikke biologiske data men er stadigvæk ret interessant, og sjovt at manipulere på. titanic er brugt som en del af en åben konkurrence på hjemmesiden Kaggle, hvor mindst 31.000 personer indtil videre har arbejdet på at lave den bedste model til at forudsige, hvem der overlever katastrofen - linket er her, hvor du kan også læse om baggrunden til datasættet https://www.kaggle.com/c/titanic. 5.6.1 Om Titanic datasæt Man kan downloade datasættet, der hedder titanic_train, direkte fra Kaggle, men der er faktisk en R-pakke, der hedder titanic som gøre det mere bekvemt: #install.packages(&quot;titanic&quot;) #hvis ikke allerede installerede library(titanic) Her er beskrivelsen for pakken: titanic is an R package containing data sets providing information on the fate of passengers on the fatal maiden voyage of the ocean liner “Titanic,” summarized according to economic status (class), sex, age and survival. These data sets are often used as an introduction to machine learning on Kaggle. Vi vil gerne bruge titanic_train fordi det er datasættet, der bliver brugt på Kaggle til at træne maskinelærings modeller (som bliver testet på titanic_test for at evaluere, hvor god modellen er). Til at gøre tingene nemmere, lad os bare omdøb titanic_train til titanic og anvende glimpse, der er fra pakken dplyr, på datasættet. titanic &lt;- as_tibble(titanic_train) glimpse(titanic) ## Rows: 891 ## Columns: 12 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,… ## $ Survived &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1… ## $ Pclass &lt;int&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3… ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Fl… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;mal… ## $ Age &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, … ## $ SibSp &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0… ## $ Parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0… ## $ Ticket &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;37… ## $ Fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,… ## $ Cabin &lt;chr&gt; &quot;&quot;, &quot;C85&quot;, &quot;&quot;, &quot;C123&quot;, &quot;&quot;, &quot;&quot;, &quot;E46&quot;, &quot;&quot;, &quot;&quot;, &quot;&quot;, &quot;G6&quot;, &quot;C… ## $ Embarked &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;Q&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;… Jeg har også kopieret de variable beskrivelser her: PassengerId: unique index for each passenger Survived: Whether or not the passenger survived. 0 = No, 1 = Yes. Pclass: Ticket class: 1 = 1st Class, 2 = 2nd Class, 3 = 3rd Class. Name: A character string containing the name of each passenger. Sex: Character strings for passenger sex (“male”/ “female”). Age: Age in years. SibSp: The number of siblings/spouses aboard the titanic with the passenger Parch: The number of parents/children aboard the titanic with the passenger Ticket: Another character string containing the ticket ID of the passenger. Fare: The price paid for tickets in pounds Sterling (Keep in mind that unskilled workers made around 1 pound a week - these were expensive tickets!) Cabin: The cabin number of the passengers (character). Embarked: Where passengers boarded the titanic. C = Cherbourg, Q = Queenstown, S = Southampton). 5.6.2 Titanic: oprydning Der er faktisk nogle rengøring i datasættet vi skal tage os af, før vi kan komme videre med analysen. Vi kan se fra glimpse(titanic) ovenpå at der er 891 observationer. De fleste (687) passagerer har faktisk ingenting for variabel Cabin: sum(titanic$Cabin==&quot;&quot;) #ingenting for variabelen &#39;cabin&#39; ## [1] 687 Andre har mere end én cabin. Det ser ikke særlig tidy ud, og man kan hellere ikke forestille sig at få meget insigt fra variablen, så vi vælger at fjerne hele kolon med funktionen select(): titanic_no_cabin &lt;- select(titanic, -Cabin) select() er en af de kerne funktioner i tidyverse - her angiver vi, hvilke kolonner vi gerne vil beholde eller fjerne fra datasættet. I dette tilfælde har vi specificeret -Cabin, som betyder, at vi ikke vil have variablen Cabin med, men gerne vil beholde resten af kolonnerne. Prøv selv at køre select(titanic, Cabin) i stedet for - så får vi kun Cabin og fjerner resten af vores variabler. glimpse(titanic_no_cabin) ## Rows: 891 ## Columns: 11 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17,… ## $ Survived &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1… ## $ Pclass &lt;int&gt; 3, 1, 3, 1, 3, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 2, 3, 3… ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Fl… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;mal… ## $ Age &lt;dbl&gt; 22, 38, 26, 35, 35, NA, 54, 2, 27, 14, 4, 58, 20, 39, 14, … ## $ SibSp &lt;int&gt; 1, 1, 0, 1, 0, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 0, 1, 0… ## $ Parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0… ## $ Ticket &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;37… ## $ Fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 8.4583, 51.8625,… ## $ Embarked &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;Q&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;… Næste tjekker vi efter NA i datasættet. NA er hvordan R betegner manglende værdier. Man kan se i følgende, mens de fleste variabler ikke har NA værdier, har variablen Age 177 NA. colSums(is.na(titanic_no_cabin)) ## PassengerId Survived Pclass Name Sex Age ## 0 0 0 0 0 177 ## SibSp Parch Ticket Fare Embarked ## 0 0 0 0 0 I dette tilfælde vælger jeg at fjerne alle passagerer som har NA i stedet for deres alder. Til dette formål bruger jeg funktionen drop_na, som fjerner alle observationer, der har NA i mindst èn variabel. titanic_clean &lt;- drop_na(titanic_no_cabin) colSums(is.na(titanic_clean)) ## PassengerId Survived Pclass Name Sex Age ## 0 0 0 0 0 0 ## SibSp Parch Ticket Fare Embarked ## 0 0 0 0 0 Nu kan vi tjekke igen, hvor mange observationer og variabel vi har tilbage. glimpse(titanic_clean) ## Rows: 714 ## Columns: 11 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19… ## $ Survived &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1… ## $ Pclass &lt;int&gt; 3, 1, 3, 1, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 3, 2, 2, 3… ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Fl… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;mal… ## $ Age &lt;dbl&gt; 22, 38, 26, 35, 35, 54, 2, 27, 14, 4, 58, 20, 39, 14, 55, … ## $ SibSp &lt;int&gt; 1, 1, 0, 1, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 1, 0, 0, 0… ## $ Parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0… ## $ Ticket &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;37… ## $ Fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 51.8625, 21.0750… ## $ Embarked &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;… Vi har beholdt 714 observationer og 11 variabler, og datasættet opfylder kriteren for at være tidy. 5.6.3 Pipe Man kan faktisk gøre den samme som i ovenstående ved at bruge pipe %&gt;%: titanic_clean &lt;- titanic %&gt;% # we take the titanic dataset select(-Cabin) %&gt;% # select the bits we want drop_na() # then remove the NAs Man bruger pipe %&gt;% til at kombinere adskillige tidyverse funktioner i den samme kommando - linjen slutter med %&gt;%, der fortæller, at vi skal bruge resultatet fra den linje som inputtet i den næste linje. Logikken er således, at vi starter med en dataframe, gør dernæst én ting ad gangen, og så slutter med en ny dataframe (som vi kan gemme med &lt;-). Bemærk, at processen ligner den, man bruger i ggplot2, men forskellen er at man bruger %&gt;% i stedet for + i denne ramme. Bemærk også her, at ligesom i ggplot2, skriver jeg koden over flere linjer. Det er ikke et krav men det gøre det nemmere at læse og forstå koden. For at illustrerer logikken, kan man se, at følgende to linjer er tilsvarende: #take x and apply some function f f(x) #traditional approach x %&gt;% f #tidyverse approach I begge tilfælde starter vi med x, og så anvender vi funktionen f med x som argument - en kæmpe fordel med den tidyverse løsning er, at når man har flere funktioner, slipper man for at anvende mange parenteser, og rækkefølgen man skriver funktionerne læses fra venstre til højre og ikke omvendt, se for eksempel følgende: #take x, apply f, then apply g, then apply h h(g(f(x))) #traditional approach x %&gt;% f %&gt;% g %&gt;% h #tidyverse approach På sammen måde i vores titanic oprydning kan man både pakke funktionen select() ind i funktionen drop_na(), eller bruge den tidyverse løsning, ligesom i nedenstående - de to giver det tilsvarende resultat: første bruger vi select() til at fjerne kolonnen Cabin, og så bruger vi drop_na() til at fjerne alle række med mindste én NA . titanic_clean &lt;- drop_na(select(titanic,-Cabin)) titanic_clean &lt;- titanic %&gt;% select(-Cabin) %&gt;% drop_na() 5.7 Bearbejdning af data: dplyr Pakken dplyr er nok den meste brugbare pakke til at bearbejde dataframes. Jeg gennemgår nogle af de meste almindelige muligheder med pakken, og der er også en “cheatsheet” som du kan downloade som reference: https://github.com/rstudio/cheatsheets/raw/master/data-transformation.pdf. Jeg tager afsæt i følgende funktioner, og dækker flere gennem de forskellige øvelese og øvrige emner. dplyr verbs beskrivelse select() udvælge kolonner (variabler) filter() udvælge rækker (observationer) arrange() sortere rækker mutate() tilføje eller ændre eksisterende kolonner rename() ændre variabler navne recode() ændre selve data group_by() dele datasættet op efter en variabel summarise() aggregere rækker, findes ofte tilknyttet til group_by() Bemærk, at alle disse funktioner tager udgangspunkt i en dataframe, og man får altid en ny dataframe som outputtet. Ved at kunne bruge disse funktioner og kombinere dem (ved hjælp af %&gt;%), har man godt styr på bearbejdningen af datarammer. 5.7.1 dplyr verbs: select() Som vi lige har set i ovenstående, med select() udvælger man bestemte variabler. Vi kan vælger at beholde, fjerne eller andre rækkefølgen af variablerne i dataframe. Som eksempel, her beholder vi kun variablerne Name og Age: titanic_clean %&gt;% select(Name, Age) %&gt;% glimpse() ## Rows: 714 ## Columns: 2 ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Florence … ## $ Age &lt;dbl&gt; 22, 38, 26, 35, 35, 54, 2, 27, 14, 4, 58, 20, 39, 14, 55, 2, 31, … Hvis vi gerne vil fjerne en variabel fra en dataframe, kan vi bruge et minustegn. I nedenstående fjerner vi Name og Age fra dataframe: titanic_clean %&gt;% select(-Name, -Age) %&gt;% glimpse() ## Rows: 714 ## Columns: 9 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19… ## $ Survived &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1… ## $ Pclass &lt;int&gt; 3, 1, 3, 1, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 3, 2, 2, 3… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;mal… ## $ SibSp &lt;int&gt; 1, 1, 0, 1, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 1, 0, 0, 0… ## $ Parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0… ## $ Ticket &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;37… ## $ Fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 51.8625, 21.0750… ## $ Embarked &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;… 5.7.1.1 Hjælper funktioner til select() Hjælper funktioner til funktionen select() kan være brugbare hvis du gerne vil udvælge bestemte variabler efter nogle kriterier. Jeg har samlet nogle (men ikke alle mulige!) funktioner nedenfor og inddrager eksempler i problemstillingerne. select helper beskrivelse starts_with() starts with a prefix ends_with() ends with a prefix contains() contains a literal string matches() matches a regular expression num_range() a numerical range like x01, x02, x03. one_of() variables in character vector. everything() all variables. where() fk. takes a function and returns all variables for which the function returns TRUE: For eksempel: titanic_clean %&gt;% select(starts_with(&quot;P&quot;)) ## # A tibble: 714 × 3 ## PassengerId Pclass Parch ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 1 3 0 ## 2 2 1 0 ## 3 3 3 0 ## 4 4 1 0 ## 5 5 3 0 ## 6 7 1 0 ## 7 8 3 1 ## 8 9 3 2 ## 9 10 2 0 ## 10 11 3 1 ## # … with 704 more rows Særligt brugbar i statistik statistisk metoder der kræver kun numeriske variabler er where() når kombinerede med is.numeric. Eksempelvis i følgende kode udvælger man kun numeriske variabler fra datasættet titanic_clean: titanic_clean %&gt;% select(where(is.numeric)) ## # A tibble: 714 × 7 ## PassengerId Survived Pclass Age SibSp Parch Fare ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 0 3 22 1 0 7.25 ## 2 2 1 1 38 1 0 71.3 ## 3 3 1 3 26 0 0 7.92 ## 4 4 1 1 35 1 0 53.1 ## 5 5 0 3 35 0 0 8.05 ## 6 7 0 1 54 0 0 51.9 ## 7 8 0 3 2 3 1 21.1 ## 8 9 1 3 27 0 2 11.1 ## 9 10 1 2 14 1 0 30.1 ## 10 11 1 3 4 1 1 16.7 ## # … with 704 more rows 5.7.2 dplyr verbs: filter() Med funktionen select() udvælger man bestemte variabler. Man anvender til gengæld funktionen filter() til at udvælge bestemte observationer (rækker) fra dataframe. I nedenstående beholder jeg rækkerne, hvor variablen Age er lig med 50. Bemærk, at vi bevarer alle variabler i dataframe. titanic_clean %&gt;% filter(Age == 50) %&gt;% glimpse() ## Rows: 10 ## Columns: 11 ## $ PassengerId &lt;int&gt; 178, 260, 300, 435, 459, 483, 527, 545, 661, 724 ## $ Survived &lt;int&gt; 0, 1, 1, 0, 1, 0, 1, 0, 1, 0 ## $ Pclass &lt;int&gt; 1, 2, 1, 1, 2, 3, 2, 1, 1, 2 ## $ Name &lt;chr&gt; &quot;Isham, Miss. Ann Elizabeth&quot;, &quot;Parrish, Mrs. (Lutie Davis)… ## $ Sex &lt;chr&gt; &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;, &quot;f… ## $ Age &lt;dbl&gt; 50, 50, 50, 50, 50, 50, 50, 50, 50, 50 ## $ SibSp &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 1, 2, 0 ## $ Parch &lt;int&gt; 0, 1, 1, 0, 0, 0, 0, 0, 0, 0 ## $ Ticket &lt;chr&gt; &quot;PC 17595&quot;, &quot;230433&quot;, &quot;PC 17558&quot;, &quot;13507&quot;, &quot;F.C.C. 13531&quot;,… ## $ Fare &lt;dbl&gt; 28.7125, 26.0000, 247.5208, 55.9000, 10.5000, 8.0500, 10.5… ## $ Embarked &lt;chr&gt; &quot;C&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot; Man kan også vælge intervaller - for eksempel hvis man vil vælge alle som er i halvtredserne. titanic_clean %&gt;% filter(Age &gt;= 50 &amp; Age &lt; 60) %&gt;% head() ## # A tibble: 6 × 11 ## PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 7 0 1 &quot;McCarthy, M… male 54 0 0 17463 51.9 ## 2 12 1 1 &quot;Bonnell, Mi… fema… 58 0 0 113783 26.6 ## 3 16 1 2 &quot;Hewlett, Mr… fema… 55 0 0 248706 16 ## 4 95 0 3 &quot;Coxon, Mr. … male 59 0 0 364500 7.25 ## 5 125 0 1 &quot;White, Mr. … male 54 0 1 35281 77.3 ## 6 151 0 2 &quot;Bateman, Re… male 51 0 0 S.O.P… 12.5 ## # … with 1 more variable: Embarked &lt;chr&gt; Man kan også kombinere betingelser fra forskellige kolonner, for eksempel i nedenstående vælger vi alle personer som er kvinder og som rejste ved første klasse. titanic_clean %&gt;% filter(Sex == &#39;female&#39; &amp; Pclass == 1) %&gt;% head() ## # A tibble: 6 × 11 ## PassengerId Survived Pclass Name Sex Age SibSp Parch Ticket Fare ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 2 1 1 Cumings, Mrs… fema… 38 1 0 PC 17… 71.3 ## 2 4 1 1 Futrelle, Mr… fema… 35 1 0 113803 53.1 ## 3 12 1 1 Bonnell, Mis… fema… 58 0 0 113783 26.6 ## 4 53 1 1 Harper, Mrs.… fema… 49 1 0 PC 17… 76.7 ## 5 62 1 1 Icard, Miss.… fema… 38 0 0 113572 80 ## 6 89 1 1 Fortune, Mis… fema… 23 3 2 19950 263 ## # … with 1 more variable: Embarked &lt;chr&gt; Vi kan også inddrage flere symboler. For eksempel i nedenståenden vælger vi personer som er kvinder og som rejste i enten første eller anden klass og som er i trediverne. Huske at tilføje runde parenteser omkring de to Pclass - prøv selv at fjerne dem og se, hvad der sker. titanic_clean %&gt;% filter(Sex == &#39;female&#39; &amp; (Pclass == 1 | Pclass == 2) &amp; Age %in% c(30:39)) %&gt;% glimpse() ## Rows: 43 ## Columns: 11 ## $ PassengerId &lt;int&gt; 2, 4, 62, 99, 191, 212, 216, 219, 231, 258, 259, 270, 310,… ## $ Survived &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1… ## $ Pclass &lt;int&gt; 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2… ## $ Name &lt;chr&gt; &quot;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&quot;, &quot;Fu… ## $ Sex &lt;chr&gt; &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;… ## $ Age &lt;dbl&gt; 38, 35, 38, 34, 32, 35, 31, 32, 35, 30, 35, 35, 30, 31, 30… ## $ SibSp &lt;int&gt; 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0… ## $ Parch &lt;int&gt; 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0… ## $ Ticket &lt;chr&gt; &quot;PC 17599&quot;, &quot;113803&quot;, &quot;113572&quot;, &quot;231919&quot;, &quot;234604&quot;, &quot;F.C.C… ## $ Fare &lt;dbl&gt; 71.2833, 53.1000, 80.0000, 23.0000, 13.0000, 21.0000, 113.… ## $ Embarked &lt;chr&gt; &quot;C&quot;, &quot;S&quot;, &quot;&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;,… 5.7.3 Comparitiver reference Her er en tabel af comparitiver (kopirede fra grundlæggende R) - de er brugbare i både filter() og i baseR (fordi koncepten bag er den samme, bare tilgang er ænderledes). comparitive beskrivelse &lt; less than &gt; greater than &lt;= less than or equal to &gt;= greater than or equal to == equal to != not equal to &amp; and %in% in | or 5.7.4 Kombinere filter() og select() Man kan også kombinere både filter() og select() i samme kommando, som i følgende: titanic_clean %&gt;% filter(Sex == &#39;female&#39; &amp; (Pclass == 1 | Pclass == 2) &amp; Age %in% c(30:39)) %&gt;% select(Name, Fare) %&gt;% glimpse() ## Rows: 43 ## Columns: 2 ## $ Name &lt;chr&gt; &quot;Cumings, Mrs. John Bradley (Florence Briggs Thayer)&quot;, &quot;Futrelle,… ## $ Fare &lt;dbl&gt; 71.2833, 53.1000, 80.0000, 23.0000, 13.0000, 21.0000, 113.2750, 7… Bemærk at man bør passe på rækkefølgen, som man anvender de forskellige funktioner. For eksempel hvis man bytter rundt filter() og select() i ovenstående, få man en advarsel - prøv selv at køre følgende: ##virker ikke!!!!!##### titanic_clean %&gt;% select(Name, Fare) %&gt;% filter(Sex == &#39;female&#39; &amp; (Pclass == 1 | Pclass == 2) &amp; Age %in% c(30:39)) %&gt;% glimpse() Det er fordi, hvis man første vælger at beholde variablerne Name og Age, så findes de andre variabler ikke mere i de resulterende dataframe, som bliver dernæst brugt i funktionen filter() - man kan derfor ikke benytte funktionen filter() på variablerne Pclass,Sex og Age. 5.7.5 dplyr verbs: mutate() Man kan avende funktionen mutate() til at tilføje en ny variable til en dataframe. I nedenstående tilføjer jeg en ny variabel med navnet Adult, der angiver om personen kan betragtes som en voksen (hvis vedkommende er mindst 18 år gammel). titanic_with_Adult &lt;- titanic_clean %&gt;% mutate(Adult = Age&gt;=18) titanic_with_Adult %&gt;% select(Adult) %&gt;% glimpse ## Rows: 714 ## Columns: 1 ## $ Adult &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, FALSE, TRUE, FALSE, FALSE, T… #Så kan man se, at der er 601 voksne og 113 børn som passagerere på skibet. Bemærk her, at jeg gemmer resultatet som en ny dataframe, der hedder titanic_with_Adult, og derefter bruger jeg glimpse() på det nye objekt titanic_with_Adult for at se, hvordan min nye dataframe ser ud. I forudgående eksempler havde jeg ikke gemt resultatet - bare brugt glimpse() for at se resultatet på skærmen. Hvis du gerne vil bruge din resulterende dataframe videre, så skal du husk at gemme den (med brugen af &lt;- tegn) funktionen ifelse() indenfor mutate() Jeg kan oprette variablen Adult sådan at den er mere informativ end bare TRUE eller FALSE. Jeg anvender funktionen ifelse(), der giver mulighed for at angive, at jeg gerne vil have teksten “adult” hvis udsagnet Age&gt;=18 er TRUE, og hvis FALSE vil jeg have teksten “child”: ifelse(Age&gt;=18,&quot;adult&quot;,&quot;child&quot;) Fuktionen ifelse() bruges indenfor funktionen mutate(), fordi vi er i gang med at oprette en ny variable Adult - ifelse() giver bare mulighed for at fortælle, hvordan den nye variablen skal ser ud. titanic_clean %&gt;% mutate(Adult = ifelse(Age&gt;=18,&quot;adult&quot;,&quot;child&quot;)) %&gt;% select(Age,Adult) %&gt;% glimpse() ## Rows: 714 ## Columns: 2 ## $ Age &lt;dbl&gt; 22, 38, 26, 35, 35, 54, 2, 27, 14, 4, 58, 20, 39, 14, 55, 2, 31,… ## $ Adult &lt;chr&gt; &quot;adult&quot;, &quot;adult&quot;, &quot;adult&quot;, &quot;adult&quot;, &quot;adult&quot;, &quot;adult&quot;, &quot;child&quot;, &quot;… Så er variablen lidt mere informativ end før. 5.7.6 rename() Man kan bruge rename() til at ændre navnet på en eller flere variabler i datasættet. Som eksempel bruger jeg rename() til at give en variable navnet Years i stedet for Age (bemærk at variablen Age findes ikke længere). titanic_clean %&gt;% rename(Years = Age) %&gt;% glimpse() ## Rows: 714 ## Columns: 11 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19… ## $ Survived &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1… ## $ Pclass &lt;int&gt; 3, 1, 3, 1, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 3, 2, 2, 3… ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Fl… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;mal… ## $ Years &lt;dbl&gt; 22, 38, 26, 35, 35, 54, 2, 27, 14, 4, 58, 20, 39, 14, 55, … ## $ SibSp &lt;int&gt; 1, 1, 0, 1, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 1, 0, 0, 0… ## $ Parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0… ## $ Ticket &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;37… ## $ Fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 51.8625, 21.0750… ## $ Embarked &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;… Man kan også ændre navne på flere kolonner samtidigt - for eksempel, i følgende laver jeg nogle oversættelsesarbejde: titanic_clean_dansk &lt;- titanic_clean %&gt;% rename(Overlevede = Survived, Navn = Name, Klasse = Pclass) Så du kan se, at jeg har ændrede de variabler navne. Jeg kalder den nye dataframe for titanic_clean_dansk, så jeg min danske udgave er blevet gemt et sted. Man kan også gøre sådan, at man har kun små bogstaver i de variabler navne. Jeg benytter den danske version, og Jeg anvender rename_with() og specificerer tolower. titanic_clean_dansk %&gt;% rename_with(tolower) %&gt;% #all variable names are lower case only glimpse() ## Rows: 714 ## Columns: 11 ## $ passengerid &lt;int&gt; 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19… ## $ overlevede &lt;int&gt; 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1… ## $ klasse &lt;int&gt; 3, 1, 3, 1, 3, 1, 3, 3, 2, 3, 1, 3, 3, 3, 2, 3, 3, 2, 2, 3… ## $ navn &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Fl… ## $ sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;mal… ## $ age &lt;dbl&gt; 22, 38, 26, 35, 35, 54, 2, 27, 14, 4, 58, 20, 39, 14, 55, … ## $ sibsp &lt;int&gt; 1, 1, 0, 1, 0, 0, 3, 0, 1, 1, 0, 0, 1, 0, 0, 4, 1, 0, 0, 0… ## $ parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 1, 2, 0, 1, 0, 0, 5, 0, 0, 1, 0, 0, 0, 0… ## $ ticket &lt;chr&gt; &quot;A/5 21171&quot;, &quot;PC 17599&quot;, &quot;STON/O2. 3101282&quot;, &quot;113803&quot;, &quot;37… ## $ fare &lt;dbl&gt; 7.2500, 71.2833, 7.9250, 53.1000, 8.0500, 51.8625, 21.0750… ## $ embarked &lt;chr&gt; &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;… Prøv også at erstatte tolower med toupper. 5.7.7 dplyr verbs: recode() Med recode() kan man ændre hvordan en variable ser ud - fk. male/female kan ændres til 0/1, som i følgende. titanic_clean %&gt;% mutate(Sex = recode(Sex, &quot;male&quot; = 0, &quot;female&quot; = 1)) %&gt;% select(PassengerId,Name,Sex) %&gt;% glimpse() ## Rows: 714 ## Columns: 3 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19… ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Fl… ## $ Sex &lt;dbl&gt; 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1… Bemærk den måde, at funktionen recode() er blevet brugt indenfor funktionen mutate(): jeg lavede en ny variable af samme navn, men med ændret værdier indenfor variablen. Hvis vi gerne vil skifter omvendt fra 0/1 til male/female er vi nødt til at skrive 1 / 0 for at specificie at vi har værdier som er tal, og vi gerne vil kalde dem for nogle andet (“male”/“female” i dette tilfælde): #recodes variable Sex and then recodes it back to original form again titanic_clean %&gt;% mutate(Sex = recode(Sex, male = 1, female = 0)) %&gt;% mutate(Sex = recode(Sex, `1` = &quot;male&quot;, `0` = &quot;female&quot;)) %&gt;% #note use of `` in the numbers select(PassengerId,Name,Sex) %&gt;% glimpse() ## Rows: 714 ## Columns: 3 ## $ PassengerId &lt;int&gt; 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19… ## $ Name &lt;chr&gt; &quot;Braund, Mr. Owen Harris&quot;, &quot;Cumings, Mrs. John Bradley (Fl… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;mal… 5.7.8 dplyr verbs: arrange() Man anvender arrange() for at vælge rækkefølgen på observationerne. I nedenstående tager vi datarammen titanic_clean og arrangerer observationer efter variablen Fare. Det sker således at, personer som betalt mindst er på toppen af de resultarende dataramme, og personer som betalt mest er på bunden. # Arrange by increasing Fare titanic_clean %&gt;% arrange(Fare) %&gt;% glimpse() ## Rows: 714 ## Columns: 11 ## $ PassengerId &lt;int&gt; 180, 264, 272, 303, 598, 807, 823, 379, 873, 327, 844, 819… ## $ Survived &lt;int&gt; 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0… ## $ Pclass &lt;int&gt; 3, 1, 3, 3, 3, 1, 1, 3, 1, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3… ## $ Name &lt;chr&gt; &quot;Leonard, Mr. Lionel&quot;, &quot;Harrison, Mr. William&quot;, &quot;Tornquist… ## $ Sex &lt;chr&gt; &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;m… ## $ Age &lt;dbl&gt; 36.0, 40.0, 25.0, 19.0, 49.0, 39.0, 38.0, 20.0, 33.0, 61.0… ## $ SibSp &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0… ## $ Parch &lt;int&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ Ticket &lt;chr&gt; &quot;LINE&quot;, &quot;112059&quot;, &quot;LINE&quot;, &quot;LINE&quot;, &quot;LINE&quot;, &quot;112050&quot;, &quot;19972… ## $ Fare &lt;dbl&gt; 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 4.… ## $ Embarked &lt;chr&gt; &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;S&quot;… Hvis man gerne vil få det omvendt - at personer som betalt mest er på toppen af datarammen, kan man bruge desc() omkring Fare, som i nedenstående: # Arrange by decreasing Fare titanic_clean %&gt;% arrange(desc(Fare)) %&gt;% glimpse() ## Rows: 714 ## Columns: 11 ## $ PassengerId &lt;int&gt; 259, 680, 738, 28, 89, 342, 439, 312, 743, 119, 300, 381, … ## $ Survived &lt;int&gt; 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1… ## $ Pclass &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ## $ Name &lt;chr&gt; &quot;Ward, Miss. Anna&quot;, &quot;Cardeza, Mr. Thomas Drake Martinez&quot;, … ## $ Sex &lt;chr&gt; &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;mal… ## $ Age &lt;dbl&gt; 35.00, 36.00, 35.00, 19.00, 23.00, 24.00, 64.00, 18.00, 21… ## $ SibSp &lt;int&gt; 0, 0, 0, 3, 3, 3, 1, 2, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1… ## $ Parch &lt;int&gt; 0, 1, 0, 2, 2, 2, 4, 2, 2, 1, 1, 0, 0, 0, 2, 1, 0, 1, 2, 1… ## $ Ticket &lt;chr&gt; &quot;PC 17755&quot;, &quot;PC 17755&quot;, &quot;PC 17755&quot;, &quot;19950&quot;, &quot;19950&quot;, &quot;199… ## $ Fare &lt;dbl&gt; 512.3292, 512.3292, 512.3292, 263.0000, 263.0000, 263.0000… ## $ Embarked &lt;chr&gt; &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;S&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;, &quot;C&quot;… 5.8 Visualisering: bruge som input i ggplot2 Efter man har lavet bearbejdning med tidyverse kommandoer, kan man specificere de resulterende dataframe som data i funktionen ggplot(). Man benytter %&gt;% til at forbinde de dpylr kommandoer med den ggplot funktion, og I dette tilfælde behøver man ikke at angive navnet på datasættet indenfor funktionen ggplot. I nedenstående eksempel tager jeg udgangspunkt i titanic_clean og så laver jeg et barplot som viser antallet af passagerer som rejste i hver af de tre klass. titanic_clean %&gt;% ggplot(aes(x=Pclass,fill=as.factor(Pclass))) + geom_bar(stat=&quot;count&quot;) + theme_minimal() Jeg gør det lidt mere kompliceret i følgende, ved at tage titanic_clean, lave en ny kolon der hedder Adult, og så bruge den resulterende dataframe med funktionen ggplot, hvor jeg laver et plot med Adult på x-aksen for at tælle op antallet af voksne og børn. titanic_clean %&gt;% mutate(Adult = ifelse(Age&gt;=18,&quot;Adult&quot;,&quot;Child&quot;)) %&gt;% ggplot(aes(x=Adult,fill=Adult)) + geom_bar(stat=&quot;count&quot;) + theme_minimal() Så viser det, at der var 600 Adults og lidt over 100 Children ombord skibet. 5.9 Misc funktioner som er nyttige at vide 5.9.1 Pull I tidyverse arbejder vi meget med dataframes - tilgagen er således at man tager udgangspunkt i en dataframe, får en dataframe som resultat og så arbejde videre på den dataframe. Nogle gange kan det dog være at man gerne vil udtrække en variabel som vector fra en dataframe, fk. hvis man gerne vil bruge den i en bestemt statistik metode. Se følgende eksempel, hvor man udtrække variable Age for “male” og “female” (variablen Sex) og bruge resulterende vectorer i en t-test sammenhæng: ages_male &lt;- titanic_clean %&gt;% filter(Sex==&quot;male&quot;) %&gt;% pull(Age) ages_female &lt;- titanic_clean %&gt;% filter(Sex==&quot;female&quot;) %&gt;% pull(Age) t.test(ages_male,ages_female) ## ## Welch Two Sample t-test ## ## data: ages_male and ages_female ## t = 2.5259, df = 560.05, p-value = 0.01181 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.6250732 4.9967983 ## sample estimates: ## mean of x mean of y ## 30.72664 27.91571 Så kan man se at mænd og kvinder har signifikant forskellige alder i gennemsnit (hvor mændene er ældre en kvinderne). 5.9.2 Slice Med funktionen Slice kan man kigge på nogle bestemte observationer, for eksempel, viser følgende de to passagerer der betalt mest for billeten (variable Fare). titanic %&gt;% arrange(desc(Fare)) %&gt;% select(Name,Age) %&gt;% slice(1,2) ## # A tibble: 2 × 2 ## Name Age ## &lt;chr&gt; &lt;dbl&gt; ## 1 Ward, Miss. Anna 35 ## 2 Cardeza, Mr. Thomas Drake Martinez 36 Se udvidet muligheder her: https://dplyr.tidyverse.org/reference/slice.html 5.10 Problemstillinger Problem 1) Lav quizzen på Absalon - “Quiz - tidyverse - part 1” Vi øver os med titanic. Inlæs datasættet og lav overstående oprydningen med følgende kode: library(tidyverse) library(titanic) titanic &lt;- as_tibble(titanic_train) titanic_clean &lt;- titanic %&gt;% select(-Cabin) %&gt;% drop_na() %&gt;% mutate(Adult = ifelse(Age&gt;=18,&quot;adult&quot;,&quot;child&quot;)) %&gt;% mutate(Survived = recode(Survived, `1` = &quot;yes&quot;, `0` = &quot;no&quot;)) glimpse(titanic_clean) #take a look! Problem 2) select(). Fjern variablen Name fra titanic_clean (du behøver ikke at gemme din nye dataframe). titanic_clean %&gt;% select(...) #redigere her Tilføj også glimpse() for at se et overblik (man kan også bruge head()) Problem 3) select(). Lave en ny dataframe fra titanic_clean med kun variabler Name, Pclass og Fare. Gør det en forskel, hvilke rækkefølger man skriver Name, Pclass og Fare? Problem 4) select() og hjælper funktoner. I stedet for at specificere bestemt kolonner navn, skriv starts_with(\"S\") indenfor select(). Hvad sker der? Prøv også contains(\"ar\") Prøv også -any_of(c(\"Survived\",\"Pclass\",\"FavouriteColour\")) og -all_of(c(\"Survived\",\"Pclass\",\"FavouriteColour\") i tilfældet af all_of skal alle variablerne i vectoren c(\"Survived\",\"Pclass\",\"FavouriteColour\") være i datasættet, ellers får man en advarsal. i tilfældet af any_of gælder det alle variabler fra vectoren c(\"Survived\",\"Pclass\",\"FavouriteColour\") der er i datasættet, og resten bliver ignoreret. Prøv også matches(\"^S[i|u]\") - kan du gisner på hvad det betyder (se nedenunder)? Problem 5) filter(). Lave en ny dataframe fra titanic_clean med alle passagerer som er mellem 10 og 15 og rejst enten første eller anden klass. Prøv at tilføje %&gt;% count() til kommandoen - Hvor mange observationer er der i den nye dataframe? Problem 6) filter() og select() : kombinering med %&gt;% Lave en ny dataramme fra titanic_clean med alle passagerer som er “male” og overlevede (variablen Survived er “yes”), og udvælg kun kolonner Name, Age og Fare. Problem 7) filter() og select() kombinering med %&gt;% Lave en ny dataramme fra titanic_clean med kun variabler Name og Age og dernæst specificere kun de passagerer som er over 60. Få man så den samme sæt observationer hvis du skriver dine select() og filter() funktionerne omvendt her? Hvorfor? Problem 8) Mutate(). Lave en ny dataframe fra titanic_clean som hedder FareRounded og viser Fare rundet til det nærmest integar (hint: benyt funktionen round()). Problem 9) Mutate() og ifelse(). Lave en ny dataramme fra titanic_clean med en ny kolon som hedder Family som angiver TRUE hvis Parch er ikke nul, ellers FALSE. Anvende ifelse til at gøre variablen mere intuitiv - “Family” og “Not family.” Problem 10) Mutate() og ifelse() Kig en gang til på beskrivelsen af følgende to variabler i datasættet: SibSp: The number of siblings/spouses aboard the titanic with the passenger Parch: The number of parents/children aboard the titanic with the passenger Lav en ny variabel Solo som viser “Yes” hvis passageren rejste alene, og “No” hvis passageren rejste med andre. Brug mutate igen til at lave den nye variabel om til at være en factor. Gem også dit output (som titanic_clean igen) så du kan bruge din nye variable videre i næste spørgsmål. titanic_clean &lt;- titanic_clean %&gt;% ... Problem 11) pull() og t.test() Betalte passagererne der rejste alene (variablen Solo fra sidste problem) den samme i gennemsnit for deres billet (variablen Fare) end passagererne der ikke rejste alene? Lav et t.test (anvend pull() til at udtrække hensigtsmæssige vectorer - se også eksempel i kursusnotaterne) t.test(titanic_clean %&gt;% filter(Solo==&quot;Yes&quot;) %&gt;% pull(Fare), titanic_clean %&gt;% filter(Solo==&quot;No&quot;) %&gt;% pull(Fare) ) ## ## Welch Two Sample t-test ## ## data: titanic_clean %&gt;% filter(Solo == &quot;Yes&quot;) %&gt;% pull(Fare) and titanic_clean %&gt;% filter(Solo == &quot;No&quot;) %&gt;% pull(Fare) ## t = -6.9703, df = 573.64, p-value = 8.724e-12 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## -35.57536 -19.93377 ## sample estimates: ## mean of x mean of y ## 22.64421 50.39878 Problem 12) Recode() I variablen Embarked: C står for Cherbourg Q står for Queenstown S står for Southampton a) Anvend recode (indenfor mutate) til at ændre værdierne i variablen Embarked således at man får de fulde navne af de steder folk gik ombord skibet, i stedet for kun den første bogstav. Gem også dit output (som titanic_clean igen) så du kan bruge din nye variable videre. b) Erstat recode med recode_factor og sammenlign datatypen af variablen Embarked i din nye dataframe. c) Prøv at tilføje funktionen count() for at tælle op hvor mange gik om bord i de forskellige steder. Prøv også med to variabler indenfor count() - Solo og Embarked Resultatet ser sådan ud: ## # A tibble: 7 × 3 ## Solo Embarked n ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 No &quot;Southampton&quot; 229 ## 2 No &quot;Queenstown&quot; 9 ## 3 No &quot;Cherbourg&quot; 72 ## 4 Yes &quot;Southampton&quot; 325 ## 5 Yes &quot;Queenstown&quot; 19 ## 6 Yes &quot;Cherbourg&quot; 58 ## 7 Yes &quot;&quot; 2 d) Man kan se, at der er to passagerer hvor der ikke er noget skrevet i Embarked. + Rejste de alene? + Lav en ny dataframe med de to passagerer fjernet fra datasættet. Problem 13) Arrange(). Lave en ny dataramme fra titanic_clean med observationerne arrangerede således at de yngst er på toppen og ældste er på bunden. Kig på resultatet - hvad kan du fortælle om den yngste passager ombord skibet Titanic? Hvad kan du fortælle om den ældste passager ombord skibet? Overlevede de? Hvad med de andre ældste passagerer? Problem 14) Arrange() og kombinering med andre verber. Lave en ny dataramme fra titanic_clean med kun personer med SibSp&gt;0 og som gik ombord skibet i Southampton, arrangere de resulterende observationer efter Fare (højeste på toppen) og udvælg kun kolonnerne Name, Age og Fare. Problem 15) Rename. Fra titanic_clean udvælg kun variabler Survived,Ticket, og Name og ændre deres navne til Overlevede, Billet og Navn. Gør variabler navne til store bogstaver ved at anvende rename_with(). Problem 16) Lave et plot. Fra titanic_clean bruge filter() til at lave en ny dataramme kun med personer under 30 og bruge den til at lave et barplot som viser antallet af personer opdelt efter Pclass. Bruge følgende struktur for koden: titanic_clean %&gt;% filter(...) %&gt;% #rediger linjen ggplot(aes(...)) + .... #tilføj plot Problem 17) Lave et plot. Fra titanic_clean, bruge mutate() til at lave et nyt kolon der hedder with_siblings_spouses der er TRUE hvis SibSp ikke er nul. Brug den til at lave boxplots som viser Fare på y-aksen og with_siblings_spouses på x-aksen. Ekstra: Ændre skalen på y-aksen for at gøre plottet klarer at fortolke. 5.11 Kommentarer matches(\"^S[i|u]\") betyder ^S variabel navn skal starter med en S [i|u] den næste bogstav i variabel navnet skal være enten i eller u OBS det er ikke vigtigt at lære pattern matching i kurset men det er meget brugbart i andre sammenhænge! Næste gange arbejder vi videre med tidyverse. Group_by kombinerede med Summarise Pivot_Longer/Pivot_Wider Join funktionerne "],["bearbejdning-dag-2.html", "Chapter 6 Bearbejdning dag 2 6.1 Indledning og læringsmålene 6.2 group_by() med summarise() i dplyr-pakken 6.3 pivot_longer()/pivot_wider() med Tidyr-pakken 6.4 Eksempel: Titanic summary statistics 6.5 left_join(): forbinde dataframes 6.6 Problemstillinger 6.7 Ekstra links", " Chapter 6 Bearbejdning dag 2 6.1 Indledning og læringsmålene I dag arbejder du videre med tidyverse, især på pakken dplyr og tidyr, som kan bruges til at ændre på strukturen af et datasæt, således at det passer til den struktur, som kræves for at blandt andet lave plots med ggplot2. Det er ofte tilfældet indenfor biologi, at man har sit data i et dataframe og nogle ekstra sample oplysninger i en anden dataframe. Derfor vil vi gerne have en måde, at forbinde de to dataframes i R, som gør, at vi kan inddrage de ekstra oplysninger når vi lave plots af de data. 6.1.1 Læringsmålene Du skal være i stand til at Benytte kombinationen af group_by() og summarise(). Forstå forskellen mellem wide og long data og bruge pivot_longer() til at facilitere plotting Benytte left_join() eller øvrige join funktioner til at tilføje sample information til datasættet. 6.1.2 Videoer Video 1 - vi skal kig lidt nærmere på group_by() + summarise() og forbinde tidyverse kode og ggplot2 kode sammen med %&gt;%/+. Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/546910681 Video 2 - wide/long data forms og pivot_longer() og bruge den i ggplot2 Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/707081191 Video 3 - eksempel med titanic summary statistics Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/707223997 Video 4: left_join() of tables with extra sample information and plot Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/707082269 6.2 group_by() med summarise() i dplyr-pakken Med kombination af group_by() med summarise() kan man finde numeriske svar på spørgsmålet: havde mænd eller kvinde en højre sandsynlighed for at overleve tragedien? Lad os starte med løsningen med tapply til at udregne proportionen af mænd og kvinde der overlevede: følgende kode svarer til, at man opdeler variablen Survived efter den katagoriske variable Sex og tager middelværdien. Det giver dermed proportionen der overlevede efter køn (da Survived er kodet sådan at 1 betyder at man overlevede og 0 betyder at man ikke overlevede). titanic_clean &lt;- titanic %&gt;% select(-Cabin) %&gt;% drop_na() #tapply løsning tapply(titanic_clean$Survived,titanic_clean$Sex,mean) ## female male ## 0.7547893 0.2052980 Lad os skifter over til den tidyverse løsning. Lad os tage udgangspunkt i summarise(): som et eksempel af hvordan man bruger funktionen, vil vi beregner en variable der hedder “medianFare” som er lig med median(fare). titanic_clean %&gt;% summarise(&quot;medianFare&quot;=median(Fare)) ## # A tibble: 1 × 1 ## medianFare ## &lt;dbl&gt; ## 1 15.7 Vi får faktisk en ny dataramme her, med kun variablen som vi lige har specificeret. Vi er interesseret i proportionen, der overlevede, så vi tager middelværdien af variablen Survived. Lad os gøre det med summarise(): titanic_clean %&gt;% summarise(meanSurvived = mean(Survived)) ## # A tibble: 1 × 1 ## meanSurvived ## &lt;dbl&gt; ## 1 0.406 Få at svare på spørgsmålet er vi også nødt til at opdele efter kolonnen Sex. Vi kan bruge den kombinering af group_by() og summarise() - vi opdele efter Sex ved at anvende funktionen group_by() og derefter bruger summarise() til at oprette en kolon der hedder meanSurvived, der viser proportionen der overlevede for female and male. #tidyverse løsning titanic_clean %&gt;% group_by(Sex) %&gt;% summarise(meanSurvived = mean(Survived)) ## # A tibble: 2 × 2 ## Sex meanSurvived ## &lt;chr&gt; &lt;dbl&gt; ## 1 female 0.755 ## 2 male 0.205 Lad os tage resultatet fra ovenpå og visualiserer det i et barplot, som i nedenstående: titanic_clean %&gt;% group_by(Sex) %&gt;% summarise(meanSurvived = mean(Survived)) %&gt;% ggplot(aes(x=Sex,y=meanSurvived,fill=Sex)) + geom_bar(stat=&quot;identity&quot;,show.legend = FALSE) + theme_minimal() 6.2.1 Reference af summarise() funktioner Nogle fuktioner man ofte bruge med summarise() (der er mange andre muligheder). fuktion beskrivelse mean() to give us the mean value of a variable. sd() to give us the standard deviation of a variable. min() giving us the lowest value of a variable. max() giving us the highest value of a variable. n() giving us the number of observations in a variable. and many more. first() first values 6.2.2 Flere summary statistic på én gang Vi kan også lave flere summary statistics på én gang. For eksempel, lad os anvende funktionen group_by med Sex igen, men beregner flere forskellige summary statistics: titanic_clean_summary_by_sex &lt;- titanic_clean %&gt;% group_by(Sex) %&gt;% summarise(count = n(), #count meanSurvived = mean(Survived), #middelværdi survived meanAge = mean(Age), #middelværdi age propFirst = sum(Pclass==1)/n()) #proportionen i første klass titanic_clean_summary_by_sex ## # A tibble: 2 × 5 ## Sex count meanSurvived meanAge propFirst ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 female 261 0.755 27.9 0.326 ## 2 male 453 0.205 30.7 0.223 Igen kan denne summary table bruges som et datasæt til at lave et plot med ggplot2. Bemærk at her bruger vi stat=\"identity\", fordi vi skal ikke tælle observationerne op, men bare plot præcis de tal som er i datarammen på y-aksen. I nedenstående laver vi barplots for meanAge og propFirst - de er plottet ved at bruge to forskellige ggplot kommandoer og bemærk, at det er plottet ved siden af hinanden med en funktion der hedder grid.arrange() fra R-pakken gridExtra. plotA &lt;- ggplot(data=titanic_clean_summary_by_sex,aes(x=Sex,y=meanAge,fill=Sex)) + geom_bar(stat=&quot;identity&quot;,show.legend = FALSE) + theme_minimal() plotB &lt;- ggplot(data=titanic_clean_summary_by_sex,aes(x=Sex,y=propFirst,fill=Sex)) + geom_bar(stat=&quot;identity&quot;,show.legend = FALSE) + theme_minimal() library(gridExtra) grid.arrange(plotA,plotB,ncol=2) #plot both together Vi kan se, at females var i gennemsnit lidt yngere end males, og havde en højere sandsynlighed for at være i første klass. Et interessant spørgsmål er, hvordan man kan lave ovenstående plots uden at bruge to forskellige ggplot kommandoer - altså, en automatiske løsning hvor vi kan plotte flere summary statistiks med kun én ggplot kommando. Vi kommer til at se hvordan man gøre det med at første lave datasættet om til long form. 6.2.3 Mere kompliceret group_by() Lad os også beregne hvor mange passagerer der var efter både deres klass, og hvor de gik ombord skibet: titanic_clean %&gt;% group_by(Embarked, Pclass) %&gt;% # group by multiple variables... summarise(count = n()) ## `summarise()` has grouped output by &#39;Embarked&#39;. You can override using the ## `.groups` argument. ## # A tibble: 10 × 3 ## # Groups: Embarked [4] ## Embarked Pclass count ## &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 &quot;&quot; 1 2 ## 2 &quot;C&quot; 1 74 ## 3 &quot;C&quot; 2 15 ## 4 &quot;C&quot; 3 41 ## 5 &quot;Q&quot; 1 2 ## 6 &quot;Q&quot; 2 2 ## 7 &quot;Q&quot; 3 24 ## 8 &quot;S&quot; 1 108 ## 9 &quot;S&quot; 2 156 ## 10 &quot;S&quot; 3 290 Man kan se at de flest gik om bord i Southampton (S), men der var også forholdsvis mange første klass passagerer der gik om bord i Cherbourg (C). Lad os gå videre med vores Survived eksempel og beregne proportionen der overlevede efter de tre variabler Adult, Sex og Pclass. titanic_clean_summary_survived &lt;- titanic_clean %&gt;% mutate(Adult = ifelse(Age&gt;=18,&quot;Adult&quot;,&quot;Child&quot;)) %&gt;% group_by(Adult,Sex,Pclass) %&gt;% summarise(meanSurvived = mean(Survived)) ## `summarise()` has grouped output by &#39;Adult&#39;, &#39;Sex&#39;. You can override using the ## `.groups` argument. titanic_clean_summary_survived ## # A tibble: 12 × 4 ## # Groups: Adult, Sex [4] ## Adult Sex Pclass meanSurvived ## &lt;chr&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; ## 1 Adult female 1 0.974 ## 2 Adult female 2 0.903 ## 3 Adult female 3 0.418 ## 4 Adult male 1 0.371 ## 5 Adult male 2 0.0682 ## 6 Adult male 3 0.133 ## 7 Child female 1 0.875 ## 8 Child female 2 1 ## 9 Child female 3 0.543 ## 10 Child male 1 1 ## 11 Child male 2 0.818 ## 12 Child male 3 0.233 Og så kan vi også bruge resultatet ind i en ggplot, hvor vi kombinerer de tre variabler og adskiller efter Pclass: ggplot(titanic_clean_summary_survived,aes(x=Sex,y=meanSurvived,fill=Adult)) + geom_bar(stat=&quot;identity&quot;,position = &quot;dodge&quot;) + facet_grid(~Pclass) + ylab(&quot;Proportion survived&quot;) + theme_bw() 6.2.4 Funktionen ungroup Nogle gange når man er færdig med en proces, men gerne vil arbejde videre på et dataframe, er det nyttigt at anvende ungroup() på datasættet igen. Det er meste relevant i længere projektor men som eksempel kig på følgende kode og bemærk at der står “Groups: Adult [2]” på toppen af den nye dataframe med summary statistics: titanic_clean_summary &lt;- titanic_clean %&gt;% mutate(Adult = ifelse(Age&gt;=18,&quot;Adult&quot;,&quot;Child&quot;)) %&gt;% group_by(Adult,Sex) %&gt;% summarise(meanSurvived = mean(Survived)) ## `summarise()` has grouped output by &#39;Adult&#39;. You can override using the ## `.groups` argument. titanic_clean_summary ## # A tibble: 4 × 3 ## # Groups: Adult [2] ## Adult Sex meanSurvived ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Adult female 0.772 ## 2 Adult male 0.177 ## 3 Child female 0.691 ## 4 Child male 0.397 Bemærk at vi først anvendte group_by på både Adult og Sex, men hver gange man lave en beregning bliver én opdeling fjernet - i dette tilfælde opdeler man ikke længere efter Sex men man stadig opdeler efter Adult. Det er ikke et problem hvis vi ikke vil arbejde videre med dataframen. Men forstil at vi gerne vil vide, hvad den maksimum chance for survival er ud fra de fire tal beregnede. Der vi ikke vil adskille efter en kategorisk variabel dropper vi group_by(): titanic_clean_summary %&gt;% summarise(&quot;maxChance&quot; = max(meanSurvived)) ## # A tibble: 2 × 2 ## Adult maxChance ## &lt;chr&gt; &lt;dbl&gt; ## 1 Adult 0.772 ## 2 Child 0.691 Man kan dog se, at outtputtet er blevet adskilt efter variablen Adult. For at undgå disse bør man første anvende ungroup for at få fjernet effekten af group_by(). titanic_clean_summary %&gt;% ungroup() %&gt;% summarise(&quot;maxChance&quot; = max(meanSurvived)) ## # A tibble: 1 × 1 ## maxChance ## &lt;dbl&gt; ## 1 0.772 6.3 pivot_longer()/pivot_wider() med Tidyr-pakken Tidy data findes i to former: wide data og long data. Det kan være nyttigt at transformere dataframen fra den ene form til den anden, for fk. at lave et bemstemt plot med ggplot2-pakken. Indenfor pakken tidyr er der funktioner som kan bruges til at lave disse transformeringer. Inden vi begynde at kigge lidt nærmere på tidyr skal vi beskrive, hvad betyder long data og wide data. Figure 6.1: source: https://www.garrickadenbuie.com/project/tidyexplain/ Wide data: Her har man en kolon til hver variabel og en række til hver observation. Det gøre de data nem at forstå og denne data type findes ofte indenfor biologi - for eksempel hvis man har forskellige samples (treatments, controls, conditions osv.) som variabler. Long data: Med long data har man værdier samlet i en enkel kolon og en kolon som en slags nøgle, som fortæller også hvilken variable hver værdi hørte til i den wide format. Datasættet er stadig betragtet som tidy men informationen opbevares på en anden måde. Det er lidt sværer at læse men nemmere at arbejde med når man analyser de data. Når man transformer data fra wide til long eller omvendt, kaldes det for reshaping. 6.3.1 Tidyr pakke - oversigt Her er en oversigt over de fire vigtigste funktioner fra R-pakken tidyr. Vi fokuserer mest på pivot funktionerne men det kan være nyttigt at bruge separate og unite en gang i mellem. tidr funktion Beskrivelse pivot_longer() short til long pivot_wider() long til short separate() opdele strings fra en kolon til to unite() tilføje strings sammen ind fra to til én kolon 6.3.2 Wide -&gt; Long med pivot_longer() Lad os arbejde med datasættet Iris. Man få Iris i long form med følgende kommando. Her vil man gerne tage alle numeriske kolonner og placerer deres værdier i en enkel kolon value (med en nøgle kolon name til at skelne imellem de forskellige variabler). iris %&gt;% pivot_longer(cols = where(is.numeric)) ## # A tibble: 600 × 3 ## Species name value ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 setosa Sepal.Length 5.1 ## 2 setosa Sepal.Width 3.5 ## 3 setosa Petal.Length 1.4 ## 4 setosa Petal.Width 0.2 ## 5 setosa Sepal.Length 4.9 ## 6 setosa Sepal.Width 3 ## 7 setosa Petal.Length 1.4 ## 8 setosa Petal.Width 0.2 ## 9 setosa Sepal.Length 4.7 ## 10 setosa Sepal.Width 3.2 ## # … with 590 more rows At beholde numeriske kolonner svarer i dette tilfælde til at man ikke vil have variablen Species med i den enkel kolon: iris %&gt;% pivot_longer(cols = -Species) ## # A tibble: 600 × 3 ## Species name value ## &lt;fct&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 setosa Sepal.Length 5.1 ## 2 setosa Sepal.Width 3.5 ## 3 setosa Petal.Length 1.4 ## 4 setosa Petal.Width 0.2 ## 5 setosa Sepal.Length 4.9 ## 6 setosa Sepal.Width 3 ## 7 setosa Petal.Length 1.4 ## 8 setosa Petal.Width 0.2 ## 9 setosa Sepal.Length 4.7 ## 10 setosa Sepal.Width 3.2 ## # … with 590 more rows Her er et billede der illustrerer wide og long form med datasættet iris: Figure 6.2: wide til long med Iris Til venstre har vi målingerne i datasættet over fire forskellige kolonner som hedder Sepal.Length, Sepal.Width, Petal.Length og Petal.Width, og en ekstra kolon der skelne imellem de tre Species. Til højre har vi fået alle målingerne ind i en enkel kolon der hedder values, og så bruger man en anden ‘nøgle’ kolon der hedder name til at fortælle os om det er en måling for Sepal.Length eller Sepal.Width osv. Jeg kan kalde de kolonner navne for målingerne og nøglen til nogle andre en default: for eksempel i nedenstående skal målingerne hedde measurements og nøglen hedde trait. iris.long &lt;- iris %&gt;% pivot_longer(cols = -Species, names_to = &quot;trait&quot;, values_to = &quot;measurement&quot;) Man kan for eksempel bruge den long form den til at visualisere samtlige mulige boxplots opdelt efter Species og trait på samme plot: ggplot(iris.long,aes(y=measurement,x=Species,fill=Species)) + geom_boxplot() + facet_grid(~trait) + theme_bw() 6.3.3 separate() Funktionen separate() fra pakken tidyr kan bruges til at opdele to forskellige dele som eksisterer i samme kolon. For eksempel, i iris har vi variabler med navne Sepal.Width, Sepal.Length osv. - man kan forestille sig, at opdele disse navne over to kolonner i stedet for en - fk. “Sepal” og “Width” i tilfældet af Sepal.Width. I nedenstående kan man se, hvordan man anvende separate(). iris %&gt;% pivot_longer(cols = -Species, names_to = &quot;trait&quot;, values_to = &quot;measurement&quot;) %&gt;% separate(col = trait, into = c(&quot;part&quot;, &quot;measure&quot;),sep = &quot;\\\\.&quot;) %&gt;% head() ## # A tibble: 6 × 4 ## Species part measure measurement ## &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 setosa Sepal Length 5.1 ## 2 setosa Sepal Width 3.5 ## 3 setosa Petal Length 1.4 ## 4 setosa Petal Width 0.2 ## 5 setosa Sepal Length 4.9 ## 6 setosa Sepal Width 3 Man specificerer variablen trait, og at det skal opdeles til to variabler part og measure. Vi angiver sep = \"\\\\.\" som betyder, at vi gerne vil have part som delen af trait foran ‘.’ og measure som delen af trait efter .. Vi bruger “\\.” til at fortælle, at vi er interesseret i punktum og ikke en “anonym character,” som punktum plejer at betyde i “string”-sprog. Man behøver faktisk ikke at specifice sep = \"\\\\.\" i dette tilfælde - som standard kigger funktionen efter ‘non-character’ tegne og bruger dem til at lave opdelingen. Samme resultat: iris %&gt;% pivot_longer(cols = -Species, names_to = &quot;trait&quot;, values_to = &quot;measurement&quot;) %&gt;% separate(col = trait, into = c(&quot;part&quot;, &quot;measure&quot;)) %&gt;% head() ## # A tibble: 6 × 4 ## Species part measure measurement ## &lt;fct&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 setosa Sepal Length 5.1 ## 2 setosa Sepal Width 3.5 ## 3 setosa Petal Length 1.4 ## 4 setosa Petal Width 0.2 ## 5 setosa Sepal Length 4.9 ## 6 setosa Sepal Width 3 Bruger resultatet i et plot: iris %&gt;% pivot_longer(cols = -Species, names_to = &quot;trait&quot;, values_to = &quot;measurement&quot;) %&gt;% separate(col = trait, into = c(&quot;part&quot;, &quot;measure&quot;)) %&gt;% ggplot(aes(y=measurement,x=part,fill=part)) + geom_boxplot() + facet_grid(~measure) + theme_bw() Se også unite() som gøre det modsatte til separate(). 6.4 Eksempel: Titanic summary statistics Her er et eksempel med datasættet titanic der inddrager mange af de tidyverse koncepter vi har lært indtil videre. group_by() og summarise() Vi laver vores summary statistics som i ovenstående. titanic_clean_summary_by_sex &lt;- titanic_clean %&gt;% group_by(Sex) %&gt;% summarise(count = n(), meanSurvived = mean(Survived), meanAge = mean(Age), propFirst = sum(Pclass==1)/n()) titanic_clean_summary_by_sex ## # A tibble: 2 × 5 ## Sex count meanSurvived meanAge propFirst ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 female 261 0.755 27.9 0.326 ## 2 male 453 0.205 30.7 0.223 pivot_longer() Vi transformerer eller reshape datarammen fra wide data til long data. Vi vil få kun de numeriske summary statistics samlede i en enkel kolonne, så variablen Sex skal indgå i den enkel kolonne. titanic_clean_summary_by_sex %&gt;% pivot_longer(cols=-Sex) ## # A tibble: 8 × 3 ## Sex name value ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 female count 261 ## 2 female meanSurvived 0.755 ## 3 female meanAge 27.9 ## 4 female propFirst 0.326 ## 5 male count 453 ## 6 male meanSurvived 0.205 ## 7 male meanAge 30.7 ## 8 male propFirst 0.223 ggplot() med facet_grid() Vi kombinerer pivot_longer() med et plot af vores summary statistics og benytte facet_grid() til at separere ved de forskellige statistiker. titanic_clean_summary_by_sex %&gt;% pivot_longer(cols=-Sex) %&gt;% ggplot(aes(x=Sex,y=value,fill=Sex)) + geom_bar(stat=&quot;identity&quot;) + facet_grid(~name) + theme_bw() facet_wrap() Vi laver den sammen som ovenstående men specificerer facet_wrap() i stedet for facet_grid() - indenfor facet_wrap() kan man bruge indstillingen scales=\"free\" som gøre, at de fire plots få hver deres egne akse limits. titanic_clean_summary_by_sex %&gt;% pivot_longer(cols=-Sex) %&gt;% ggplot(aes(x=Sex,y=value,fill=Sex)) + geom_bar(stat=&quot;identity&quot;) + facet_wrap(~name,scales=&quot;free&quot;,ncol=4) + theme_bw() 6.4.1 Demonstration af pivot_wider() Det er også brugbart at kende måden at man skifter fra long form til wide form. Wide -&gt; Long titanic_summary_long &lt;- titanic_clean_summary_by_sex %&gt;% pivot_longer(cols=-Sex) Long -&gt; Wide titanic_summary_long %&gt;% pivot_wider(names_from = &quot;name&quot;,values_from = &quot;value&quot;) ## # A tibble: 2 × 5 ## Sex count meanSurvived meanAge propFirst ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 female 261 0.755 27.9 0.326 ## 2 male 453 0.205 30.7 0.223 Parametre er: names_from - nøglekolon som skal udgør flere kolonner i den nye dataframe values_from - selve værdier, som skal være i de nye kolonner i den wide form 6.5 left_join(): forbinde dataframes Vi tager udgangspunkt i følgende to dataframes: gene_table &lt;- as_tibble(read.table(&quot;https://www.dropbox.com/s/6ll8ezrskly8joi/mouse_2gene_expr.txt?dl=1&quot;,header=T)) coldata &lt;- as_tibble(read.table(&quot;https://www.dropbox.com/s/jlrszakmqlnmu2m/bottomly_phenodata.txt?dl=1&quot;)) Lad os kigge først på datasættet gene_table, som viser genekspression målinger over forskellige samples i mus. gene_table ## # A tibble: 3 × 22 ## gene SRX033480 SRX033488 SRX033481 SRX033489 SRX033482 SRX033490 SRX033483 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ENSMUSG… 158. 182. 119. 155. 167. 164. 180. ## 2 ENSMUSG… 143. 118. 91.6 106. 157. 95.1 131. ## 3 ENSMUSG… 132. 117. 100. 116. 88.1 125. 124. ## # … with 14 more variables: SRX033476 &lt;dbl&gt;, SRX033478 &lt;dbl&gt;, SRX033479 &lt;dbl&gt;, ## # SRX033472 &lt;dbl&gt;, SRX033473 &lt;dbl&gt;, SRX033474 &lt;dbl&gt;, SRX033475 &lt;dbl&gt;, ## # SRX033491 &lt;dbl&gt;, SRX033484 &lt;dbl&gt;, SRX033492 &lt;dbl&gt;, SRX033485 &lt;dbl&gt;, ## # SRX033493 &lt;dbl&gt;, SRX033486 &lt;dbl&gt;, SRX033494 &lt;dbl&gt; Man kan se, at der er 22 kolonner i datasættet - én der refererer til et gen navn og 21 der er forskellige samples fra eksperimentet. Men det ikke er klart, hvad den enkel sample egentlig er. Lad os derfor kigge på de sample oplysninger, som kan være nyttige at inddrage i vores analyse/plotter for at undersøge eventualle batch effekter osv. coldata ## # A tibble: 21 × 5 ## sample num.tech.reps strain batch lane.number ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 SRX033480 1 C57BL.6J 6 1 ## 2 SRX033488 1 C57BL.6J 7 1 ## 3 SRX033481 1 C57BL.6J 6 2 ## 4 SRX033489 1 C57BL.6J 7 2 ## 5 SRX033482 1 C57BL.6J 6 3 ## 6 SRX033490 1 C57BL.6J 7 3 ## 7 SRX033483 1 C57BL.6J 6 5 ## 8 SRX033476 1 C57BL.6J 4 6 ## 9 SRX033478 1 C57BL.6J 4 7 ## 10 SRX033479 1 C57BL.6J 4 8 ## # … with 11 more rows Man kan se forskellige oplysninger om de 21 samples, blandt andet den strain af mus hver sample stammer fra og den batch. Her refererer batch på de forskellige omstændigheder eller tidspunkter de samples var blevet samlet. Hvis man er interesset i om der er en forskel i ekspressionsniveau mellem de to strains, kan det være, at man er nødt til at kontrolle efter batch for at sikre at forskellen skyldes strain og ikke tekniske effekter pga. batch. 6.5.1 Funktionen left_join() fra dplyr-pakken Funktionen left_join() er en del af pakken dplyr som vi har arbejdet meget med indtil videre i kurset. funktion Beskrivelse (kopiret left_join() Join matching rows from second table to the first right_join() Join matching rows from the first table to the second inner_join() Join two tables, returning all rows present in both full_join() Join data with all possible rows present Vi fokuserer her på funktionen left_join() fordi den er den meste brugbart i biologiske data analyser, men vi kigger også på de øvrige funktioner gennem problemstillingerne nedenunder. Her er en grafiske demonstration af left_join(): Figure 6.3: left_join graphical demonstration (source https://mgimond.github.io/ES218/Week03c.html) Det særligt med left_join i forhold til de andre funktioner, er at left_join bevarer samtlige data i dataframen man tager udgangspunkt i - det vil sige df i ovenstående billede, selvom d matchet ikke med en frugt i dj. I ovenstående genekspression eksempel betyder det, at man bevarer alle målinger i gene_table, uanset om der er oplysninger om deres pågældende samples. 6.5.2 Anvende left_join() for vores dataset. Ligesom man matcher kolonnen y i df og dj i ovenstående eksempel, skal vi også have en kolon vi kan matcher. Vi vil gerne bruge kolonnen sample fra sample_info til at sammenligne med de forskellige sample navne i gene_table, men første er vi nødt til at lave gene_table om til long-form, således at sample navne fremgår i en enkel kolon, sample (der kan bruges i left_join). gene_table_long &lt;- gene_table %&gt;% pivot_longer(cols = -gene, names_to = &quot;sample&quot;, values_to = &quot;expression&quot;) gene_table_long ## # A tibble: 63 × 3 ## gene sample expression ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 ENSMUSG00000006517 SRX033480 158. ## 2 ENSMUSG00000006517 SRX033488 182. ## 3 ENSMUSG00000006517 SRX033481 119. ## 4 ENSMUSG00000006517 SRX033489 155. ## 5 ENSMUSG00000006517 SRX033482 167. ## 6 ENSMUSG00000006517 SRX033490 164. ## 7 ENSMUSG00000006517 SRX033483 180. ## 8 ENSMUSG00000006517 SRX033476 263. ## 9 ENSMUSG00000006517 SRX033478 276. ## 10 ENSMUSG00000006517 SRX033479 328. ## # … with 53 more rows Dernæst kan vi tilføje oplysninger data fra sample_info. Her angiver vi by = \"sample\" fordi det er navnet til kolonnen som vi geerne vil bruge til at forbinde de to datarammer - altså, det er med i begge to datarammer, så left_join() kan bruge den som en slags nøgle til at vide, hvor alle de forskellige oplysninger skal tilføjes. data_join &lt;- gene_table_long %&gt;% left_join(coldata,by=&quot;sample&quot;) Nu at vi har fået forbundet de to datarammer, kan man inddrage de ekstra oplysninger vi har fået i et plot. Her laver vi et plot med en farve til hver strain og et plot med en farve til hver batch. gg2 &lt;- data_join %&gt;% ggplot(aes(y=expression,x=as.factor(strain),fill=gene)) + geom_boxplot() + facet_wrap(~gene,scales=&quot;free&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) + ggtitle(&quot;Expression split according to strain&quot;) gg2 gg1 &lt;- data_join %&gt;% ggplot(aes(y=expression,x=as.factor(batch),fill=gene)) + geom_boxplot() + facet_wrap(~gene,scales=&quot;free&quot;) + theme_minimal() + theme(legend.position = &quot;none&quot;) + ggtitle(&quot;Expression split according to batch&quot;) gg1 6.6 Problemstillinger Problem 1) Lav quizzen - “Quiz - tidyverse - part 2.” Vi øver os med titanic. Inlæs de data og lave oprydningen med følgende kode: library(tidyverse) library(titanic) titanic &lt;- as_tibble(titanic_train) titanic_clean &lt;- titanic %&gt;% select(-Cabin) %&gt;% drop_na() Problem 2) Fra titanic_clean beregn den gennemsnitlige alder af alle passagerer ombord skibet. titanic_clean %&gt;% summarise(....) #rediger her I samme kommando beregne også den maksimum alder og minimum alder, samt proportionen af passagerer, der er under 18 (for den sidste se mit eksempel med Pclass oven på). Dataframen skal ser sådan ud: ## # A tibble: 1 × 4 ## mean_alder max_alder min_alder under_18p ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 29.7 80 0.42 0.158 Problem 3) a) Beregne samme summary statistics som i sidste problem men anvende group_by() til at først opdeler efter variablen Pclass. b) Brug din nye summary statistikker dataframe til at lave et barplot med stat=\"identity\" som viser den gennemsnitlige alder på y-aksen opdelt efter Pclass på x-aksen (tænke lidt over data typen på Pclass) c) Anvend pivot_longer() på din summary statistikker dataframe (brug indstilling cols = -Pclass) d) Brug din long-form dataframe af summary statistikker til at lave plots af samtlige summary statistikker med én ggplot kommando (adskil dem ved at benytte facet og opdele efter Pclass indenfor hvert plot, ligesom i følgende). Problem 4) a) Beregne samme summary statistics som i 2) men anvende group_by() til at først opdele efter både variablerne Pclass og Sex. OBS: Man får en advarsel “summarise() has grouped output by ‘Pclass’ …” fordi din dataframe er stadig betragtet som opdelte efter Pclass, som du skal tage i betragtning hvis du laver flere beregninger på den. Brug til sidste ungroup() på din nye dataframe for at være sikker på, at den ikke længere er opdelt efter en variabel. b) Brug pivot_longer til at få datasættet i long form (tænk over hvilke variabler skal være i indstillingen cols - det kan hjælp at skrive dem i en vector med notationen c()). Nøglekolonnen skal hed stat og kolonnen med værdierne skal hed values. ## `summarise()` has grouped output by &#39;Pclass&#39;. You can override using the ## `.groups` argument. c) Lav et plot af samtlige summary statistikker, som er i long form og ser ud som følgende plot. Problem 5) group_by() med tre variabler og summarise(). Afprøv en kombination med tre forskellige variabler (vælg selv) indenfor group_by() og bruge summarise() til at beregne middelværdien for Fare. Anvend ungroup() når du er færdig med summarise Lave et plot for at visualisere meanFare. Idé: som mulighed kan man tilføje variabler til facet_grid() - for eksempel facet_grid(~Var1 + Var2). Problem 6) pivot_longer() Lav følgende plot Først lave to nye variabler fra SibSp og Parch, hvor der står “yes” hvis værdien er større end 0 select nødvendige variabler Lave om til long form (tænk over hvilke variabler skal være i en enkel kolon) Brug din long form dataframe til at lave plottet Problem 7) Pivot_wider() Vi har en tribble som jeg har kopiret fra https://r4ds.had.co.nz/index.html. people &lt;- tribble( ~name, ~names, ~values, #-----------------|--------|------ &quot;Phillip Woods&quot;, &quot;age&quot;, 45, &quot;Phillip Woods&quot;, &quot;height&quot;, 186, &quot;Jessica Cordero&quot;, &quot;age&quot;, 37, &quot;Jessica Cordero&quot;, &quot;height&quot;, 156, &quot;Brady Smith&quot;, &quot;age&quot;, 23, &quot;Brady Smith&quot;, &quot;height&quot;, 177 ) Brug pivot_wider() på people. Vi er nødt til at specificer som minimum names_from og values_from indenfor pivot_wider() - prøv at angiv de relevante variabler Problem 8) left_join() øvelse. Kør følgende kode med to tribbles: superheroes &lt;- tribble( ~name, ~alignment, ~gender, ~publisher, &quot;Magneto&quot;, &quot;bad&quot;, &quot;male&quot;, &quot;Marvel&quot;, &quot;Storm&quot;, &quot;good&quot;, &quot;female&quot;, &quot;Marvel&quot;, &quot;Mystique&quot;, &quot;bad&quot;, &quot;female&quot;, &quot;Marvel&quot;, &quot;Batman&quot;, &quot;good&quot;, &quot;male&quot;, &quot;DC&quot;, &quot;Joker&quot;, &quot;bad&quot;, &quot;male&quot;, &quot;DC&quot;, &quot;Catwoman&quot;, &quot;bad&quot;, &quot;female&quot;, &quot;DC&quot;, &quot;Hellboy&quot;, &quot;good&quot;, &quot;male&quot;, &quot;Dark Horse Comics&quot; ) publishers &lt;- tribble( ~publisher, ~yr_founded, &quot;DC&quot;, 1934L, &quot;Marvel&quot;, 1939L, &quot;Image&quot;, 1992L ) Vi har to dataframes - superheroes og publishers. Hvilken kolon kan man bruge til at forbinde de to dataframes? Brug left_join() til at tilføje oplysninger fra publishers til datarammen superheroes. Få man alle observationerne fra dataframen superheroes med i din nye dataframe? Benyt inner_join() til at forbinde publishers til superheroes - få man så nu alle observationer med denne gang? Benyt full_join() til at forbinde publishers til superheroes - hvor mange observationer få man med nu? Hvorfor? Problem 9) left_join() øvelse. Køre nedenstående kode, hvor der er to dataframes - iris2 og sample_table. Dataframen iris2 er ikke særlig informativ med hensyn til hvad de forskellige samples egentlige er, men oplysningerne om dem står i sample_table. Brug left_join() til at tilføje sample_table til iris2 for at få en dataramme som indeholder både de data og de samples oplysninger. data(iris) iris2 &lt;- as_tibble(iris) names(iris2) &lt;- c(&quot;sample1&quot;,&quot;sample2&quot;,&quot;sample3&quot;,&quot;sample4&quot;,&quot;Species&quot;) samp_table &lt;- tribble( ~sample, ~part, ~measure, #------|-------|--------# &quot;sample1&quot;, &quot;Sepal&quot;, &quot;Length&quot;, &quot;sample2&quot;, &quot;Sepal&quot;, &quot;Width&quot;, &quot;sample3&quot;, &quot;Petal&quot;, &quot;Length&quot;, &quot;sample4&quot;, &quot;Sepal&quot;, &quot;Width&quot; ) iris2 %&gt;% glimpse() ## Rows: 150 ## Columns: 5 ## $ sample1 &lt;dbl&gt; 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4.8, 4.… ## $ sample2 &lt;dbl&gt; 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3.4, 3.… ## $ sample3 &lt;dbl&gt; 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1.6, 1.… ## $ sample4 &lt;dbl&gt; 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0.2, 0.… ## $ Species &lt;fct&gt; setosa, setosa, setosa, setosa, setosa, setosa, setosa, setosa… samp_table %&gt;% glimpse() ## Rows: 4 ## Columns: 3 ## $ sample &lt;chr&gt; &quot;sample1&quot;, &quot;sample2&quot;, &quot;sample3&quot;, &quot;sample4&quot; ## $ part &lt;chr&gt; &quot;Sepal&quot;, &quot;Sepal&quot;, &quot;Petal&quot;, &quot;Sepal&quot; ## $ measure &lt;chr&gt; &quot;Length&quot;, &quot;Width&quot;, &quot;Length&quot;, &quot;Width&quot; Problem 10) Separate() øvelse Tag udgangspunkt i datasættet titanic_clean og benyt funktionen Separate() til at opdele variablen Name ind til to variabler, “Surname” og “Rest” (Godt råd: brug sep=\", \" for at undgå, at man få en unødvendig mellemrum lige før “Rest”). Anvend Separate() en gang til, men for at opdele variablen Rest into to variabler, “Title” og “Names.” Hvad bruger man som sep? (Hint: brug “\\\\” foran en punktum). Beregn summary statistikker for hver “Title” - mange passagerer, gennemsnits alder, proportionen der overlevede, og proportionen der rejste i første klass. Arrange din ny dataframe efter hvor mange personer der er for hver “Title” - mest på toppen og mindst på bunden. Problem 11) Valgfri ekstra: lav en ny dataramme med alle passagerer, der hedder “Alice” eller “Elizabeth” (brug Google her). Problem 12) Analyse og visualisering af biologiske datasæt konkurrence! Når du færdig med ovenstående husk at få lavet dit plot til konkurrencen!! Se siden på Absalon for yderligere detaljer 6.7 Ekstra links Cheatsheet: https://github.com/rstudio/cheatsheets/blob/master/data-import.pdf "],["functional-programming-med-purrr-pakken.html", "Chapter 7 Functional programming med purrr-pakken 7.1 Inledning og læringsmålene 7.2 Iterativ processer med map() fuktioner 7.3 Custom fuktioner 7.4 Nesting nest() 7.5 Andre brugbar purrr 7.6 Problemstillinger 7.7 Ekstra notater og næste gang", " Chapter 7 Functional programming med purrr-pakken 7.1 Inledning og læringsmålene Emnet handler om hvordan man kan inddrage funktioner for at øge reproducebarhed og gennemskuelighed i dine analyser. Det er ofte tilfældet i biologi, at man har flere datasæts eller variabler, der referer fk. til forskellige samples, replikator eller batches, og man gerne vil lave præcis samme proces på dem alle sammen samtidig. I dette emne beskæftiger du dig med især pakken Purrr og map() funktioner, som kan benyttes til at lave gentagne baserende analyser i R. 7.1.1 Læringsmålene I skal være i stand til at: Anvende map() - funktioner til at udføre beregninger iterativt over flere kolonner group_by() og nest() til at lave reproducerbar analyser over forskellige dele af datasættet. Kombinere map() og map2() med custom funktioner for at øge fleksibilitet i analyserne. 7.1.2 Video ressourcer Video 1: Introduction to map functions for iterating over columns Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/549630848 Video 2: Introduction to custom functions and combining them with map Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/549630825 Video 3: Introduction to nest functions for breaking data into sections Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/549630798 7.2 Iterativ processer med map() fuktioner Når man lave en interativ proces, vil man gerne lave samme ting gentagne gange. Det kan være for eksempel, at vi har ti variabler og vi gerne vil beregne middelværdien for hver variable. Vi arbejder med datasættet eukaryotes, som indeholder oplysninger om forskellige organismer som hører til eukaryotes - for eksempel deres navne, gruppe, sub-gruppe, antal proteins/genes, genom størrelse og så videre. Man kan få de data indlæste med følgende kommando og se en list over for de forskellige kolon navne nedenfor. eukaryotes &lt;- read_tsv(&quot;https://www.dropbox.com/s/3u4nuj039itzg8l/eukaryotes.tsv?dl=1&quot;) ## Rows: 11508 Columns: 19 ## ── Column specification ──────────────────────────────────────────────────────── ## Delimiter: &quot;\\t&quot; ## chr (10): organism_name, bioproject_accession, group, subgroup, assembly_ac... ## dbl (7): taxid, bioproject_id, size_mb, gc, scaffolds, genes, proteins ## date (2): release_date, modify_date ## ## ℹ Use `spec()` to retrieve the full column specification for this data. ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message. Vi tager udgangspunkt i kun fire variabler, så for at gøre tingene mere overskuelige, har jeg brugt select() til at kun får de fire variabler organism_name,center,group og subgroup i en dataframe #eukaryotes_full &lt;- eukaryotes eukaryotes_subset &lt;- eukaryotes %&gt;% select(organism_name, center, group, subgroup) eukaryotes_subset %&gt;% glimpse() ## Rows: 11,508 ## Columns: 4 ## $ organism_name &lt;chr&gt; &quot;Pyropia yezoensis&quot;, &quot;Emiliania huxleyi CCMP1516&quot;, &quot;Arab… ## $ center &lt;chr&gt; &quot;Ocean University&quot;, &quot;JGI&quot;, &quot;The Arabidopsis Information … ## $ group &lt;chr&gt; &quot;Other&quot;, &quot;Protists&quot;, &quot;Plants&quot;, &quot;Plants&quot;, &quot;Plants&quot;, &quot;Plan… ## $ subgroup &lt;chr&gt; &quot;Other&quot;, &quot;Other Protists&quot;, &quot;Land Plants&quot;, &quot;Land Plants&quot;,… Lad os forestille os, at vi gerne vil beregne antallet af unikke organismer (variablen organism_name). Der er en funktion der hedder n_distinct som beregner antallet af unikke værdier i en vector/variable. Her vælger vi organism_name og så tilføjer n_distinct(). eukaryotes_subset %&gt;% select(organism_name) %&gt;% n_distinct() ## [1] 6111 Lad os forestille os, at vi også er interesseret i antallet af unikke værdier i variablerne center, group og subgroup - som er de tre andre kolonner i datasættet. Vi har forskellige muligheder: Skrive dem ud - men hvad nu hvis vi havde 100 variabler at håndtere? eukaryotes_subset %&gt;% select(organism_name) %&gt;% n_distinct() eukaryotes_subset %&gt;% select(center) %&gt;% n_distinct() eukaryotes_subset %&gt;% select(group) %&gt;% n_distinct() eukaryotes_subset %&gt;% select(subgroup) %&gt;% n_distinct() ## [1] 6111 ## [1] 2137 ## [1] 5 ## [1] 19 Vi kræver en mere automatiske løsning på det. Vi bruger ikke tid på det her, men der er den traditionele programmering løsning: for loop, som fungerer også i R: col_names &lt;- names(eukaryotes_subset) for(column_name in col_names) { print(eukaryotes_subset %&gt;% select(column_name) %&gt;% n_distinct()) } ## Note: Using an external vector in selections is ambiguous. ## ℹ Use `all_of(column_name)` instead of `column_name` to silence this message. ## ℹ See &lt;https://tidyselect.r-lib.org/reference/faq-external-vector.html&gt;. ## This message is displayed once per session. ## [1] 6111 ## [1] 2137 ## [1] 5 ## [1] 19 Man i teorien kan holde sig til for loops men jeg vil gerne præsentere den tidyverse løsning, som bliver mere intuitiv og nemmere for ændre at læse koden når man er vant til det (det integrerer også bedre med de andre tidyverse pakker). 7.2.1 Introduktion til map() funktioner Den tidyverse løsning er såkaldte de map() funktioner, som er en del af pakken purrr. Jeg introducerer dem her frem for de base-R løsninger ikke bare fordi de er tidyverse, men fordi de er en meget fleksibelt og nemt at forstå tilgang, når man vænner sig til dem. Jeg viser hvordan de fungere igennem eukaryotes og bagefter introducerer dem i konteksten af custom funktioner og nest() som kan bruges til at opdele datasættet indtil forskellige dele (ovenpå hvori man kan gentage samme process). Man anvender map() ved at angiv funktionen navn n_distinct indenfor map(), og map() beregner n_distinct() for hver kolon i datasættet. eukaryotes_subset %&gt;% map(n_distinct) #do &#39;n_distinct&#39; for every single column ## $organism_name ## [1] 6111 ## ## $center ## [1] 2137 ## ## $group ## [1] 5 ## ## $subgroup ## [1] 19 Så kan man se, at vi har fået en list tilbage, med en tal som viser antallet af unikke værdier til hver af de fire kolonner. Det fungerer lidt som den base-R funktion apply, men med apply skal man bruge 2 i anden plads til at fortælle, at vi gerne vil iterate over kolonnerne. apply(eukaryotes_subset,2,n_distinct) ## organism_name center group subgroup ## 6111 2137 5 19 Bemærk at vi har fået her en vector af tal tilbage, men vi fået en list med map. Der er faktisk andre varianter af map som kan benyttes til at give resultatet som andre data typer. For eksempel, kan man bruge map_dbl() til at få en double dbl tilbage - en vector af tal ligesom vi fået med apply i ovenstående. # Apply n_distinct to all variables, returning a double eukaryotes_subset %&gt;% map_dbl(n_distinct) ## organism_name center group subgroup ## 6111 2137 5 19 Man kan også bruge map_df() for at få en dataramme (tibble) tilbage - det er særligt nyttigt for os, fordi vi tager altid udgangspunkt i en dataramme når vi skal få lavet et plot. # Apply n_distinct to all variables, returning a dataframe eukaryotes_subset %&gt;% map_df(n_distinct) ## # A tibble: 1 × 4 ## organism_name center group subgroup ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 6111 2137 5 19 For eksempel, kan man tilføje de tal fra map_df direkte ind i et ggplot. eukaryotes_subset %&gt;% map_df(n_distinct) %&gt;% pivot_longer(everything(), names_to = &quot;variable&quot;, values_to = &quot;count&quot;) %&gt;% ggplot(aes(x = variable, y = count,fill = variable)) + geom_col() + coord_flip() + theme_minimal() 7.2.2 Reference for the different map functions Funktion Beskrivelse map_lgl() returns a logical map_int() returns an integer vector map_dbl() returns a double vector map_chr() returns a character vector map_df() returns a data frame 7.3 Custom fuktioner Vi kan lave vores egne funktioner og betnytter dem indenfor map til at yderligere øge fleksibiliteten i R. For eksempel, kan det være at vi har en bestemt idé overfor, hvordan vi gerne vil normalisere vores data, og der eksisterer ikke en relevant funktion indenfor R i forvejen. 7.3.1 Simple functions Vi starter med en simpel funktion fra base-R og så forklare den i den table bagefter. Vi bruger mest en anden form af funktioner i tidyverse som vi kigger på næste, men koncepten er den samme. my_function &lt;- function(.x) { return(sum(.x)/length(.x)) } Kode Beskrivelse my_function_name funktion navn &lt;- function(.x) fortæl R, at vi lave en funktion med nogle data .x sum(.x)/length(.x) brug data .x til at beregne middelværdi return() hvad funktionen skal output - her middelværdi Lad også afprøve vores nye funccion ved at beregne den gennemsnitlige værdi for Sepal.Length i iris. my_function(iris$Sepal.Length) mean(iris$Sepal.Length) ## [1] 5.843333 ## [1] 5.843333 7.3.2 Custom functions with mapping Indenfor den tidyverse bruger man en lidt anden måde at skrive samme funktion på. my_function &lt;- ~ sum(.x)/length(.x) ~ betyder at vi definere en funktion .x betyder de data, der vi angiver funktionen (for eksempel variablen Sepal.Length fra iris). Man bruger den symbol .x hver gang og R ved automatiske hvad det betyder. Vi kan bruge my_function indenfor map() for at beregne den gennemsnitlige værdi for alle variabler (uden Species), og vi kan se at vi få tilsvarende resultat til funktionen mean(): iris %&gt;% select(-Species) %&gt;% map_df(my_function) iris %&gt;% select(-Species) %&gt;% map_df(mean) ## # A tibble: 1 × 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.84 3.06 3.76 1.20 ## # A tibble: 1 × 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.84 3.06 3.76 1.20 Man kan også placere funktionen direkte indenfor map_df i stedet for at kalde den for nogle (fk. my_funktion): iris %&gt;% select(-Species) %&gt;% map_df(~ sum(.x)/length(.x)) #for each data column, compute the sum and divide by the length ## # A tibble: 1 × 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 5.84 3.06 3.76 1.20 Vi kan godt specificere andre funktioner. iris %&gt;% map_df(~nth(.x,10)) #tag hver kolon, kalde det for .x og finde 10. værdi ## # A tibble: 1 × 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 4.9 3.1 1.5 0.1 setosa eller når nth is a tidyverse funktion kan vi bruge %&gt;%: iris %&gt;% map_df(~.x %&gt;% nth(10)) #tag hver kolon, kalde det for .x og finde 10. værdi ## # A tibble: 1 × 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; ## 1 4.9 3.1 1.5 0.1 setosa Antallet af distinkt værdier som ikke er NA: #tag hver kolon, kalde det for .x og beregne n_distinct iris %&gt;% map_df(~.x %&gt;% n_distinct(na.rm = TRUE)) #n_dinstict er fra tidyverse ## # A tibble: 1 × 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 35 23 43 22 3 Bemærk at hvis det er en indbygget funktion og vi benytter default parametre (altså na.rm = FALSE i ovenstående) kan man bare skrive: iris %&gt;% map_df(n_distinct) ## # A tibble: 1 × 5 ## Sepal.Length Sepal.Width Petal.Length Petal.Width Species ## &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 35 23 43 22 3 Et andet eksempel: tilføje 3 og square: iris %&gt;% select(-Species) %&gt;% map_df(~(.x + 3)^2) %&gt;% head() ## # A tibble: 6 × 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 65.6 42.2 19.4 10.2 ## 2 62.4 36 19.4 10.2 ## 3 59.3 38.4 18.5 10.2 ## 4 57.8 37.2 20.2 10.2 ## 5 64 43.6 19.4 10.2 ## 6 70.6 47.6 22.1 11.6 Jo mere funktionen bliver indviklet, jo mere mening det giver at specificere den udenfor den map() funktion: my_function &lt;- ~(.x - mean(.x))^2 + 0.5*(.x - sd(.x))^2 #a long pointless function iris %&gt;% select(-Species) %&gt;% map_df(my_function) #beregne my_function for hver kolon og output en dataramme ## # A tibble: 150 × 4 ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 9.68 4.89 5.63 1.16 ## 2 9.18 3.29 5.63 1.16 ## 3 8.80 3.84 6.15 1.16 ## 4 8.66 3.55 5.13 1.16 ## 5 9.41 5.30 5.63 1.16 ## 6 10.6 6.71 4.24 0.705 ## 7 8.66 4.51 5.63 0.916 ## 8 9.41 4.51 5.13 1.16 ## 9 8.46 3.06 5.63 1.16 ## 10 9.18 3.55 5.13 1.43 ## # … with 140 more rows 7.3.3 Effekten af map på andre data typer I ovenstående fokuser jeg på map i forhold til dataframes. I group_by + nest i nedenstående anvender man map() på en list af dataframes, der hedder data, der tillader os at arbejde med datasæt hvert for sig. Det er derfor værd at tage lidt tid på at se hvordan map() behandler forskellige data typer. input: vector .x referes til en værdi i vectoren. Hvis man tager integer 1:10 og anvender map, så tager man hvert tal hver for sig og beregner en funktion med det - i følgende simulere man et tal fra den normale fordeling med indstillingen mean=.x: c(1:10) %&gt;% map_dbl(~rnorm(1,mean=.x)) ## [1] 1.982341 1.460212 5.566752 4.225571 6.115275 5.748129 9.289555 ## [8] 7.149355 7.900811 11.354384 input: dataframe .x refereres til en variable fra dataframe. I ovenståene er første variable int1 og i map tager man den første element med funktionen pluck(1). tibble(&quot;int1&quot;=1:10,&quot;int2&quot;=21:30) %&gt;% map(~.x %&gt;% pluck(1)) ## $int1 ## [1] 1 ## ## $int2 ## [1] 21 Med nest kigger vi på den mulighed vore man laver map over en list, som bliver lavet med funktionen nest(). input: list .x referes til et list element - i nedenstående er den første element c(1,2) så hvis man anvender funktionen max så tager man maksimum værdi (2 i dette tilfælde). list(c(1,2),c(2,3),c(3,4)) %&gt;% map(~max(.x)) ## [[1]] ## [1] 2 ## ## [[2]] ## [1] 3 ## ## [[3]] ## [1] 4 Bemærk at der der kommer kun et tal som resultat, kan man map_dbl i stedet for map - så får man en vector som outputtet, selvom inputtet er en list. list(c(1,2),c(2,3),c(3,4)) %&gt;% map_dbl(~max(.x)) ## [1] 2 3 4 list af dataframe .x referes til et datasæt - så kan man referer til de forskellige variabler i .x som man plejer i tidyverse. Følgende er ligesom i tilfælde med koncepten “nesting” i næste sektion. Man tager en list af tibbles og vælger det første tal fra variablen int. list(tibble(&quot;int&quot;=1:10),tibble(&quot;int&quot;=1:10),tibble(&quot;int&quot;=1:10)) %&gt;% map_int(~.x %&gt;% pluck(&quot;int&quot;,1)) ## [1] 1 1 1 7.4 Nesting nest() Vi kommer til at se i næste lektion, at det er meget nyttige at bruge funktionen nest() for at få svar på adskillige statistiske spørgsmål. Det kan være for eksempel: Vi har lavet 10 eksperimental under lidt forskellige konditioner, og gerne vil lave præcis samme analyse på alle 10. Vi har 5 forskellige type bakterier med 3 replikater til hver, og gerne vil transformere de data på samme måde efter bakterien og replikat. Funktionen nest() kan virke lidt abstract i starten men koncepten er faktisk ret simpelt. Vi kan opelde vores datasæt (som indeholder vores forskellige konditioner/replikats etc.) med group_by() og så bruge nest() til at gemme de opdelt “sub” datasæt i en list. De bliver gemt indenfor en kolon i en tibble, og det gøre det bekvemt at arbejde med de forskellige datasæt på samme tid (med hjælp af map()). Lad os opdele eurkaryotes_subset efter variablen ‘group’ og anvende nest(): eukaryotes_subset_nested &lt;- eukaryotes_subset %&gt;% group_by(group) %&gt;% nest() eukaryotes_subset_nested ## # A tibble: 5 × 2 ## # Groups: group [5] ## group data ## &lt;chr&gt; &lt;list&gt; ## 1 Other &lt;tibble [51 × 3]&gt; ## 2 Protists &lt;tibble [888 × 3]&gt; ## 3 Plants &lt;tibble [1,304 × 3]&gt; ## 4 Fungi &lt;tibble [6,064 × 3]&gt; ## 5 Animals &lt;tibble [3,201 × 3]&gt; Vi kan se at vi har to variabler - group og data. Variablen data er indeholde faktisk fem dataramme (tibble), for eksempel den første datasæt har kun observationerne hvor group er lig med “Other,” den anden dataset har kun observationerne hvor group er lig med “Protists” osv. Vi kan tjekke ved at kig på den første datasæt: her er to måder at gøre det på: first_dataset &lt;- eukaryotes_subset_nested$data[[1]] first_dataset &lt;- eukaryotes_subset_nested %&gt;% pluck(&quot;data&quot;,1) first_dataset %&gt;% head() ## # A tibble: 6 × 3 ## organism_name center subgroup ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Pyropia yezoensis Ocean University Other ## 2 Thalassiosira pseudonana CCMP1335 Diatom Consortium Other ## 3 Guillardia theta CCMP2712 JGI Other ## 4 Cyanidioschyzon merolae strain 10D National Institute of Genetics… Other ## 5 Galdieria sulphuraria Galdieria sulphuraria Genome P… Other ## 6 Phaeodactylum tricornutum CCAP 1055/1 Diatom Consortium Other Hvis vi gerne vil tilbage til vores oprindeligt datasæt, kan vi brug unnest() og specificer kolonnen data: eukaryotes_subset_nested %&gt;% unnest(data) %&gt;% head() ## # A tibble: 6 × 4 ## # Groups: group [1] ## group organism_name center subgroup ## &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Other Pyropia yezoensis Ocean University Other ## 2 Other Thalassiosira pseudonana CCMP1335 Diatom Consortium Other ## 3 Other Guillardia theta CCMP2712 JGI Other ## 4 Other Cyanidioschyzon merolae strain 10D National Institute of Ge… Other ## 5 Other Galdieria sulphuraria Galdieria sulphuraria Ge… Other ## 6 Other Phaeodactylum tricornutum CCAP 1055/1 Diatom Consortium Other Spørgsmålet er: hvordan kan vi inddrage “nested” data indenfor vores analyser? 7.4.1 Anvende map() med nested data De fleste gange vi arbejder med nested data, er fordi vi gerne vil lave samme ting på hver af de “sub” datasæt. Derfor hænger det sammen med funktionen map(). Den typiske process er: Tag nested datasæt Tilføj en ny kolon med mutate(), hvor vi: Tag hver datasæt fra kolonnen data og brug map(), i nedenstående tilfælde til at finde antallet af rækkerne. eukaryotes_subset_nested %&gt;% mutate(n_row = map_dbl(data,nrow)) ## # A tibble: 5 × 3 ## # Groups: group [5] ## group data n_row ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; ## 1 Other &lt;tibble [51 × 3]&gt; 51 ## 2 Protists &lt;tibble [888 × 3]&gt; 888 ## 3 Plants &lt;tibble [1,304 × 3]&gt; 1304 ## 4 Fungi &lt;tibble [6,064 × 3]&gt; 6064 ## 5 Animals &lt;tibble [3,201 × 3]&gt; 3201 Vi kan også bruge en custom funktion. I nedenstående beregne man antallet af unikke organisme fra variablen orangism_name i datasættet. Husk: ~ betyder at vi lave en funktion, som kommer til at fungere for alle de fem datasæt. Tag et datasæt og kalde det for .x - det referer til en bestemt datasæt fra en af de fem datasæt som hører under kolonnen data i den nest() data. Vælg variablen organism_name fra .x Beregn n_dinstinct n_distinct_organisms &lt;- ~ .x %&gt;% #take data select(organism_name) %&gt;% #select organism name n_distinct #give back distinct #repeat function for each of the five datasets: eukaryotes_subset_nested %&gt;% mutate(n_organisms = map_dbl(data, n_distinct_organisms)) ## # A tibble: 5 × 3 ## # Groups: group [5] ## group data n_organisms ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; ## 1 Other &lt;tibble [51 × 3]&gt; 35 ## 2 Protists &lt;tibble [888 × 3]&gt; 490 ## 3 Plants &lt;tibble [1,304 × 3]&gt; 673 ## 4 Fungi &lt;tibble [6,064 × 3]&gt; 2926 ## 5 Animals &lt;tibble [3,201 × 3]&gt; 1987 Her er en anden eksempel. Her handler det om de eukaryotes data (ikke den subset), som har oplysninger om fk. GC-content med variablen gc. Her bruger vi pull i stedet for select - det er næsten den samme men med pull() få vi en vector som fungerer med median som er en base-R funktion. # func_gc &lt;- ~ .x %&gt;% # pull(gc) %&gt;% # ligesom select men vi har bruge for en vector for at beregne median # median(.x,na.rm=T) # `na.rm` fjerne `NA` værdier) func_gc &lt;- ~median(.x %&gt;% pull(gc),na.rm=T) ekaryotes_gc_by_group &lt;- eukaryotes %&gt;% group_by(group) %&gt;% nest() %&gt;% mutate(&quot;median_gc&quot;=map_dbl(data, func_gc)) ekaryotes_gc_by_group ## # A tibble: 5 × 3 ## # Groups: group [5] ## group data median_gc ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; ## 1 Other &lt;tibble [51 × 18]&gt; 46.7 ## 2 Protists &lt;tibble [888 × 18]&gt; 49.4 ## 3 Plants &lt;tibble [1,304 × 18]&gt; 37.9 ## 4 Fungi &lt;tibble [6,064 × 18]&gt; 47.5 ## 5 Animals &lt;tibble [3,201 × 18]&gt; 40.6 Og jeg kan bruge resultatet ind i et plot ligesom vi plejer: ekaryotes_gc_by_group %&gt;% ggplot(aes(x=group,y=median_gc,fill=group)) + geom_bar(stat=&quot;identity&quot;) + coord_flip() + theme_minimal() flere statistik på en gang Lave funktionerne: func_genes &lt;- ~median(.x %&gt;% pull(genes), na.rm=T) func_proteins &lt;- ~median(.x %&gt;% pull(proteins),na.rm=T) func_size &lt;- ~median(.x %&gt;% pull(size_mb), na.rm=T) Anvende nest(): eukaryotes_nested &lt;- eukaryotes %&gt;% group_by(group) %&gt;% nest() Tilføje resultatet over de fem datasæt med mutate(): eukaryotes_stats &lt;- eukaryotes_nested %&gt;% mutate(mean_genes = map_dbl(data,func_genes), proteins = map_dbl(data,func_proteins), mean_size_mb = map_dbl(data,func_size)) Husk at fjerne kolonnen data før man anvende pivot_longer() (ellers får man en advarsel): eukaryotes_stats %&gt;% select(-data) %&gt;% pivot_longer(-group) %&gt;% ggplot(aes(x=group,y=value,fill=group)) + geom_bar(stat=&quot;identity&quot;) + facet_wrap(~name,scales=&quot;free&quot;,ncol=4) + theme_bw() 7.5 Andre brugbar purrr 7.5.1 map2() function for flere inputs Funktionen map2() kan bruges ligesom map() men tager 2 “input” i stedet for kun én. I følgende eksempel angiver jeg to kolonner fra datasættet eukaryotes_stats, mean_genes og proteins og beregner sum, som bliver lagret takket være funktionen mutate som colstat. eukaryotes_stats %&gt;% mutate(colstat = map2_dbl(mean_genes,proteins,sum)) ## # A tibble: 5 × 6 ## # Groups: group [5] ## group data mean_genes proteins mean_size_mb colstat ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Other &lt;tibble [51 × 18]&gt; 11354. 11240. 49.7 22594 ## 2 Protists &lt;tibble [888 × 18]&gt; 8813 8628. 33.5 17442. ## 3 Plants &lt;tibble [1,304 × 18]&gt; 33146. 37660 358. 70806. ## 4 Fungi &lt;tibble [6,064 × 18]&gt; 10069 10034 32.2 20103 ## 5 Animals &lt;tibble [3,201 × 18]&gt; 20733 25161 692. 45894 Bemærk at præcis samme resultat kan fås ved at bare lægger de to kolonner sammen: eukaryotes_stats %&gt;% mutate(colstat2 = mean_genes + proteins) ## # A tibble: 5 × 6 ## # Groups: group [5] ## group data mean_genes proteins mean_size_mb colstat2 ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Other &lt;tibble [51 × 18]&gt; 11354. 11240. 49.7 22594 ## 2 Protists &lt;tibble [888 × 18]&gt; 8813 8628. 33.5 17442. ## 3 Plants &lt;tibble [1,304 × 18]&gt; 33146. 37660 358. 70806. ## 4 Fungi &lt;tibble [6,064 × 18]&gt; 10069 10034 32.2 20103 ## 5 Animals &lt;tibble [3,201 × 18]&gt; 20733 25161 692. 45894 Der er dog mange mere indviklet situationer hvor man ikke kan gå udenom map2: eukaryotes_stats_with_plots &lt;- eukaryotes_stats %&gt;% mutate(log10_genes = map(data,~log10(.x %&gt;% pull(genes)))) %&gt;% mutate(myplots = map2(group,log10_genes, ~ tibble(&quot;log10_genes&quot;=.y) %&gt;% ggplot(aes(x=log10_genes)) + geom_density(colour=&quot;red&quot;,alpha=0.3) + theme_bw() + ggtitle(paste(&quot;Density plot of log10(genes) in&quot;,.x)))) eukaryotes_stats_with_plots %&gt;% pluck(&quot;myplots&quot;,2) ## Warning: Removed 613 rows containing non-finite values (stat_density). Der er flere map funktion der tager flere input fk. pmap - jeg har ikke tid til at dække dem men du kan godt læse om dem hvis du har bruge for dem: https://purrr.tidyverse.org/reference/map2.html 7.5.2 Transformer numeriske variabler Som sidste bemærk, her er en brugbar variant af map - her kan man lave noget på kun bestemte variabler - for eksempel i følgende anvender jeg funktionen log2() på alle numeriske variabler. Bemærk at man er nødt til at anvende as_tibble() igen bagefter (som kun fungerere hvis alle variabler har stadig samme længde efter map_if()): eukaryotes %&gt;% map_if(is.numeric,~log2(.x)) %&gt;% as_tibble() ## # A tibble: 11,508 × 19 ## organism_name taxid bioproject_acce… bioproject_id group subgroup size_mb ## &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; ## 1 Pyropia yezoensis 11.4 PRJNA589917 19.2 Other Other 6.75 ## 2 Emiliania huxley… 18.1 PRJNA77753 16.2 Prot… Other P… 7.39 ## 3 Arabidopsis thal… 11.9 PRJNA10719 13.4 Plan… Land Pl… 6.90 ## 4 Glycine max 11.9 PRJNA19861 14.3 Plan… Land Pl… 9.94 ## 5 Medicago truncat… 11.9 PRJNA10791 13.4 Plan… Land Pl… 8.69 ## 6 Solanum lycopers… 12.0 PRJNA119 6.89 Plan… Land Pl… 9.69 ## 7 Hordeum vulgare … 16.8 PRJEB34217 19.1 Plan… Land Pl… 12.1 ## 8 Oryza sativa Jap… 15.3 PRJNA12269 13.6 Plan… Land Pl… 8.55 ## 9 Triticum aestivum 12.2 PRJNA392179 18.6 Plan… Land Pl… 13.9 ## 10 Zea mays 12.2 PRJNA10769 13.4 Plan… Land Pl… 11.1 ## # … with 11,498 more rows, and 12 more variables: gc &lt;dbl&gt;, ## # assembly_accession &lt;chr&gt;, replicons &lt;chr&gt;, wgs &lt;chr&gt;, scaffolds &lt;dbl&gt;, ## # genes &lt;dbl&gt;, proteins &lt;dbl&gt;, release_date &lt;date&gt;, modify_date &lt;date&gt;, ## # status &lt;chr&gt;, center &lt;chr&gt;, biosample_accession &lt;chr&gt; 7.6 Problemstillinger Problem 1) Lave Quiz på Absalon “Quiz - functional programming” Problem 2) map() øvelse Eksempel: diamonds %&gt;% select(cut,color,depth) %&gt;% map_df(n_distinct) ## # A tibble: 1 × 3 ## cut color depth ## &lt;int&gt; &lt;int&gt; &lt;int&gt; ## 1 5 7 184 Husk også referencen med de forskellige varianter af map() som kan bruges for at få en anden output type. Indlæse diamonds med data(diamonds). Brug map() funktioner til at beregne følgende: a) Select variabler cut, color og clarity og beregne antallet af distinkt værdier til hver (anvende funktionen n_distinct). Resultatet skulle være en list (anvende deault map() funktion). b) Select variabler som er numeriske og beregne den median værdi til hver. Resultatet skal være en double. c) Brug alle variabler og return de datatyper (funktion en typeof). Resultatet skal være en dataramme. Problem 3) map() øvelse med custom funktioner Indlæse diamonds med data(diamonds). Husk at når man inddrager nogle data .x, for eksempel når man vil bruge en custom funktion eller specificer non-default indstillinger såsom na.rm=TRUE (for at fjerne NA værdier i beregningen) i funktionen, skal man angiv ~ i starten: diamonds %&gt;% map_df(n_distinct) #specificere funktion unden instillinger diamonds %&gt;% map_df(~n_distinct(.x,na.rm = TRUE)) #custom funktion a) Afprøve følgende kode linjer og beskrive hvad der sker. diamonds %&gt;% select(carat, depth, price) %&gt;% map_df(~mean(.x,na.rm=T)) diamonds %&gt;% filter(cut==&quot;Ideal&quot;) %&gt;% select(&quot;color&quot;,&quot;clarity&quot;) %&gt;% map(~nth(.x,100)) diamonds %&gt;% select(carat, depth, price) %&gt;% map_df(~ifelse(.x&gt;mean(.x),&quot;big_value&quot;,&quot;small_value&quot;)) Brug custom funktioner indenfor map() til at beregne følgende: Udvælg variabler carat, depth, table og price og for hver kolonne tilføj tre og så dernæst tag square (^2). Resultatet skal være en dataramme. Udvælg numeriske variabler og angiv TRUE hvis den først værdi i kolonnen (betegnet med nth(.x,1)) er større en den median værdi i kolonnen, ellers FALSE. Resultatet skal være en logical. Problem 4) map på forskellige datatyper Vi har set, at når vi kører map på en dataframe, laver man en funktion over hver kolonne. Lad os se hvad der forgår hvis man har andre datatyper: a) (En vector af tal) Kør følgende - hvad sker der? c(1:10) %&gt;% map_dbl(~rnorm(1,mean=.x,sd=1)) Tag udangspunkt i c(1:10) og anvend map_dbl til at beregne den log() af hvert tal i vektoren (angiv indstillingen base=5): c(1:10) %&gt;% ??? b) (En list af tibbles) my_list_of_tibbles &lt;- list( tibble(&quot;letter&quot; = c(&quot;a&quot;,&quot;a&quot;,&quot;a&quot;), &quot;number&quot; = c(1,3,3)), tibble(&quot;letter&quot; = c(&quot;a&quot;,&quot;b&quot;,&quot;b&quot;), &quot;number&quot; = c(3,3,1)), tibble(&quot;letter&quot; = c(&quot;a&quot;,&quot;b&quot;,&quot;a&quot;), &quot;number&quot; = c(2,3,3))) Kør følgende kode, der tager den første tibble udvælger observationer hvor letter = “a” og dernæst beregner den middelværdi af “number.” my_list_of_tibbles %&gt;% pluck(1) %&gt;% filter(letter==&quot;a&quot;) %&gt;% summarise(mn = mean(number)) Nu at jeg kan se, at min kode virker til den første tibble, kan jeg ændre den til en funktion og anvende den med map() til at lave samme process på alle dataframes - prøve at køre følgende. my_list_of_tibbles %&gt;% map(~.x %&gt;% filter(letter==&quot;a&quot;) %&gt;% summarise(mn = mean(number))) Tag udgangspunkt i my_list_of_tibbles og for hver tibble select alle tilfælde hvor variaben number er 3 og dernæst optæl hvor mange a er tilbage i variablen letter (man kan afprøve på den første tibble hvis det hjælper). Problem 5) group_by/nest øvelse a) For datasættet iris, anvend group_by(Species) og tilføj dernæst nest(), og kigger på resultatet. b) tilføj pull(data) og se på resultatet fjern pull(data) og tilføj pluck(\"data\",1) i stedet for, for at se den første dataramme. tilføj unnest(data) i stedet for og se på resultatet tilføj følgende i stedet for og prøve at forstå hvad der sker: mutate(new_column_nrow = map_dbl(data,nrow)) mutate(new_column_ratio = map(data,~(.x$Sepal.Width/.x$Sepal.Length))) b) Skift mellem long og wide form Afprøv også følgende funktion med map()-funktionen på kolonnen data (angiv ny kolonnenavne new_column_long i mutate()). #add an id and put data into long form my_func_longer &lt;- ~.x %&gt;% mutate(id=1:50) %&gt;% pivot_longer(cols=-id) Skriv en funktion og anvend den på kolonnen new_column_long, der laver hvert datasæt i kolonnen om til wide-form igen (lav ny kolonne “new_column_wide”). my_func_wider &lt;- ??? #lave long data om til wide form (husk at angiv names_from,values_from,id_cols) iris_nested_stats %&gt;% ???#anvend din funktion Anvend pluck på kolonnerne new_column_long og new_column_wide til at kigge på den første datasæt for at se, om du har outputtet i long/wide form som forventede. Problem 6) group_by/nest + map på datasættet mtcars a) Åbn mtcars med data(mtcars) og anvende group_by()/nest() for at opdele datasættet i tre efter variablen cyl. b) Lave nye kolonner med map og inddrage hensigtsmæssige funktioner, som beskriver dine tre datasæt, der er lagret i kolonne data (outputtet skal være dbl): Antal observationer Korrelationskoefficient mellem wt og drat (funktionen cor) Antal unikke værdier fra variablen gear c) Omsætte dine statistikke til et plot for at sammenligne de tre datasæt. Problem 7) Forberedelse til næste lektion For at bedre kunne se værdien af at bruge group_by()/nest() + map() kan vi gennemgå en simpel eksampel som indledning til vores næste lektion. Tag funktionen: my_func &lt;- ~ t.test(.x$Petal.Width,.x$Sepal.Length) anvend group_by(Species) og dernæst nest() på datasættet iris. tilføj mutate() til at lave en ny kolon som hedder t_test og bruge funktionen indenfor map() på kolonnen data. tilføj pull(t_test) til din kommando - man får de tre t-tests frem, som man lige har beregnet. prøv unnest(t_test) i stedet for pull(t_test) - man får en advarsel fordi de t-test resultater ikke er i en god form til at vise indenfor en dataramme. Vi vil gerne ændre deres output til tidy-form først. Nu installer R-pakken broom (install.packages(\"broom\")) Lav samme som ovenstående men bruge følgende funktion i stedet for (glance() få statistikkerne fra t.test() ind i en pæn form (tidy)) library(broom) my_func &lt;- ~ t.test(.x$Petal.Width,.x$Sepal.Length) %&gt;% glance() Tilføj pull eller unnest til din kommando som før og se på resultatet. Man får en pæn dataramme frem med alle de forskellige statistikker fra t.test(). Vælge en statistik og omsætte den til et plot. Problem 8) Hvis du færdig før tid kan du se videorne til næste emne i morgen :) 7.7 Ekstra notater og næste gang https://r4ds.had.co.nz/iteration.html https://sanderwuyts.com/en/blog/purrr-tutorial/ "],["visualisering-af-trends.html", "Chapter 8 Visualisering af trends 8.1 Indledning og læringsmålene 8.2 nest() og map(): eksempel med korrelation 8.3 Lineær regression - visualisering 8.4 Plot linear regresion estimates 8.5 Multiple regression and model comparison 8.6 Problemstillinger 8.7 Ekstra", " Chapter 8 Visualisering af trends #load following packages library(ggplot2) library(tidyverse) library(broom) library(glue) library(ggsignif) 8.1 Indledning og læringsmålene 8.1.1 Læringsmålene Du skal være i stand til at Anvende nest() og map() strukturen til at gentage en korrelation analyse over flere forskellige datasæt. Bruge ggplot funktion geom_smooth() til at visualisere lineær regression eller loess-kurver. Kombinere map()/nest() og lm() til at beregne regression statistikker for flere lineær regression modeller på samme tid og sammenligne dem med anova(). 8.1.2 Introduktion til chapter I dette kapitel viser jeg flere eksempler på processen, hvor man anvender group_by() og nest() og dernæst map()-funktioner for at lave reproducebar statistiske analyser. Vi fokuserer på eksempler med korrelationanalyse og lineær regression modeller, men den overordnede ramme kan anvendes i mange forskellige kontekster. 8.1.3 Video ressourcer OBS der er mange videoer til i dag men de gentager samme process fra sidste emner med group_by/nest og map mange gange (med forskellige statistike metoder). Video 1: Korrelation koefficient med nest() og map() Jeg gennemgår processen langsomt med en korrelationsanalyse Jeg introducerer glance til at lave outputtet fra statistikse methoder i tidy-form. OBS: Jeg sagde “antal gener” flere gange i videoen men variablen log10_size_mb er faktisk genomstørrelse i megabases. Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/709225323 Video 2: Lineær regression linjer med ggplot2 Jeg viser hvordan man tilføjer regression linjer på et plot Jeg sammenligne linjen med resultatet fra lm() Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/709225203 Video 3: Lineær regression med nest() og map() Den proces igen fra Video 1 men anvendte på lineær regression Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/709225158 Video 4: Multiple linær regression model Sammen processen men med flere modeller og multiple uafhængige variabler Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/709225266 Video 5: anova+map (OBS muligvis mest udfordrende del i kurset) Benytte funktionen anova for at sammenligne to modeller beregnede på datasættet penguins og få outputtet i “tidy”-form med fuktionen tidy() Lave en funktion med anova, der kan anvendes over alle arter med map2() Omsætte p-værdier fra sammenligningerne til et plot og tilføj signifikans annotations Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/710108716 8.2 nest() og map(): eksempel med korrelation Man laver en korrelationsanalyse i R ved at benytte cor.test() (cor() virker også hvis du kun vil beregne koefficient og ikke signifikans). Forestille dig at du gerne vil finde ud af korrelationen mellem GC-indehold (variablen gc, procent G/C bases i genomet) og genomstørrelse (variablen log10_size_mb) i datasættet eukaryotes fra sidste lektion. I følgende plotter jeg en density mellem gc og den transformerede variable log10_size_mb som er log10 genomstørrelse (ikke antal gener, som jeg sagde i videoen). eukaryotes &lt;- eukaryotes %&gt;% mutate(log10_size_mb = log10(size_mb)) eukaryotes %&gt;% mutate(log10_size_mb = log10(size_mb)) %&gt;% select(log10_size_mb,gc) %&gt;% pivot_longer(everything()) %&gt;% ggplot(aes(x=value,fill=name)) + geom_density(colour=&quot;black&quot;) + facet_wrap(~name,scales=&quot;free&quot;) + theme_bw() ## Warning: Removed 388 rows containing non-finite values (stat_density). Plottet ser ud til at have flere “peaks” og jeg mistænker, at der kan være nogle sub-struturer indenfor de data - ekempelvis pga. de forskellige organismer grupper i variablen Group (Animals, Plants osv.). I følgende benytter jeg alligevel cor.test() til at teste for korrelation mellem gc og log10_size_mb over hele datasæt: my_cor_test &lt;- cor.test(eukaryotes %&gt;% pull(gc), eukaryotes %&gt;% pull(log10_size_mb)) my_cor_test ## ## Pearson&#39;s product-moment correlation ## ## data: eukaryotes %&gt;% pull(gc) and eukaryotes %&gt;% pull(log10_size_mb) ## t = -15.678, df = 11118, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## -0.1652066 -0.1288369 ## sample estimates: ## cor ## -0.1470715 Outputtet fra cor.test (og mange andre metoder i R) er ikke særlig egnet til at bruge indenfor en dataframe, så jeg introducerer en funktion der hedder glance() som findes i R-pakken broom. Funktionen glance() anvendes til at tage outputtet fra en statistiske test (fk. cor.test() eller lm()) og lave det om til et tidy dataramme. Det gør det nemmere eksempelvis til at lave et plot, eller samler op statistikker fra forskellige tests. library(broom) my_cor_test %&gt;% glance() FALSE # A tibble: 1 × 8 FALSE estimate statistic p.value parameter conf.low conf.high method alternative FALSE &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; FALSE 1 -0.147 -15.7 8.25e-55 11118 -0.165 -0.129 Pearson&#39;… two.sided Man kan se, at over hele datasættet, er der en signifikant negativ korrelation (estimate -0.147 og p-værdi 8.25054^{-55}) mellem de to variabler. Men jeg er imidlertid stadig mistænksom overfor eventuelle forskelligheder blandt de fem grupper fra variablen group. Jeg vil gerne gentage den samme analyse for de fem grupper fra variablen group hver for sig. En god tilgang til at undersøge det er at bruge den ramme med group_by() og nest() som vi lært sidste gange. 8.2.1 Korrelation over flere datasæt på en gang Jeg tjekker først fordelingen af de to variabler opdelt efter variablen group: eukaryotes %&gt;% select(log10_size_mb,gc,group) %&gt;% pivot_longer(-group) %&gt;% ggplot(aes(x=value,fill=group)) + geom_density(colour=&quot;black&quot;,alpha=0.5) + #geom_histogram(bins=40,alpha=0.5,colour=&quot;black&quot;) + scale_fill_brewer(palette = &quot;Set1&quot;) + facet_wrap(~name,scales=&quot;free&quot;) + theme_bw() ## Warning: Removed 388 rows containing non-finite values (stat_density). Man kan se, at der er forskelligheder blandt de fem grupper og der sagtens kan forekommer forskellige sammenhænge mellem de to variabler. Jeg benytter i følgende den group_by() + nest() ramme som blev introducerede sidste lektion. Step 1: Benytte group_by() + nest() Jeg anvender group_by() på variablen group og så funktionen nest() for at adskille eukaryotes i fem forskellige datasæt (lagrede i samme dataframe i en kolonne der hedder data): eukaryotes_nest &lt;- eukaryotes %&gt;% group_by(group) %&gt;% nest() eukaryotes_nest ## # A tibble: 5 × 2 ## # Groups: group [5] ## group data ## &lt;chr&gt; &lt;list&gt; ## 1 Other &lt;tibble [51 × 19]&gt; ## 2 Protists &lt;tibble [888 × 19]&gt; ## 3 Plants &lt;tibble [1,304 × 19]&gt; ## 4 Fungi &lt;tibble [6,064 × 19]&gt; ## 5 Animals &lt;tibble [3,201 × 19]&gt; Step 2: Definere korrelation funktion Lad os definere den korrelation test mellem gc og log10_size_mb i en funktion. Brug ~ lige i starten for at fortælle R, at man arbejder med en funktion. Specificer et bestemt datasæt (som er en delemængde af eukaryotes) indenfor cor.test() med .x For det bestemt datasæt benytter jeg .x %&gt;% pull(gc) og .x %&gt;% pull(size_mb) til at udtrække de relevante vectorer for at udføre testen cor.test. cor_test &lt;- ~cor.test(.x %&gt;% pull(gc), .x %&gt;% pull(log10_size_mb)) Vi vil gerne få statistikker fra cor.test() i en pæn form så vi tilføjer glance() til ovenstående funktion: library(broom) my_cor_test &lt;- ~cor.test(.x$gc,log10(.x$size_mb)) %&gt;% glance() Step 3: Bruge map() på det nested datasæt Nu lad os køre vores funktion på den nested dataframe. Vi bruger map() til at lave funktionen my_cor_test for hvert af de fem datasæt. Det gøres ved at bruge funktionen map() indenfor funktionen mutate() til at oprette en ny kolonne, der hedder test_stats, hvor resultaterne for hver af de fem tests lagres. eukaryotes_cor &lt;- eukaryotes_nest %&gt;% mutate(test_stats=map(data,my_cor_test)) eukaryotes_cor ## # A tibble: 5 × 3 ## # Groups: group [5] ## group data test_stats ## &lt;chr&gt; &lt;list&gt; &lt;list&gt; ## 1 Other &lt;tibble [51 × 19]&gt; &lt;tibble [1 × 8]&gt; ## 2 Protists &lt;tibble [888 × 19]&gt; &lt;tibble [1 × 8]&gt; ## 3 Plants &lt;tibble [1,304 × 19]&gt; &lt;tibble [1 × 8]&gt; ## 4 Fungi &lt;tibble [6,064 × 19]&gt; &lt;tibble [1 × 8]&gt; ## 5 Animals &lt;tibble [3,201 × 19]&gt; &lt;tibble [1 × 8]&gt; Step 4: Anvende unnest() for at kunne se resultaterne For at kunne se statistikerne bruger jeg funktionen unnest() på den nye variabel test_stats: eukaryotes_cor &lt;- eukaryotes_cor %&gt;% unnest(test_stats) eukaryotes_cor ## # A tibble: 5 × 10 ## # Groups: group [5] ## group data estimate statistic p.value parameter conf.low conf.high ## &lt;chr&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Other &lt;tibble&gt; 0.489 3.80 4.22e- 4 46 0.238 0.679 ## 2 Protists &lt;tibble&gt; 0.301 9.26 1.54e- 19 860 0.239 0.361 ## 3 Plants &lt;tibble&gt; -0.203 -7.37 3.10e- 13 1267 -0.255 -0.149 ## 4 Fungi &lt;tibble&gt; 0.377 31.2 3.87e-198 5884 0.355 0.399 ## 5 Animals &lt;tibble&gt; 0.0437 2.42 1.57e- 2 3053 0.00825 0.0790 ## # … with 2 more variables: method &lt;chr&gt;, alternative &lt;chr&gt; Step 5: Lave et plot fra statistikker Vi kan bruge den direkte i et plot. Jeg fokuserer på den korrelaton koefficient i variablen estimate og omsætte den til et plot som i følgende: cor_plot &lt;- eukaryotes_cor %&gt;% ggplot(aes(x=group,y=estimate,fill=group)) + geom_bar(stat=&quot;identity&quot;,colour=&quot;black&quot;) + scale_fill_brewer(palette = &quot;Set3&quot;) + ylab(&quot;Corrlation estimate&quot;) + theme_classic() cor_plot Bemærk at den overordnede process her med cor.test ligner processen hvis man anvender andre metoder såsom t.test, lm osv. Jeg gennemgår lidt om lineær regression og visualisering, og dernæst anvende processen på et eksempel med funktionen lm() og datasættet penguins. 8.3 Lineær regression - visualisering 8.3.1 Lineær trends Vi skifter over til datasættet penguins som findes i pakken palmerpenguins. Man kan se i følgende scatter plot mellem bill_length_mm og body_mass_g, at der er plottet en bedste rette linje igennem punkterne, som viser, at der er en positiv sammenhæng mellem de to variabler. ## `geom_smooth()` using formula &#39;y ~ x&#39; Husk at den bedste rette linje har en formel \\(y = a + bx\\), hvor \\(a\\) er den “intercept” (skæringspunktet) og \\(b\\) er den “slope” (hældningen) af linjen, og idéen med simpel lineær regression er, at man gerne vil finde de bedste mulige værdier for \\(a\\) og \\(b\\) for at plotte ovenstående linje således, at afstanden mellem linjen og punkterne bliver minimeret. Uden at gå i detaljer om hvordan det beregnes, husk at man bruger funktionen lm() som i følgende: mylm &lt;- lm(body_mass_g~bill_length_mm,data=penguins) mylm ## ## Call: ## lm(formula = body_mass_g ~ bill_length_mm, data = penguins) ## ## Coefficients: ## (Intercept) bill_length_mm ## 388.85 86.79 Intercept er således 388.85 og slope er 86.79 - det betyder, at hvis variablen bill_length_mm stiger ved 1, så ville den forventede body_mass_g stiger ved 86.79. Man kan således bruge linjen til at lave forudsigelser. For eksempel, hvis jeg målet en ny pingvin og fandt ud af, at den havde en bill_length_mm af 50 mm, kunne jeg bruge min linje som den bedste gætte på dens body_mass_g: y &lt;- mylm$coefficients[1] + mylm$coefficients[2] * 50 y ## (Intercept) ## 4728.433 Jeg forventer derfor en pingvin med en bill længde af 50 mm til at have vægten omkring 4728.4331411 g: ## `geom_smooth()` using formula &#39;y ~ x&#39; 8.3.2 geom_smooth(): lm trendlinjer Indbygget i ggplot2 er en funktion der hedder geom_smooth() som kan bruges til at tilføje den bedste rette linje til plottet. Man benytter den ved at specificere + geom_smooth(method=\"lm\") indenfor plot-kommandoen: ggplot(penguins,aes(x=bill_length_mm,y=body_mass_g)) + geom_point() + theme_minimal() + geom_smooth(method=&quot;lm&quot;,se=FALSE) ## `geom_smooth()` using formula &#39;y ~ x&#39; Det er nemt at bruge og at man kan få en konfidensinterval med, hvis man gerne vil have den: i ovenstående plot specificeret jeg se=FALSE men hvis jeg angiv se=TRUE (default), får jeg følgende plot: ggplot(penguins,aes(x=bill_length_mm,y=body_mass_g)) + geom_point() + theme_minimal() + geom_smooth(method=&quot;lm&quot;,se=TRUE) ## `geom_smooth()` using formula &#39;y ~ x&#39; 8.3.3 geom_smooth(): flere lm trendlinjer på samme plot For at tilføje en bedste rette linje til de tre species hver for sig i stedet for samtlige data, er det meget nemt i ggplot2: man angiver bare colour=species indenfor aesthetics (`aes): ggplot(penguins,aes(x=bill_length_mm,y=body_mass_g,colour=species)) + geom_point() + theme_minimal() + geom_smooth(method=&quot;lm&quot;,se=FALSE) ## `geom_smooth()` using formula &#39;y ~ x&#39; Så kan vi se, at der faktisk er tre forskellige trends her, så det giver god mening at bruge de tre forskellige linjer i stedet for kun en. 8.3.4 Trendlinjer med method==\"loess\" I ggplot er vi ikke begrænset til method=\"lm\" indenfor geom_smooth(). Lad os afprøve i stedet method=\"loess\": library(palmerpenguins) penguins &lt;- drop_na(penguins) ggplot(penguins,aes(x=bill_length_mm,y=body_mass_g,colour=species)) + geom_point() + theme_minimal() + geom_smooth(method=&quot;loess&quot;,se=FALSE) ## `geom_smooth()` using formula &#39;y ~ x&#39; Så kan man fange trends som ikke nødvendigvis er lineær - men bemærk at det er mere ligetil at beskrive og fortolke en lineær trend (og beregner udsigelser ud fra en lineær trend). 8.4 Plot linear regresion estimates For at finde vores estimates og tjekke signifikansen af en lineær trend, arbejder man direkte med den lineær model funktion lm(): my_lm &lt;- lm(body_mass_g~bill_length_mm,data=penguins) summary(my_lm) ## ## Call: ## lm(formula = body_mass_g ~ bill_length_mm, data = penguins) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1759.38 -468.82 27.79 464.20 1641.00 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 388.845 289.817 1.342 0.181 ## bill_length_mm 86.792 6.538 13.276 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 651.4 on 331 degrees of freedom ## Multiple R-squared: 0.3475, Adjusted R-squared: 0.3455 ## F-statistic: 176.2 on 1 and 331 DF, p-value: &lt; 2.2e-16 Husk de tal, som er vigtige her (se også emne 1 og 2): Den p-værdi: &lt;2e-16 - uafhængige variablen bill_length_mm har en signifikant effekt/betydning for body_mass_g. Den R-squared værdi: - det viser den proportion af variancen i body_mass_g som bill_length_mm forklarer: hvis R-squared er tæt på 1, så er der tæt på en perfekt korrespondens mellem bill_length_mm og body_mass_g. hvis R-squared er tæt på 0, så er der nærmeste ingen korrespondens. 8.4.1 Anvende lm() over nested datasæt Vi kan benytte den samme proces som ovenpå i korrelation analysen. Vi bruge group_by til at opdele efter de tre species og så nest de tre datarammer: penguins_nest &lt;- penguins %&gt;% group_by(species) %&gt;% nest() penguins_nest ## # A tibble: 3 × 2 ## # Groups: species [3] ## species data ## &lt;fct&gt; &lt;list&gt; ## 1 Adelie &lt;tibble [146 × 7]&gt; ## 2 Gentoo &lt;tibble [119 × 7]&gt; ## 3 Chinstrap &lt;tibble [68 × 7]&gt; Jeg definenerer en funktion hvor man lave lineær regression og tilføjer glance() til at få de model statistikker i en pæn form. #husk ~ og skriv .x for data og IKKE penguins lm_model_func &lt;- ~lm(body_mass_g~bill_length_mm,data=.x) %&gt;% glance() Vi kører en lineær model på hver af de tre datasæt med map og ved at specificere funktionen lm_model_func som vi definerede ovenpå. Vi bruger mutate ligesom før til at tilføje statistikkerne som en ny kolon der hedder lm_stats: penguins_lm &lt;- penguins_nest %&gt;% mutate(lm_stats=map(data,lm_model_func)) penguins_lm ## # A tibble: 3 × 3 ## # Groups: species [3] ## species data lm_stats ## &lt;fct&gt; &lt;list&gt; &lt;list&gt; ## 1 Adelie &lt;tibble [146 × 7]&gt; &lt;tibble [1 × 12]&gt; ## 2 Gentoo &lt;tibble [119 × 7]&gt; &lt;tibble [1 × 12]&gt; ## 3 Chinstrap &lt;tibble [68 × 7]&gt; &lt;tibble [1 × 12]&gt; Til sidste bruger vi funktionen unnest() på vores statistikker: penguins_lm &lt;- penguins_lm %&gt;% unnest(cols=lm_stats) penguins_lm ## # A tibble: 3 × 14 ## # Groups: species [3] ## species data r.squared adj.r.squared sigma statistic p.value df logLik ## &lt;fct&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie &lt;tibble&gt; 0.296 0.291 386. 60.6 1.24e-12 1 -1076. ## 2 Gentoo &lt;tibble&gt; 0.445 0.440 375. 93.6 1.26e-16 1 -873. ## 3 Chinst… &lt;tibble&gt; 0.264 0.253 332. 23.7 7.48e- 6 1 -490. ## # … with 5 more variables: AIC &lt;dbl&gt;, BIC &lt;dbl&gt;, deviance &lt;dbl&gt;, ## # df.residual &lt;int&gt;, nobs &lt;int&gt; Så kan vi se, at vi har fået en dataramme med vores lineær model statistikker. Jeg tager r.squared og p.value og omsætter dem til et plot for at sammenligne dem over de tre species af pingviner. penguins_lm %&gt;% select(species,r.squared,p.value) %&gt;% mutate(&quot;-log10pval&quot; = -log10(p.value)) %&gt;% select(-p.value) %&gt;% pivot_longer(-species) %&gt;% ggplot(aes(x=species,y=value,fill=species)) + geom_bar(stat=&quot;identity&quot;) + scale_fill_brewer(palette = &quot;Set2&quot;) + facet_wrap(~name,scale=&quot;free&quot;,ncol=4) + coord_flip() + theme_bw() 8.4.2 Funktion glue() for at tilføje labels Det kan være nyttigt at tilføje nogle etiketter til vores plots med statistikkerne, vi lige har beregnet. Til at gøre det kan man bruge følgende kode. Vi tage vores datasæt penguins_lm med vores beregnet statistikker og bruge den til at lave en datasæt som kan bruges i geom_text() i vores trend plot. Funktionen glue() (fra pakken glue) er bare en nyttig måde at tilføj de r.squared og p.value værdier sammen i en “string,” som beskriver vores forskellige trends (lidt som paste fra base-R) library(glue) # for putting the values together in a label label_data &lt;- penguins_lm %&gt;% mutate( rsqr = signif(r.squared, 2), # round to 2 significant digits pval = signif(p.value, 2), label = glue(&quot;r^2 = {rsqr}, p-value = {pval}&quot;) ) %&gt;% select(species, label) label_data FALSE # A tibble: 3 × 2 FALSE # Groups: species [3] FALSE species label FALSE &lt;fct&gt; &lt;glue&gt; FALSE 1 Adelie r^2 = 0.3, p-value = 1.2e-12 FALSE 2 Gentoo r^2 = 0.44, p-value = 1.3e-16 FALSE 3 Chinstrap r^2 = 0.26, p-value = 7.5e-06 Vi kan tilføje vores label data indenfor geom_text(). x og y specificere hvor i plottet teksten skal være, og husk at specificere data=label_data og label=label skal stå indenfor aes() når det handler om en variable i label_data. ggplot(penguins, aes(body_mass_g, flipper_length_mm, colour=species)) + geom_point() + geom_smooth(method = &quot;lm&quot;, se = FALSE) + geom_text( x = 5500, y = c(175,180,185), data = label_data, aes(label = label), #specify label data from above size = 4 ) + scale_color_brewer(palette = &quot;Set2&quot;) + theme_minimal() ## `geom_smooth()` using formula &#39;y ~ x&#39; 8.5 Multiple regression and model comparison Man kan også bruge den samme ramme i ovenstående til at sammenligne forskellige modeller over samme tre datasæt - her definerer jeg lm_model_func, der har kun sex som uafhængige variabel og så bygger jeg op på den model ved at definere lm_model_func2 og lm_model_func3, hvor jeg tilføjer ekstra uafhængige variabler bill_length_mm og flipper_length_mm. Jeg er interesseret i, hvor meget af variansen i body_mass_g de tre variabler forklarer tilsammen, og om der er forskelligeheder efter de tre arter i species. lm_model_func &lt;- ~lm(body_mass_g ~ sex ,data=.x) lm_model_func2 &lt;- ~lm(body_mass_g ~ sex + bill_length_mm ,data=.x) lm_model_func3 &lt;- ~lm(body_mass_g ~ sex + bill_length_mm + flipper_length_mm ,data=.x) Bemærk at jeg endnu ikke har tilføjet glance() her men jeg har tænkt mig at gøre det lidt senere i processen for at undgå, at jeg får alt for mange statistikker i min dataframe med mine resultater. Jeg anvender først group_by() efter species og nest(): penguins_nest &lt;- penguins %&gt;% group_by(species) %&gt;% nest() penguins_nest ## # A tibble: 3 × 2 ## # Groups: species [3] ## species data ## &lt;fct&gt; &lt;list&gt; ## 1 Adelie &lt;tibble [146 × 7]&gt; ## 2 Gentoo &lt;tibble [119 × 7]&gt; ## 3 Chinstrap &lt;tibble [68 × 7]&gt; Her bruger jeg map tre gange indenfor sammen mutate, for at bygge de tre modeller for hver art (ni modeller i alt). penguins_nest_lm &lt;- penguins_nest %&gt;% mutate( model_sex = map(data,lm_model_func), model_sex_bill = map(data,lm_model_func2), model_sex_bill_flipper = map(data,lm_model_func3)) penguins_nest_lm ## # A tibble: 3 × 5 ## # Groups: species [3] ## species data model_sex model_sex_bill model_sex_bill_flipper ## &lt;fct&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; &lt;list&gt; ## 1 Adelie &lt;tibble [146 × 7]&gt; &lt;lm&gt; &lt;lm&gt; &lt;lm&gt; ## 2 Gentoo &lt;tibble [119 × 7]&gt; &lt;lm&gt; &lt;lm&gt; &lt;lm&gt; ## 3 Chinstrap &lt;tibble [68 × 7]&gt; &lt;lm&gt; &lt;lm&gt; &lt;lm&gt; Nu vil jeg gerne udtrækker nogle statistikkker fra modellerne så jeg kan sammenligne dem. Jeg vil gerne lave samme process på alle ni modeller - hvor jeg benytter functionen glance til at få outputtet i tidy-form, og så udtrækker r.squared bagefter til at undgå, at der kommer alt for mange statistikker i min nye dataframe. get_r2_func &lt;- ~.x %&gt;% glance() %&gt;% pull(r.squared) Nu gælder det om at køre ovenstående funktion på alle mine modeller, som er lagret i tre kolonner, model_sex,model_sex_bill og model_sex_bill_flipper. Jeg gøre det indenfor map så det bliver også kørte til hver af de tre arter. penguins_nest_lm &lt;- penguins_nest_lm %&gt;% mutate(model_sex_r2 = map_dbl(model_sex, get_r2_func), model_sex_bill_r2 = map_dbl(model_sex_bill, get_r2_func), model_sex_bill_flipper_r2 = map_dbl(model_sex_bill_flipper, get_r2_func)) penguins_nest_lm %&gt;% select(species,model_sex_r2,model_sex_bill_r2,model_sex_bill_flipper_r2) ## # A tibble: 3 × 4 ## # Groups: species [3] ## species model_sex_r2 model_sex_bill_r2 model_sex_bill_flipper_r2 ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 0.545 0.563 0.602 ## 2 Gentoo 0.649 0.691 0.716 ## 3 Chinstrap 0.291 0.331 0.476 Omsætte til et plot: penguins_nest_lm %&gt;% pivot_longer(cols=c(&quot;model_sex_r2&quot;,&quot;model_sex_bill_r2&quot;,&quot;model_sex_bill_flipper_r2&quot;)) %&gt;% ggplot(aes(x=species,y=value,fill=name)) + geom_bar(stat=&quot;identity&quot;,position=&quot;dodge&quot;) + theme_minimal() Man kan se i plottet, at body_mass_g i species “Gentoo” er bedste forklaret af de tre varibler, og den lavest r.squared er tilfælde hvor variablen sex er dene eneste uafhængig variable og species er “Chinstrap.” 8.5.1 anova for at sammenligne de forskellige modeller Grunden til, at jeg valgt at bruge glance() i en ny funktion for at udtrække r.squared værdier, var fordi jeg gerne ville bevare mine modeller i rå form, så de kan bruges indenfor anova(). Med anova() kan jeg sammenligne to modeller direkte og får således en p-værdi hvor man teste hypotesen, hvor den ekstra variabler i den ene model forklarer den afhængig variabel signifikant (når man tager højde for de variabler, der er fælles til både modeller). I følgende skriver jeg en funktion hvor jeg kan sammenligne to modeller med anova og udtrækker p-værdien: aov_func &lt;- ~anova(.x,.y) %&gt;% tidy() %&gt;% pluck(&quot;p.value&quot;,2) ~ fordi det er en funktion (som jeg benytter for hver art og model sammenligning - 9 gange i alt!) anova for at sammenligne modellerne som er betegnet ved .x og .y (vi anvender map2 som tager to input i stedet for én som i map) tidy() er ligesom glance men angiver sumamry statistikker og flere linjer - herunder p-værdien pluck - jeg vil have kun én statistik (“p.value”) - og det er lagret i anden plads. Se følgende kode for når man anvende anova og tidy på modellerne model_sex og model_sex_bill i species “Adelie” (da jeg benyttet pluck med “1” som betyder den først plads i listen): myaov &lt;- anova(penguins_nest_lm %&gt;% pluck(&quot;model_sex&quot;,1), penguins_nest_lm %&gt;% pluck(&quot;model_sex_bill&quot;,1)) myaov %&gt;% tidy #p.value for comparing the two models is in the second position ## # A tibble: 2 × 6 ## res.df rss df sumsq statistic p.value ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 144 13884760. NA NA NA NA ## 2 143 13332955. 1 551805. 5.92 0.0162 Man kan se, at p-værdien er 0.016 som er signifikant og betyder at den mere ‘indviklet’ model der også inddrager bill_length_mm er den model, vi accepterer (dvs. effekten af variablen bill_length_mm på body_mass_g er signifikant så vores ‘final’ m). Man kan lave en lignende sammenligne mellem samtlige par modeller over de tre arter: penguins_nest_lm &lt;- penguins_nest_lm %&gt;% mutate(model_sex_vs_model_sex_bill = map2_dbl(model_sex,model_sex_bill,aov_func), model_sex_vs_model_sex_bill_flipper = map2_dbl(model_sex,model_sex_bill_flipper,aov_func), model_sex_bill_vs_model_sex_bill_flipper = map2_dbl(model_sex_bill,model_sex_bill_flipper,aov_func)) penguins_nest_lm %&gt;% select(species,model_sex_vs_model_sex_bill,model_sex_vs_model_sex_bill_flipper,model_sex_bill_vs_model_sex_bill_flipper) ## # A tibble: 3 × 4 ## # Groups: species [3] ## species model_sex_vs_model_sex_bill model_sex_vs_model_sex… model_sex_bill_… ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Adelie 0.0162 0.0000730 0.000273 ## 2 Gentoo 0.000142 0.00000592 0.00193 ## 3 Chinstrap 0.0540 0.0000621 0.0000795 Det kunne være nyttigt at inddrage p-værdier i ovenstående plot med r.squared værdierne, til at se om, der er en signifikant effekt når man tilføjer flere variabler til modellen samtidig at r.squared stiger. I følgende omsætter jeg r.squared statistikker til kun “Chunstrap” i et plot: library(ggsignif) stats_plot &lt;- penguins_nest_lm %&gt;% filter(species==&quot;Chinstrap&quot;) %&gt;% pivot_longer(cols=c(&quot;model_sex_r2&quot;,&quot;model_sex_bill_r2&quot;,&quot;model_sex_bill_flipper_r2&quot;)) %&gt;% ggplot(aes(x=name,y=value,fill=name)) + geom_bar(stat=&quot;identity&quot;,position=&quot;dodge&quot;) + coord_flip() + theme_bw() stats_plot I følgende tilføjer jeg funktionen geom_signif til plottet - det tillader, at jeg kan tilføje signifikans linjer/annotations til plottet - dvs. viser hvilke to modeller jeg sammenligner, og angiver stjerne efter beregnede p-værdierne. Du er velkommen til at kopier mine kode og tilpasse til egen behov. Når jeg sammenligne modellerne “model_sex” og “model_sex_bill” i “Chinstrap,” er p-værdien over 0.05, så tilføjelsen af bill_length_mm i modellen var ikke signifikant - jeg giver ingen stjerner men skriver “.” til at matcher outputtet i lm. Når jeg sammenligne modellerne “model_sex” og “model_sex_bill_flipper” kan jeg se at p-værdien er under 0.05, så der er en signifikant effekt - bill_length_mm og flipper_length_mm forklarer den afhængige variabel body_mass_g, ud over variablen sex. Jeg angiver \"***\" fordi p-værdien er under 0.001 (Se signif. codes i lm summary). Indstillingen y_position fortæller hvor jeg vil placerer linjerne. stats_plot + geom_signif(comparisons = list(c(&quot;model_sex_r2&quot;, &quot;model_sex_bill_r2&quot;)), annotations=&quot;.&quot;, y_position = 0.35, tip_length = 0.03) + geom_signif(comparisons = list(c(&quot;model_sex_bill_r2&quot;, &quot;model_sex_bill_flipper_r2&quot;)), annotations=&quot;***&quot;, y_position = 0.5, tip_length = 0.03) + geom_signif(comparisons = list(c(&quot;model_sex_r2&quot;, &quot;model_sex_bill_flipper_r2&quot;)), annotations=&quot;***&quot;, y_position = 0.55, tip_length = 0.03) 8.6 Problemstillinger Problem 1) Quizzen på Absalon. Husk at have indlæste følgende: library(tidyverse) library(broom) data(msleep) data(iris) Problem 2) Korrelation øvelse Brug data(mtcars) og cor.test() til at lave et test af korrelationen mellem variablerne qsec og drat. Tip: hvis du foretrækker at undgå $ i analysen til at speciefice en kolon indenfor cor.test() kan du bruge mtcars %&gt;% pull(qsec) i stedet for mtcars$qsec. Tilføj funktionen glance() til din resultat fra cor.test() til at se de statistikker i tidy form (installer pakken broom hvis nødvendigt). Kan du genkende de statistikker fra cor.test() i den resulterende dataramme? Problem 3) Nesting øvelse For datasættet msleep, anvende group_by() og nest() til at få en nested dataframe hvor datasættet er opdelt efter variablen vore. Kalder det for msleep_nest. Tilføj en ny kolon til msleep_nest med mutate, der hedder n_rows og viser antallet af rækker i hvert af de fire datasæt - husk følgende struktur: msleep_nest %&gt;% mutate(&quot;n_rows&quot; = map(???,???)) #erstatte ??? her I dette tilfælde kan man ændre map til map_dbl - gør det. Problem 4) Multiple korrelation Vi vil gerne beregne den korrelation mellem variablerne sleep_total og sleep_rm til hver af de fire datasæt lagret i msleep_nest Tilpas følgende funktion så at vi teste korrelation mellem de to variabler. Tilføj glance() så at vi få vores data i tidy form. cor_test &lt;- ~cor.test(????,???) #erstatte ??? og tilføj glance funktion Brug map() indenfor mutate() med din funktion for at beregne de korrelation statistikker til hver af de fire datasæt. Unnest din nye kolonne bagefter Lav barplots af estimate og -log10(p.value) med den resulterende dataramme Prøv også at tilføj %&gt;% pluck(\"estimate\",1) til din cor_test funktion og kig på resultat Problem 5) Linear regression øvelse Åbn LungCapData (herunder Age.Groups): LungCapData &lt;- read.csv(&quot;https://www.dropbox.com/s/ke27fs5d37ks1hm/LungCapData.csv?dl=1&quot;) glimpse(LungCapData) #se variabler navne ## Rows: 725 ## Columns: 6 ## $ LungCap &lt;dbl&gt; 6.475, 10.125, 9.550, 11.125, 4.800, 6.225, 4.950, 7.325, 8.… ## $ Age &lt;int&gt; 6, 18, 16, 14, 5, 11, 8, 11, 15, 11, 19, 17, 12, 10, 10, 13,… ## $ Height &lt;dbl&gt; 62.1, 74.7, 69.7, 71.0, 56.9, 58.7, 63.3, 70.4, 70.5, 59.2, … ## $ Smoke &lt;chr&gt; &quot;no&quot;, &quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;,… ## $ Gender &lt;chr&gt; &quot;male&quot;, &quot;female&quot;, &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;female&quot;, &quot;male&quot;… ## $ Caesarean &lt;chr&gt; &quot;no&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;… Anvende lm() med LungCap som afhængig variabel og Age som uafhængig variabel. Hvad er den intercept og slope af den beregnede linje? Prøv at tilføj funktionen glance() til din lm funktion og angive værdier r.squared og p.value. Problem 6) Lave et scatter plot af Age på x-aksen og LungCap på y-aksen. Ændre linjen til geom_smooth(method=\"lm\") Ændre linjen til geom_smooth(method=\"lm\",se=FALSE) Nu specificer en forskellige farve efter Gender. Hvordan er de to linje forskellige? Nu specificer en forskellige farve efter Smoke. Hvordan er de to linje forskellige? Problem 7) Lineær regression øvelse over multiple datasæt Vi vil gerne udføre lineær regression med LungCap og Age men opdelte efter variablen Smoke. OBS: Vi følger sammen process som i kursus notaterne men med LungCapData i stedet for Penguins - tjek gerne kursusnotaterne for inspiration. a) Anvende group_by() og nest() for at opdele dit datsasæt efter Smoke b) Lav en funktion, lm_model_func, som beregner en lineær regression med LungCap som afhængig variabel og Age som uafhængig variabel. Tilføj glance() til lm_model_func. c) Anvende map() med din funktion indenfor mutate() til at tilføje en ny kolon som hedder lm_stats til din dataramme. Husk at unnest kolonnen lm_stats for at kunne se statistikker. d) Fortolkning - er variablen lungCap bedre forklaret er variablen Age i rygere eller ikke-rygere? Problem 8) I nedenstående er tre modeller, alle med LungCap som afhængig variabel alle som tager højde for Age: my_lm_func1 &lt;- ~lm(LungCap ~ Age ,data=.x) my_lm_func2 &lt;- ~lm(LungCap ~ Age + Gender ,data=.x) my_lm_func3 &lt;- ~lm(LungCap ~ Age + Gender + Height,data=.x) a) Anvend map til at lave tre nye kolonner i LungCapData_nest, en til hver af de tre modeller (uden glance() her, så vi kan brug vores lm objekts senere). b) Skriv en funktion my_r2_func, der udtrækker “r.squared” værdierne fra dine modeller (her refererer .x i funktionen ikke til en dataframe men til en beregnet model - hvad er det, der skal tilføjes?). Lav tre yderligere kolonner i LungCapData_nest, hvor du køre din funktion på dine modeller med map (outputtet skal være dbl). my_r2_func &lt;- ... LungCapData_nest &lt;- LungCapData_nest %&gt;% mutate(&quot;Age_only_R2&quot; = ..., &quot;Age_Gender_R2&quot; = ..., &quot;Age_Gender_Height_R2&quot;= ...) c) Omsæt dine beregnede r.squared værdier til et plot Problem 9 a) Skriv en funktion hvor man anvende anova() til at sammenligne to modeller, .x og .y og dernæst udtrækker p-værdien (det er den samme funktion som i kursusnotaterne). my_aov_func &lt;- ... b) Anvend din funktion med map2 til at sammenligne de tre modeller fra sidste spørgsmål. c) Lav et plot med dine resultater. d) Tilføj signifikans annotations på plottet med funktionen geom_signif() (tilpas gerne kode fra kursusnotaterne). 8.7 Ekstra https://www.tidymodels.org/learn/statistics/tidy-analysis/ "],["clustering.html", "Chapter 9 Clustering 9.1 Indledning og læringsmålene 9.2 Method 1: K-means clustering 9.3 Kmeans: hvor mange clusters? 9.4 Method 2: Hierarchical clustering 9.5 Problemstillinger", " Chapter 9 Clustering 9.1 Indledning og læringsmålene 9.1.1 Læringsmålene Du skal være i stand til at Beskrive hvad k-means clustering går ud på Anvende kmeans og output resultatet på en tidy måde Anvende map over forskellige antal clusters og vælge antallet som passer til de data Anvende funktionen hclust for at lave et simpel hierarchical clustering 9.1.2 Inledning til chapter I clustering er det til formål at dele observationerne i et datasæt op i forskellige grupper (clusters eller klynge på dansk), således at observationerne i sammen cluster ligner hinanden. Det øger indsigten i datasættet ved at fk. bedre forstår strukturen. Fk. hvor mange forskellige clusters er repræsenteret i mit datasæt? Og hvilke individuelle observationer tilhører hvilken cluster? I dette kapitel ser vi hvordan vi kan implementere både k-means clustering og hierarchical clustering indenfor den tidyverse ramme. 9.1.3 Video ressourcer Video 1: K-means clustering Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/553656150 Video 2: augment, glanced og tidy med K-means. OBS der er en lille fejl i koden omkring 6:00 - den anden geom_point skal være geom_point(data = kclust_tidy,aes(x=bill_length,y=bill_depth),shape=\"x,colour=\"black\") fordi tallerne er allerede basaserede på “scaled” data i kclust_tidy - se sektion 9.2.5 for uddybelse. Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/553656139 Video 3: Hvor mange clusters skal man vælge? Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/553656129 Video 4: Hierarchical clustering (OBS Video 4 mangler: se gerne kursusnotaterne og jeg laver videoen ASAP) 9.2 Method 1: K-means clustering library(palmerpenguins) library(tidyverse) library(broom) I k-means clustering bliver samtlige observationer tilknyttet den nærmeste cluster “centroid” (se “hvordan fungerer kmeans?” nedenunder). I k-means er man nødt til at specificere antallet af clusters, som observationerne skal være delt op i, i forvejen. Derfor skal der være nogle undersøgelsesarbejde for at vælge den bedste antal clusters som passer til problemstillingen, eller som bedste repræsenterer datasættet. Lad os tage udgangspunkt i datasættet penguins. Vi begynder med at få fjernet observationerne med NA i mindst én variable med funktionen drop_na og ved at specificere at year skal være en faktor (for at skelne den fra de andre numeriske kolonner): data(penguins) penguins &lt;- penguins %&gt;% mutate(year=as.factor(year)) %&gt;% drop_na() Vi vide allerede i forvejen, at der er 3 species med i de data, som vi plotter her med forskellige farver. penguins %&gt;% ggplot(aes(x=bill_length_mm,y=body_mass_g,colour=species)) + geom_point() + theme_classic() Vi vil gerne bruge k-means clustering på de numeriske variabler i datasættet, og beregne 3 clusters ud fra dem. Derefter kan det være interessant at sammenligne de clusters vi få med de tre arter af pingvin - hvor gode er de clusters til at skelne i mellem de forskellige species, eller fanger de noget anden struktur i datasættet (for eksempel kønnet eller øen, de bor på)? 9.2.1 Hvordan fungere kmeans? K-means er en iterativ process. Lad os forestille os at vi gerne vil have tre clusters i de data. Man starter med tre tilfældige observationer og kalder dem for de cluster middelværdier eller “centroids.” Man tilknytter alle observationer til én af de tre clusters (efter den nærmeste af de tre centroids), og så beregner en ny middelværdi/centroid for at hver cluster. Man tilknytter samtlige observationerne igen eften den nærmeste af de tre nye cluster centroids, og så gentager man processen flere gange. Efter flere gange konvergere de tre centroids til nogle faste værdier, der ikke længere ændre sig meget hver gange med gentager processen. Disse tre centroids defininere de tre endelige clusters og samtlige observationer er tilknyttet én af de tre. Figure 9.1: source: https://towardsdatascience.com/k-means-a-complete-introduction-1702af9cd8c Jeg spørger ikke efter detaljerne i metoden men der er mange videoer på Youtube som bedre foreklarer hvordan k-means fungerer, for eksempel: https://www.youtube.com/watch?v=4b5d3muPQmA Bemærk, at der er noget tilfældighed indbygget i algoritmen. Det betyder, at hver gang man anvende k-means, få man en lidt anderledes resultat. 9.2.2 Within/between sum of squares Man kan forestille sig, at hvis man lave en gode clustering af datasæt, så ligner observationerne indenfor den sammen cluster hinanden meget, og til gengæld er observationerne i forskellige clusters meget forskellige fra hinanden. Med andre ord, er afstanden mellem observationerne i samme cluster så mindre som muligt og afstanden mellem observationerne i forskellige clusters er så stor som muligt. For at måle det kan man beregne følgende: total within sum of squares - den totale squared afstand af observationerne fra deres nærmeste centroid. total between sum of squares - den totale afstand af centroids til samtlige andre centroids. Det skal være så stor som muligt. 9.2.3 Run k-means i R K-means fungerer kun på numeriske data, som vi kan vælge fra datasættet med select() sammen med hjælper where(is.numeric). Vi bruger også scale(), som betyder, at alle variabler få den samme skala og det undgår, at der er nogle som få mere indflydelse end andre i de færdige resultater. penguins_scaled &lt;- penguins %&gt;% select(where(is.numeric)) %&gt;% scale() Man er også nødt til at fortælle i forvejen hvor mange clusters at opdele datasættet i, så lad os sige centers=3 indenfor funktionen kmeans() her og beregner vores clusters: kclust &lt;- kmeans(penguins_scaled,centers = 3) kclust ## K-means clustering with 3 clusters of sizes 129, 85, 119 ## ## Cluster means: ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## 1 -1.0452359 0.4858944 -0.8803701 -0.7616078 ## 2 0.6710153 0.8040534 -0.2889118 -0.3835267 ## 3 0.6537742 -1.1010497 1.1607163 1.0995561 ## ## Clustering vector: ## [1] 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 ## [38] 1 2 1 1 1 1 2 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 1 1 1 2 1 2 1 1 1 2 ## [75] 1 2 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1 1 2 1 2 1 2 1 2 1 ## [112] 1 1 1 1 1 1 1 1 1 1 1 1 2 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 3 3 ## [149] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 ## [186] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 ## [223] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 ## [260] 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 1 2 2 2 2 2 2 2 1 ## [297] 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 ## ## Within cluster sum of squares by cluster: ## [1] 120.7030 109.4813 139.4684 ## (between_SS / total_SS = 72.2 %) ## ## Available components: ## ## [1] &quot;cluster&quot; &quot;centers&quot; &quot;totss&quot; &quot;withinss&quot; &quot;tot.withinss&quot; ## [6] &quot;betweenss&quot; &quot;size&quot; &quot;iter&quot; &quot;ifault&quot; Man få forskellige ting frem, for eksempel: Cluster means - det svarer til de centroids markerede med x i den ovenstående figur - bemærk at her er de 4-dimensionelle da vi brugt 4 variabler til at beregne resultatet. Clustering vector - hvilke cluster er hver observation blevet tilknyttet. Within cluster sum of squares - Jo mindre, jo bedre - hvor meget observationerne indenfor samme cluster ligner hinanden (den totale squared afstand af observationerne fra deres nærmeste centroid). 9.2.4 Tidy up k-means resultaterne med pakken broom Fra pakken broom har vi mest beskæftiget os med glance() indstil videre. Med glance() få man enkel-linje baserede summary statistikker fra én eller flere modeller sammen i én dataramme, for at facilitete et plot/labels osv. Der er også to andre funktioner vi tager i bruge her. Her er en beskrivelse af de tre. Broom verb Beskrivelse glance() single line summary - make elbow plot augment() Append dataset to clusters - make plots coloured by cluster tidy() Multi-line summary - extract centroids For at lave et plot af de clusters kan det især være nyttigt at benytte augment. Her kan man se, at vi har fået en kolon der hedder .cluster med i den oprindelige dataramme (jeg flyttet kolonen til første plads i følgende kode så man kan se den i de output af kursusnotater). kc1 &lt;- augment(kclust, penguins) #clustering = første plads, data = anden plads kc1 %&gt;% select(.cluster,all_of(names(penguins))) ## # A tibble: 333 × 9 ## .cluster species island bill_length_mm bill_depth_mm flipper_length_mm ## &lt;fct&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 Adelie Torgersen 39.1 18.7 181 ## 2 1 Adelie Torgersen 39.5 17.4 186 ## 3 1 Adelie Torgersen 40.3 18 195 ## 4 1 Adelie Torgersen 36.7 19.3 193 ## 5 1 Adelie Torgersen 39.3 20.6 190 ## 6 1 Adelie Torgersen 38.9 17.8 181 ## 7 1 Adelie Torgersen 39.2 19.6 195 ## 8 1 Adelie Torgersen 41.1 17.6 182 ## 9 1 Adelie Torgersen 38.6 21.2 191 ## 10 1 Adelie Torgersen 34.6 21.1 198 ## # … with 323 more rows, and 3 more variables: body_mass_g &lt;int&gt;, sex &lt;fct&gt;, ## # year &lt;fct&gt; Nu benytter vi kc1 til at lave et plot. Her giver jeg en farve efter .cluster og shape efter species så at vi kan sammenligne vores beregnet clusters med de tre forskellige arter. Bemæk her, at jeg kun har to variabler i plottet, men der er faktisk fire variabler som blev brugt til at lave de clusters i med funktionen kmeans. En anden måde er at plotte de først to principal components i stedet for to af de fire variabler - det beskæftige vi os med næste gang. ggplot(kc1, aes(x = scale(bill_length_mm), y = scale(bill_depth_mm))) + geom_point(aes(color = .cluster, shape = species)) + theme_minimal() Vi kan også fk. optælle hvor mange af de tre arter vi får i hver af vores tre clusters, hvor vi kan se, at Adelie og Chinstrap er blevet mere blandet blandt to af de tre clusters end Gentoo. kc1 %&gt;% count(.cluster, species) ## # A tibble: 5 × 3 ## .cluster species n ## &lt;fct&gt; &lt;fct&gt; &lt;int&gt; ## 1 1 Adelie 124 ## 2 1 Chinstrap 5 ## 3 2 Adelie 22 ## 4 2 Chinstrap 63 ## 5 3 Gentoo 119 9.2.5 Plot cluster centroids Næste kigger vi på resultatet af funktionen tidy() fra broom-pakken. Her har vi fået en pæn dataramme med middelværdierne (centroids) af de tre clusters over de fire variabler som var brugt i beregningerne. kclust_tidy &lt;- kclust %&gt;% tidy() kclust_tidy ## # A tibble: 3 × 7 ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g size withinss ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; ## 1 -1.05 0.486 -0.880 -0.762 129 121. ## 2 0.671 0.804 -0.289 -0.384 85 109. ## 3 0.654 -1.10 1.16 1.10 119 139. ## # … with 1 more variable: cluster &lt;fct&gt; I følgende benytter jeg kclust_tidy som et ekstra datasæt i ovenstående plot, men indenfor en anden geom_point() for at tilføje en x form på midten af de tre clusters - se følgende tre punkter, der forklarer nogle detaljer i koden: Jeg bruger funktionen scale() på bill_length_mm og bill_depth_mm, fordi min centroids, som også skal med i plottet, var beregnet på skaleret data. Jeg behøver ikke at anvende scale() på min centroids lagrede i kclust_tidy så jeg angiver bare akser-variablerne i aes() uden at anvende scale(). Jeg har brugt color og shape som lokale aethetics i den første geom_point() her, der de ikke eksistere som kolonner i kclust_tidy. ggplot(kc1, aes(x = scale(bill_length_mm), #need to scale the original data y = scale(bill_depth_mm))) + geom_point(aes(color = .cluster, shape = species)) + geom_point(data = kclust_tidy, aes(x = bill_length_mm, #don&#39;t need to scale again y = bill_depth_mm), size = 10, shape = &quot;x&quot;, show.legend = FALSE) + theme_bw() Vi kan se at vores clusters ikke fanger de samme tre gruppe som variablen species præcist - der er forskelligheder. Det kan være at vi også har fanget nogle oplysninger om fk. øen pingviner bor på, eller deres køn. 9.3 Kmeans: hvor mange clusters? Vi gættede på 3 clusters i ovenstående analyse (da vi havde oplysninger om arter i forvejen) men det godt kunne være, at et andet antal clusters passer bedre til datasættet. Vi kan beregene flere clusterings og angiver forskellige antal clusters, og dernæst bruge outputterne fra resultaterne til at tage en beslutning om, hvor mange clusters vi gerne vil angiv i vores færdig clustering. Det er vigtigt at kunne finde frem til en hensigtsmæssigt antal clusters - For mange clusters kan resultatere i over-fitting, hvor vi har for mange til at fortolke eller giver mening, For få kan betyde at vi mangler indsigter ind i strukturen eller vigtige trends i datasættet. 9.3.1 Få Broom output for forskellige antal clusters I følgende laver jeg en custom funktion, der laver en clustering på datasættet penguins_scaled og hvor jeg angiver, at antal beregnede clusters skal være .x, der er en integer (fk. 1,3,99 osv.). Bemærk derfor, at selve data er samme hver gang jeg anvender funktionen - det er bare antal clusters jeg beregner, der kan variere. my_func &lt;- ~kmeans(penguins_scaled,centers = .x) Dernæst laver jeg en tibble med variablen k som indeholder heltal fra 1 op til 9. Når man anvender funktionen map på kolonnen k med ovenstående funktion my_func, svarer det til, at jeg anvender kmeans ni gange, med antal clusters fra 1 til 9. Jeg gemmer clustering resultaterne i en kolon der hedder kclust, og så anvende tidy, glance og augment til at få de forskellige outputter fra mine clusterings. kclusts &lt;- tibble(k = 1:9) %&gt;% mutate( kclust = map(k, my_func), tidied = map(kclust, tidy), glanced = map(kclust, glance), augmented = map(kclust, ~.x %&gt;% augment(penguins)) ) Husk at for at få frem resultaterne i de forskellige former fra tidy,glance og augment er vi nødt til at anvende funktionen unnest() - her gemme jeg resultaterne i tre nye dataframes, som vi kan referere til efterfølgende. kclusts_tidy &lt;- kclusts %&gt;% unnest(tidied) kclusts_augment &lt;- kclusts %&gt;% unnest(augmented) kclusts_glance &lt;- kclusts %&gt;% unnest(glanced) 9.3.2 Elbow plot (glance) Vi bruger tot.withinness fra outputtet fra glance() (dataframen kclusts_glance). Det giver målinger for den totale afstand af observationerne fra deres nærmeste centroid (within sum of squares). kclusts_glance ## # A tibble: 9 × 8 ## k kclust tidied totss tot.withinss betweenss iter augmented ## &lt;int&gt; &lt;list&gt; &lt;list&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;list&gt; ## 1 1 &lt;kmeans&gt; &lt;tibble [1 × 7]&gt; 1328 1328. 9.09e-13 1 &lt;tibble&gt; ## 2 2 &lt;kmeans&gt; &lt;tibble [2 × 7]&gt; 1328 551. 7.77e+ 2 1 &lt;tibble&gt; ## 3 3 &lt;kmeans&gt; &lt;tibble [3 × 7]&gt; 1328 370. 9.58e+ 2 3 &lt;tibble&gt; ## 4 4 &lt;kmeans&gt; &lt;tibble [4 × 7]&gt; 1328 304. 1.02e+ 3 2 &lt;tibble&gt; ## 5 5 &lt;kmeans&gt; &lt;tibble [5 × 7]&gt; 1328 228. 1.10e+ 3 3 &lt;tibble&gt; ## 6 6 &lt;kmeans&gt; &lt;tibble [6 × 7]&gt; 1328 200. 1.13e+ 3 3 &lt;tibble&gt; ## 7 7 &lt;kmeans&gt; &lt;tibble [7 × 7]&gt; 1328 206. 1.12e+ 3 4 &lt;tibble&gt; ## 8 8 &lt;kmeans&gt; &lt;tibble [8 × 7]&gt; 1328 174. 1.15e+ 3 5 &lt;tibble&gt; ## 9 9 &lt;kmeans&gt; &lt;tibble [9 × 7]&gt; 1328 232. 1.10e+ 3 4 &lt;tibble&gt; Jo flere clusters, jo mindre statistikken tot.withinness er som regel, men vi kan se i følgende plot, at efter 2 eller 3 clusters, er der ikke meget gevinst ved at bruge flere clusters. Derfor vælger man enten 2 eller 3. Plottet er ofte kaldes for en ‘elbow’ plot - man vælger de tal på den ‘elbow,’ hvor der ikke er meget gevinst med at have flere clusters i datasættet (men det er selvfølgelig meget subjektiv, det tal man vælger til sidste). kclusts_glance %&gt;% ggplot(aes(x = k, y = tot.withinss)) + geom_line() + geom_point() + theme_bw() 9.3.3 Automatistke beslutning med pakken NbClust Man kan man også overvejer at prøve noget mere automatisk. For eksempel pakken NbClust lave 30 forskellige clustering algoritme på datasættet fra antal clusters = 2 op til til antal cluster = 9 og for hver af de 30 tager en beslutning om de bedste antal clusters. Man kan således se hvilket antal clusters blev valgt fleste gange af de forskellige algoritme. library(NbClust) set.seed(24) #fordi outputt af NbClust har indbygget tilfældighed cluster_30_indexes &lt;- NbClust(data = penguins_scaled, distance = &quot;euclidean&quot;, min.nc = 2, max.nc = 9, method = &quot;complete&quot;) Man kan se i følgende, at enten 2 eller 3 er optimelt, som passer sammen med den elbow plot methode. as_tibble(cluster_30_indexes$Best.nc[1,]) %&gt;% ggplot(aes(x=factor(value))) + geom_bar(stat=&quot;count&quot;,fill=&quot;blue&quot;) + xlab(&quot;Number of clusters&quot;) + ylab(&quot;Number of clustering algorithms choosing this number&quot;) + coord_flip() + theme_minimal() 9.3.4 Plot de forskellige antal clusters (augment) Vi kan også visualisere hvordan de forskellige antal clusters ser ud. Her kan vi bruge vores resultater fra funktionen augment (kclusts_augment), som indeholder tilknytninger af observationerne til clusters for hver af de 9 clusterings. Læg mærk til at kclusts_agument har 2997 observationer, der svarer til 9 (antal clusterings) x 333 (antal observationer i penguins), fordi vi brugt unnest til at lægge samtlige resultaterne sammen. kclusts_augment %&gt;% glimpse() ## Rows: 2,997 ## Columns: 13 ## $ k &lt;int&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… ## $ kclust &lt;list&gt; [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,… ## $ tidied &lt;list&gt; [&lt;tbl_df[1 x 7]&gt;], [&lt;tbl_df[1 x 7]&gt;], [&lt;tbl_df[1 x … ## $ glanced &lt;list&gt; [&lt;tbl_df[1 x 4]&gt;], [&lt;tbl_df[1 x 4]&gt;], [&lt;tbl_df[1 x … ## $ species &lt;fct&gt; Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel… ## $ island &lt;fct&gt; Torgersen, Torgersen, Torgersen, Torgersen, Torgerse… ## $ bill_length_mm &lt;dbl&gt; 39.1, 39.5, 40.3, 36.7, 39.3, 38.9, 39.2, 41.1, 38.6… ## $ bill_depth_mm &lt;dbl&gt; 18.7, 17.4, 18.0, 19.3, 20.6, 17.8, 19.6, 17.6, 21.2… ## $ flipper_length_mm &lt;int&gt; 181, 186, 195, 193, 190, 181, 195, 182, 191, 198, 18… ## $ body_mass_g &lt;int&gt; 3750, 3800, 3250, 3450, 3650, 3625, 4675, 3200, 3800… ## $ sex &lt;fct&gt; male, female, female, female, male, female, male, fe… ## $ year &lt;fct&gt; 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007… ## $ .cluster &lt;fct&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1… I følgende kode plotter jeg flipper_length_mm vs bill_length_mm, og anvende facet_wrap så at hver clustering får sit eget plot (så der er 333 observationer pr. plot). kclusts_augment %&gt;% ggplot(aes(x = flipper_length_mm, y = bill_length_mm,colour=.cluster)) + geom_point(aes(shape=factor(species)), alpha = 0.8) + facet_wrap(~ k) + theme_bw() Vi kan nemt inddrage kclusts_tidy() og lave “X”-former, bare ved at tilføje en ekstra geom_point og angive kclusts_tidy. Jeg anvender først funktionen rename så at variablen cluster fra klusts_tidy matcher til .cluster fra kclusts_augment. kclusts_tidy &lt;- kclusts_tidy %&gt;% rename(.cluster=cluster) kclusts_augment %&gt;% ggplot(aes(x = scale(flipper_length_mm), y = scale(bill_length_mm),colour=.cluster)) + #scale here geom_point(aes(shape=factor(species)), alpha = 0.8) + facet_wrap(~ k) + geom_point(data = kclusts_tidy, aes(x=flipper_length_mm,y=bill_length_mm), #already based on scaled data, so don&#39;t scale size = 10, shape = &quot;x&quot;,col=&quot;black&quot;, show.legend = FALSE) + theme_bw() Vi kan prøve at kigge endnu dyber ind i resultaterne - her introducerer jeg sex som en ekstra variabel i plottet. Husk at variablen sex var ikke blevet brugt i vores k-means clusterings, men det kan være, at der er nogle aspekter af de fire variabler, som kan fortælle os nogle om kønnet af pingvingerne. For at spare plads, har jeg kun plottet antal clusters fra 2 til 5. kclusts_augment %&gt;% filter(k %in% 2:5) %&gt;% ggplot(aes(x = scale(flipper_length_mm), y = scale(bill_length_mm),colour=.cluster)) + geom_point(aes(shape=factor(species)), alpha = 0.8) + facet_grid(sex ~ k) + geom_point(data = kclusts_tidy %&gt;% filter(k %in% 2:5), aes(x = flipper_length_mm, y = bill_length_mm), size = 10, shape = &quot;x&quot;, colour = &quot;black&quot;,show.legend = FALSE) + theme_bw() 9.3.5 Nest/map ramme fra sidste gange Som sidste bemærk med k-means, kan man også lave en clustering til de tre arter hver for sig. I følgende opretter jeg en nested dataframe, som indeholder 3 datasæt (penguins opdelt efter variablen species), og jeg anvender den custom funktion scale_me til at udvælge de numeriske variabler og anvende scale() i hvert datasæt. scale_me &lt;- ~.x %&gt;% select(where(is.numeric)) %&gt;% scale penguins_nest &lt;- penguins %&gt;% group_by(species) %&gt;% nest() %&gt;% mutate(&quot;data_scaled&quot; = map(data,scale_me)) Næste laver jeg en custom funktion til at lave en clustering på datasættet .x, og angiver at antal clusters skal være 3. Bemærk at i ovenstående sektion varierede vi på antal clusters (indstilling centers), men her fastlægger vi antal clusters og så variere selve datasæt i stedet for. cluster_me &lt;- ~.x %&gt;% kmeans(centers=3) Jeg anvender cluster_me på mine skaleret datasæts, og så anvender glance, augment og tidy på clustering resultater ligesom i ovenpå (bemærk brugen af map til at augment de opdelte datasæt). penguins_nest &lt;- penguins_nest %&gt;% mutate(clusters = map(data_scaled,cluster_me), clusters_glance = map(clusters,glance), clusters_augment = map2(clusters,data_scaled,~.x %&gt;% augment(.y)), #I augment the scaled data so the correct scaling (based on individual datasets) appears in the next plot clusters_tidy = map(clusters,tidy)) nested_clusters_augment &lt;- penguins_nest %&gt;% unnest(clusters_augment) nested_clusters_tidy &lt;- penguins_nest %&gt;% unnest(clusters_tidy) Til sidste laver jeg en plot af resultaterne: nested_clusters_augment %&gt;% ggplot(aes(x=bill_length_mm,y=flipper_length_mm,colour=.cluster)) + #data already scaled geom_point() + facet_grid(~species) + geom_point(data=nested_clusters_tidy,, shape=&quot;X&quot;,colour=&quot;black&quot;, size = 10) + theme_bw() 9.4 Method 2: Hierarchical clustering K-means er en meget populær metode til at lave clustering, men der er mange andre metoder, fk. hierarchical clustering. Vi skifter over til mtcars, og ligesom i kmeans skal vi første bruge scale på de numeriske kolonner i de data. mtcars_scaled &lt;- mtcars %&gt;% select(where(is.numeric)) %&gt;% scale() I modsætning til k-means, for at lave hierarchical clustering skal man første beregne afstanden mellem alle de observationer i de data. Det gør man med funktionen dist() (som bruger den Euclidean distance som default): d &lt;- dist(mtcars_scaled) For at lave en hierarchical clustering anvender man funktionen hclust(). Metoden complete er default men man kan afprøve de andre methoder (der er ikke en fast regel over for, hvilken metode man skal bruge). mtcars_hc &lt;- hclust(d, method = &quot;complete&quot; ) # Metoder: &quot;average&quot;, &quot;single&quot;, &quot;complete&quot;, &quot;ward.D&quot; I følgende arbejder vi lidt med mtcars_hc til at få nogle clusters frem, og til at lave et plot. 9.4.1 Vælge ønkset antal clusters Funktionen cutree anvendes til at få clusters fra resultaterne af funktionen hclust. For eksempel hvis man gerne vil have 4 clusters, bruger man k = 4. Jeg specificerer order_clusters_as_data = FALSE for at få clusters i rækkefølgen, som passer til plottet (dendrogram) vi laver (bemærk at man skal have pakken dendextend installeret for at få den til at fungere). library(dendextend) clusters &lt;- cutree(mtcars_hc, k = 4, order_clusters_as_data = FALSE) Her laver jeg et overblik over, hvor mange observationerne fra mtcars er i hver cluster: tibble(&quot;cluster&quot;=clusters) %&gt;% group_by(cluster) %&gt;% summarise(n()) FALSE # A tibble: 4 × 2 FALSE cluster `n()` FALSE &lt;int&gt; &lt;int&gt; FALSE 1 1 7 FALSE 2 2 8 FALSE 3 3 12 FALSE 4 4 5 9.4.2 Lav et pænt plot af dendrogram med ggplot2 Første anvender jeg funktionen dendro_data() til at udtrække den “dendrogram” fra de hclust() resultater. library(ggdendro) dend_data &lt;- dendro_data(mtcars_hc %&gt;% as.dendrogram, type = &quot;rectangle&quot;) Vi tilføjer vores clusters som vi beregnede ovenpå (det er derfor vi sikret rækkefølgen af de clusters): dend_data$labels &lt;- dend_data$labels %&gt;% mutate(cluster = clusters) Vi benytter dend_data$segments og dend_data$labels til at lave et informativ plot af de data i ggplot2. ggplot(dend_data$segments) + geom_segment(aes(x = x, y = y, xend = xend, yend = yend)) + coord_flip() + geom_text(data = dend_data$labels, aes(x, y, label = label,col=factor(cluster)), hjust=1,size=3) + ylim(-3, 10) + theme_dendro() Så kan man se, der er fire clusters i dengrammet, og biler der er tætest på hinanden ligner hinanden mest - fk. Merc 280C og Merc 280 må være meget éns, og er som forventet lige ved siden af hinanden i plottet. Man kan godt tilpasse ovenstående kode til et andet datasæt - se problemstillinger, men man må også gerne udvide plottet med de forskellige viden vi har om ggplot2. 9.4.3 Ekstra (valgfri): afprøve andre metoder på hierachical clustering Valfri ekstra hvis du vil afprøve de fire metoder i hclust - “average,” “single,” “complete” og “ward.D.” # samme ggplot kommando som ovenpå lavet til en funktion den_plot &lt;- ~ggplot(.x$segments) + geom_segment(aes(x = x, y = y, xend = xend, yend = yend)) + coord_flip() + geom_text(data = .x$labels, aes(x, y, label = label), hjust=1,size=2) + ylim(-4, 10) + theme_dendro() Vi iterate over de fire metoder og lave samme process som ovenpå med map. Derefter kan man lave et plot fk. med grid.arrange: # fire metoder: m &lt;- c( &quot;average&quot;, &quot;single&quot;, &quot;complete&quot;, &quot;ward.D&quot;) hc_results &lt;- tibble(method = m) %&gt;% mutate( kclust = map(method, ~hclust(d, method = .x)), dendrogram = map(kclust,as.dendrogram), den_dat = map(dendrogram,~dendro_data(.x,type=&quot;rectangle&quot;)), plot = map(den_dat,den_plot)) library(gridExtra) grid.arrange(grobs = hc_results %&gt;% pull(plot),ncol=2) 9.5 Problemstillinger Problem 1) Quiz - Clustering Problem 2) Funktionen kmeans. I ovenstående anvendt vi mtcars i hierarchical clustering, men lad os se, hvordan det ser ud med k-means. Du er velkommen til at tilpasse min ovenstående kode fa det penguins datasæt: a) Benyt kmeans til at finde 2 clusters i datasættet mtcars: husk at vælge kun de numeriske kolonner og scale datasættet i forvejen gem din clustering som my_clusters. hvor mange observationer er der i hver af de to clusters? b) Anvend funktionen augment til at forbinde det oprindelige datasæt til dine clusters fra my_clusters (skriv mtcars indenfor funktionen augment). c) Brug dit “augmented” datasæt til at lave et scatter plot mellem to af de numeriske variabler (vælg selv) i datasættet og giv dem farver efter din clusters, som du har beregnet. Da du har forbundet det oprindeligt datasæt (der ikke var scaled) i augment, scale din variabler i plottet. d) Tilføj tidy til at få fat i de middelværdier/centroids af hver af de 2 clusters og tilpas min kode fra notaterne (sektion 9.2.5) til at tilføje dem til plottet som ‘x’ (husk at din “centers”/centroids er allerede baserede på scaled data så du behøver ikke at anvende scale på deres værdier). Problem 3) Hierarchical clustering øvelse Vi laver en analyse af det msleep datasæt. Jeg har lavet oprydningen og scaling for jer: data(msleep) msleep_clean &lt;- msleep %&gt;% select(name,where(is.numeric)) %&gt;% drop_na() msleep_scaled &lt;- msleep_clean %&gt;% select(-name) %&gt;% scale row.names(msleep_scaled) &lt;- msleep_clean$name Tilpas min kode fra kursusnotaterne (sektion 9.4) til at lave følgende: a) Benyt funktioner dist og dernæst hclust på datasættet msleep_scaled. b) Benyt cutree for at finde 5 clusters fra dine hclust-resultater, og kalde det for clusters. Husk at anvende order_clusters_as_data = FALSE så at vi har den korrekt rækkefølge for et plot (OBS man skal installere/indlæse pakken dendextend) c) Benyt dendro_data til at udtrække de dendrogram fra resultaterne og tilføj clusters til dend_data$labels (kopier kode fra 9.4.2). d) Lav et dengrogram plot: igen tilpas koden (9.4.2) for mtcars eksempel for nuværende data Problem 4) Inlæs data wholesale &lt;- read.csv(&quot;https://www.dropbox.com/s/7nb5pkruqt4fqn4/Wholesale%20customers%20data.csv?dl=1&quot;, header = TRUE) a) Ændre på datasættet efter følgende instruks: Channel - anvend recode for at ændre til navne 1 = horeca 2 = retail Region - anvend recode for at ændre til navne 1 = Lisnon 2 = Oporto 3 = Other Anvend map_if til at transformere samtlige numeriske variabler med log (kode er: wholesale &lt;- wholesale %&gt;% map_if(is.numeric,log) %&gt;% as_tibble()). b) Udvælg de numeriske variabler fra dit datasæt og anvende scale() - kalde dit nye datasæt for wholescale_scale c) Tilpas min kode fra sektion 9.3.1 til at lave 10 clusterings (k=1:10) på wholesale_scale og gem dem i en dataframe, sammen med din clusterings resultater i “tidy,” “glance” og “augment” form. d) Lav et elbow plot fra dit output fra glance (sektion 9.3.2) e) Udvælg clusterings hvor k er fra 2 til 7 fra dit output fra augment og lav scatter plots af variabler Frozen VS Fresh, hvor du: Giv farve efter .cluster Adskil plots efter k Prøv bagefter at også adskil dit plots yderligere efter Channel. f) Tilpas koden fra 9.3.5 til at lave en analyse for “hoerca” og “retail” (variablen Channel) hver for sig. Angiv 4 clusters i din analyse. g) Lav et plot af din clustering (adskilt efter variablen Channel) og få “x” på plotterne til at vise din cluster middelværdier for Frozen og Fresh. "],["principal-component-analysis-pca.html", "Chapter 10 Principal component analysis (PCA) 10.1 Indledning og læringsmålene 10.2 Hvad er principal component analysis (PCA)? 10.3 Fit PCA to data in R 10.4 Integrere PCA resultater med broom-pakke 10.5 Problemstillinger 10.6 Ekstra læsning", " Chapter 10 Principal component analysis (PCA) library(tidyverse) library(broom) 10.1 Indledning og læringsmålene 10.1.1 Læringsmålene Du skal være i stand til at Forstå koncepten bag principal component analysis (PCA) Benytte PCA i R og lave et plot af et datasæt i to dimensioner Vurdere den relative varians forklarede af de forskellige components Anvende PCA til at vurdere variablernes bidrag til de principal components 10.1.2 Introduktion til chapter Principal component analysis er en meget populær og benyttet statistike metode og kan anvendes til bla. at visualisere data med et højt antal dimensioner i et enkelt scatter plot med to dimensioner. Det er meget nyttigt for at se den underliggende struktur i datasættet og indenfor biologi er det meget brugt til at blandt andet visualisere hvor de forskellige samples eller replikates sidder relative til hinanden - for eksempel for at se, om de controls samples og treatment samples fremgå i samme steder på plottet (som indikere at de ligner hinanden). 10.1.3 Video ressourcer Video 1 - hvad er PCA? Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556581604 Video 2 - hvordan man lave PCA i R og få output i tidy form Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556581588 Video 3 - hvordan man visualisere de data (principal components, rotation matrix) Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556787141 10.2 Hvad er principal component analysis (PCA)? I sidste lektion arbejdede vi med penguins, hvor vi så at der faktisk var fire numeriske variabler - altså fire dimensioner - som blev brugt til at lave k-means clustering. library(palmerpenguins) penguins &lt;- penguins %&gt;% drop_na() %&gt;% mutate(year=as.factor(year)) penguins %&gt;% select(where(is.numeric)) %&gt;% head() ## # A tibble: 6 × 4 ## bill_length_mm bill_depth_mm flipper_length_mm body_mass_g ## &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; ## 1 39.1 18.7 181 3750 ## 2 39.5 17.4 186 3800 ## 3 40.3 18 195 3250 ## 4 36.7 19.3 193 3450 ## 5 39.3 20.6 190 3650 ## 6 38.9 17.8 181 3625 Når man laver et plot for at vise de forskellige clusters, få man et problem - hvilke to variable skal plottes? Man kan plotte hver eneste pair af variabler. For eksempel kan man prøve en pakke der hedder GGally, som automatiske kan plotte de forskellige pairs af numeriske variabler og beregner korrelationen mellem variablerne. require(GGally) ## Indlæser krævet pakke: GGally ## Registered S3 method overwritten by &#39;GGally&#39;: ## method from ## +.gg ggplot2 penguins %&gt;% ggscatmat(columns = 3:6 ,color = &quot;species&quot;, corMethod = &quot;pearson&quot;) + scale_color_brewer(palette = &quot;Set2&quot;) + theme_bw() Problemmet er, at så snart antallet af dimensioner i datasættet bliver større end 4, bliver plottet alt for kompleks og pladskrævende. En løsning til problemmet er at projektere datasættet ned indtil et mindre antal demensioner (fk. kun 2 dimensioner). Disse dimensioner fanger oplysninger fra alle variablerne i datasættet, og derfor når man lave et scatter plot, får man repræsenteret det hele datasæt i stedet for kun to udvalgte variabler. Metoden for at lave disse såkaldte ‘projektion’ kaldes for ‘princial component analysis.’ 10.2.1 Simpel eksempel med to dimensioner Man kan prøve at forstå hvordan PCA fungerer ved at kigge på et simpelt eksempel med 2 dimensioner: #simulere data med en høj korrelation a &lt;- rnorm(250,1,2) b &lt;- a + rnorm(250,0,.5) df &lt;- tibble(a,b) ggplot(df,aes(a,b)) + geom_point() + theme_minimal() Vi kan se her, at der er en meget store korrelation mellem a og b. Selvom datasættet er plottet i 2 dimensioner kan de næsten forklares af én linje - en såkaldte bedste rette linje der passer bedste gennem punkterne. df &lt;- tibble(a,b) ggplot(df,aes(a,b)) + geom_point() + theme_minimal() + geom_smooth(method=&quot;lm&quot;,se=FALSE) ## `geom_smooth()` using formula &#39;y ~ x&#39; Med andre ord kan vi næsten forklare datasættet i blot én dimension - punkternes afstand langt linjen. Når man tager alle punkterne og beskriver dem langt én linje som bedste beskrive variansen i datasættet, kaldes den linje for den første principal component (PC1). Man kan dernæst beskriver en anden linje som er vinkelrettet til PC1 som bedste forklarer variancen i de data som ikke var fanget af PC1 - det kaldes for den anden princal component (PC2). Vi kan se her PC1 og PC2 plottet: Når vi tager PC1 and PC2 og plotter dem som henholdvis x-aksen og y-aksen, svarer det til en drejning af akserne i plottet (vi finder PC1 og PC2 fra funktionen prcomp som jeg forklarer i næste sektion): dat &lt;- augment(prcomp(df),df) ggplot(dat,aes(x=.fittedPC1,y=.fittedPC2)) + geom_point() + theme_minimal() + geom_smooth(method=&quot;lm&quot;) ## `geom_smooth()` using formula &#39;y ~ x&#39; Vi kan se her, at de data flyder de plads på plottet bedre en før (og bemærk at de askse skala er blevet meget mindre i den nye y-aksen, da de data spreder sig meget mindre langt PC2 i forhold til PC1.) Det her er kun et eksempel hvor vores oprindelige data ligger i to dimensions (to variabler), for at gøre det nemt at visualisere dem i et plot, men de fleste datasæt (fk penguins, iris osv.) har flere end to dimensioner. Vi kan godt lave samme process, hvor vi definerer PC1 som forklarer så meget af variancen i de data som muligt, og dernæst PC2 som forklarer nogle af variancen ikke fanget af PC1, og dernæst PC3 osv., efter hvor mange dimensioner de data har. I mange praktisk situationer vælger man de første to componenter, som er mest vigtige, da de forklarer mest af variancen i de data i forhold til de andre componenter. “So to sum up, the idea of PCA is simple — reduce the number of variables of a data set, while preserving as much information as possible.” https://builtin.com/data-science/step-step-explanation-principal-component-analysis 10.3 Fit PCA to data in R library(broom) Lad os skifte tilbage til nogle virkelige data for at benytte prcomp: datasættet penguins. Med prcomp fokuserer vi kun på numeriske variabler, så vi bruger select med where(is.numeric) og så anvender scaling ved at specificere scale = TRUE indenfor funktionen prcomp. pca_fit &lt;- penguins %&gt;% select(where(is.numeric)) %&gt;% # retain only numeric columns prcomp(scale = TRUE) # do PCA on scaled data summary(pca_fit) ## Importance of components: ## PC1 PC2 PC3 PC4 ## Standard deviation 1.6569 0.8821 0.60716 0.32846 ## Proportion of Variance 0.6863 0.1945 0.09216 0.02697 ## Cumulative Proportion 0.6863 0.8809 0.97303 1.00000 Proportion of Variance indikerer hvor meget af variancen i de data blev forklaret af de forskellige komponenter. Vi kan se, at PC1 forklaret omkring 69% og de første to komponenter sammen forklarer 88% af variancen i de data. Derfor hvis vi viser et plot af de første to komponenter ved vi, at vi har fanget rigtig meget oplysninger om de fire variabler i datasæsttet. 10.4 Integrere PCA resultater med broom-pakke Der er flere ting som kan være nyttige at lave med vores PCA resultater: Lave et plot af datasættet ud fra de første to principal components Se for meget af variansen i datasættet er forklaret af de forskellige components Bruge den rotation matrix til at se, hvordan variabler sidder med relative til hinanden For at få lavet vores plot af de principal components kan vi benytte funktionen augment() ligesom vi gjorde i vores sidste lektion med k-means clustering. Her få vi værdierne til hver af de fire principal components sammen med den oprindelige datasæt. pca_fit_augment &lt;- pca_fit %&gt;% augment(penguins) # add original dataset back in pca_fit_augment ## # A tibble: 333 × 13 ## .rownames species island bill_length_mm bill_depth_mm flipper_length_mm ## &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; ## 1 1 Adelie Torgersen 39.1 18.7 181 ## 2 2 Adelie Torgersen 39.5 17.4 186 ## 3 3 Adelie Torgersen 40.3 18 195 ## 4 4 Adelie Torgersen 36.7 19.3 193 ## 5 5 Adelie Torgersen 39.3 20.6 190 ## 6 6 Adelie Torgersen 38.9 17.8 181 ## 7 7 Adelie Torgersen 39.2 19.6 195 ## 8 8 Adelie Torgersen 41.1 17.6 182 ## 9 9 Adelie Torgersen 38.6 21.2 191 ## 10 10 Adelie Torgersen 34.6 21.1 198 ## # … with 323 more rows, and 7 more variables: body_mass_g &lt;int&gt;, sex &lt;fct&gt;, ## # year &lt;fct&gt;, .fittedPC1 &lt;dbl&gt;, .fittedPC2 &lt;dbl&gt;, .fittedPC3 &lt;dbl&gt;, ## # .fittedPC4 &lt;dbl&gt; Vi kan tage pca_fit_augment og lave et plot af de første to principal components: pca_fit_augment %&gt;% ggplot(aes(x=.fittedPC1, y=.fittedPC2, color = species)) + geom_point() + theme_bw() Vi kan også integrere de clusters som vi fik fra funktionen kmeans() i vores PCA ved at anvende funktionen augment() på resultaterne fra kmeans og vores data som allerede har resultaterne fra pca. Da både PCA og k-means fanger oplysninger om strukturen af de data baserede på de fire numeriske variabler, kan man forventer en bedre sammenligning mellem de to (i forhold til at sammenligne de clusters med et plot med kun to af variablerne). penguins_scaled &lt;- penguins %&gt;% select(where(is.numeric)) %&gt;% scale kclust &lt;- kmeans(penguins_scaled,centers = 3) kclust %&gt;% augment(pca_fit_augment) %&gt;% ggplot(aes(x=.fittedPC1, y=.fittedPC2, color = .cluster)) + geom_point() + theme_bw() Output med tidy Næste kigger vi på variansen i datasættet som er blevet fanget af hver af de forskellige components. Man kan udtrække oplysningerne ved at benytte funktionen tidy() fra pakken broom, og ved at angiv matrix = \"eigenvalues\" indenfor tidy. Det kaldes for “eigenvalues” fordi, hvis man kigger på matematikken bag principal component analysis, tager man udgangspunkt i en covariance matrix. En covariance matrix beskriver sammenhængen eller korrelationen mellem de forskellige variabler. Man bruger denne covariance matrix til at beregne de såkaldte eigenvalues og deres tilsvarende eigenvectors. Det er faktisk den største eigenvalue som fortæller os om den første principal component - det fortæller os hvor meget af variansen i datasættet den første principal component fanger - jo større det er relativ til de andre eigenvalues, jo mere variansen man forklarer med den første principal component. Og den næste største fortæller os om den anden prinical component og så videre. pca_fit_tidy &lt;- pca_fit %&gt;% tidy(matrix = &quot;eigenvalues&quot;) pca_fit_tidy ## # A tibble: 4 × 4 ## PC std.dev percent cumulative ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1.66 0.686 0.686 ## 2 2 0.882 0.195 0.881 ## 3 3 0.607 0.0922 0.973 ## 4 4 0.328 0.0270 1 Lad os visualisere de tal her i procenttal, med at specificere labels = scales::percent_format() indenfor scale_y_continuous - så vi bare ændre på de tal som kan ses på y-aksen. pca_fit_tidy %&gt;% ggplot(aes(x = PC, y = percent)) + geom_bar(stat=&quot;identity&quot;, fill=&quot;steelblue&quot;) + scale_y_continuous( labels = scales::percent_format(), #convert labels to percent format ) + theme_minimal() På den ene side hvis der er meget variance som er forklaret af de første components tilsammen, betyder det at der er en del redundans i datasættet, på grund af, at mange af de variabler har en tæt sammenhæng med hinanden. På den anden side hvis der er en meget lille andel af variancen som er forklaret af de første components tilsammen, betyder det at det er svært at beskrive datasættet i mindre dimensioner (fordi der næsten er ingen sammenhæng mellem variablerne) - i dette tilfælde, hvor datasættet er mere kompleks, er PCA mindre effektiv. 10.4.1 Rotation matrix for at udtrækker bidragen af de forskellige variabler De eigenvalues kan anvendes til at undersøge variancen i datasættet, men deres tilsvarende eigenvectors fortæller os om, hvordan de forskellige variabler er kombineret til at få de endelige principal component værdier, som vi bruger fk. i et scatter plot. De eigenvectors bruges til at lave et matrix som hedder ‘rotation matrix.’ Jeg anvender funktionen pivot_wider for at få vores matrix mere klart at se. Vi kan se at vi har variablerne her på rækkerne og de forskellige prinicpal components i kolonnerne. pca_fit_rotate &lt;- pca_fit %&gt;% tidy(matrix = &quot;rotation&quot;) %&gt;% pivot_wider(names_from = &quot;PC&quot;, names_prefix = &quot;PC&quot;, values_from = &quot;value&quot;) pca_fit_rotate ## # A tibble: 4 × 5 ## column PC1 PC2 PC3 PC4 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 bill_length_mm 0.454 -0.600 -0.642 0.145 ## 2 bill_depth_mm -0.399 -0.796 0.426 -0.160 ## 3 flipper_length_mm 0.577 -0.00579 0.236 -0.782 ## 4 body_mass_g 0.550 -0.0765 0.592 0.585 Den rotation matrix fortæller os hvordan man beregner værdierne af de principal components for alle observationer. For eksempel tager vi vores første observation, beregne 0.45 gange de bill length, og så minus 0.4 gang de bill depth, og så plus 0.58 x den flipper length og så plus 0.55 x body_mass. Og så har vi værdien for observationen langt den første princip komponent. Vi kan andvende den rotation matrix til at se hvordan de forskellige variabler relatere til hinhanden. Variablerne som er tæt på hinanden i plottet ligner hinanden. Vi kan se at flipper_length_mm og body_mass_g ligner hinhanen ret meget i vores datasæt, mens bill_depth_mm sidder over til venstre langt den første principal component, så det måske indeholder nogle oplysninger om pingvinerne, der ikke kunne fanges i de andre variabler. library(ggrepel) pca_fit_rotate %&gt;% ggplot(aes(x=PC1,y=PC2,colour=column)) + geom_point(size=3) + geom_text_repel(aes(label=column)) + theme_minimal() 10.4.2 Pakken factoextra R-pakken factoextra kan avendes til at lave et lignende plot fra de rotation matrix automatiske, og den arbejder ovenpå ggplot2 så man kan ændret temaet osv. Man kan se hvordan de fungere i følgende kode. Man få det varians procenttal på akserne. Lokationer af pilehovederne er fra den rotation matrix. Jo mindre vinklen mellem to linjer er, og tættere på de er til hinanden Jo nærmere til den cirkle pilehoveredne er, jo mere indflydelse den variable har i de principal components. library(factoextra) fviz_pca_var(pca_fit, col.var=&quot;steelblue&quot;,repel = TRUE)+ theme_minimal() 10.5 Problemstillinger Problem 1) Quiz på Absalon Download følgende datasæt ved at køre følgende kode chunk: cancer &lt;- read.csv(url(&quot;https://www.dropbox.com/s/4qa37itw9wtwtjg/breast-cancer.csv?dl=1&quot;)) %&gt;% as_tibble() %&gt;% select(-id) cancer %&gt;% glimpse() ## Rows: 569 ## Columns: 31 ## $ diagnosis &lt;chr&gt; &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;M&quot;, &quot;… ## $ radius_mean &lt;dbl&gt; 17.990, 20.570, 19.690, 11.420, 20.290, 12.450… ## $ texture_mean &lt;dbl&gt; 10.38, 17.77, 21.25, 20.38, 14.34, 15.70, 19.9… ## $ perimeter_mean &lt;dbl&gt; 122.80, 132.90, 130.00, 77.58, 135.10, 82.57, … ## $ area_mean &lt;dbl&gt; 1001.0, 1326.0, 1203.0, 386.1, 1297.0, 477.1, … ## $ smoothness_mean &lt;dbl&gt; 0.11840, 0.08474, 0.10960, 0.14250, 0.10030, 0… ## $ compactness_mean &lt;dbl&gt; 0.27760, 0.07864, 0.15990, 0.28390, 0.13280, 0… ## $ concavity_mean &lt;dbl&gt; 0.30010, 0.08690, 0.19740, 0.24140, 0.19800, 0… ## $ concave.points_mean &lt;dbl&gt; 0.14710, 0.07017, 0.12790, 0.10520, 0.10430, 0… ## $ symmetry_mean &lt;dbl&gt; 0.2419, 0.1812, 0.2069, 0.2597, 0.1809, 0.2087… ## $ fractal_dimension_mean &lt;dbl&gt; 0.07871, 0.05667, 0.05999, 0.09744, 0.05883, 0… ## $ radius_se &lt;dbl&gt; 1.0950, 0.5435, 0.7456, 0.4956, 0.7572, 0.3345… ## $ texture_se &lt;dbl&gt; 0.9053, 0.7339, 0.7869, 1.1560, 0.7813, 0.8902… ## $ perimeter_se &lt;dbl&gt; 8.589, 3.398, 4.585, 3.445, 5.438, 2.217, 3.18… ## $ area_se &lt;dbl&gt; 153.40, 74.08, 94.03, 27.23, 94.44, 27.19, 53.… ## $ smoothness_se &lt;dbl&gt; 0.006399, 0.005225, 0.006150, 0.009110, 0.0114… ## $ compactness_se &lt;dbl&gt; 0.049040, 0.013080, 0.040060, 0.074580, 0.0246… ## $ concavity_se &lt;dbl&gt; 0.05373, 0.01860, 0.03832, 0.05661, 0.05688, 0… ## $ concave.points_se &lt;dbl&gt; 0.015870, 0.013400, 0.020580, 0.018670, 0.0188… ## $ symmetry_se &lt;dbl&gt; 0.03003, 0.01389, 0.02250, 0.05963, 0.01756, 0… ## $ fractal_dimension_se &lt;dbl&gt; 0.006193, 0.003532, 0.004571, 0.009208, 0.0051… ## $ radius_worst &lt;dbl&gt; 25.38, 24.99, 23.57, 14.91, 22.54, 15.47, 22.8… ## $ texture_worst &lt;dbl&gt; 17.33, 23.41, 25.53, 26.50, 16.67, 23.75, 27.6… ## $ perimeter_worst &lt;dbl&gt; 184.60, 158.80, 152.50, 98.87, 152.20, 103.40,… ## $ area_worst &lt;dbl&gt; 2019.0, 1956.0, 1709.0, 567.7, 1575.0, 741.6, … ## $ smoothness_worst &lt;dbl&gt; 0.1622, 0.1238, 0.1444, 0.2098, 0.1374, 0.1791… ## $ compactness_worst &lt;dbl&gt; 0.6656, 0.1866, 0.4245, 0.8663, 0.2050, 0.5249… ## $ concavity_worst &lt;dbl&gt; 0.71190, 0.24160, 0.45040, 0.68690, 0.40000, 0… ## $ concave.points_worst &lt;dbl&gt; 0.26540, 0.18600, 0.24300, 0.25750, 0.16250, 0… ## $ symmetry_worst &lt;dbl&gt; 0.4601, 0.2750, 0.3613, 0.6638, 0.2364, 0.3985… ## $ fractal_dimension_worst &lt;dbl&gt; 0.11890, 0.08902, 0.08758, 0.17300, 0.07678, 0… Problem 2) Anvend funktionen ggscatmat fra pakken GGally til at lave et plot hvor man sammenligne fem af de variabler. Man kan lave en tilfældig sample af fem variabler med at angive columns = sample(2:31,5) indenfor funktionen ggscatmat(husk at installere GGally-pakken). Give farver efter factor variablen diagnosis og vælger “pearson” som corMethod. Opfatter du, at der er en del redundans i datasættet (dvs. er der stærke korrelationer mellem de forskellige variabler)? Problem 3) Benyt funktionen prcomp til at beregne en principal component analysis af datasættet. Husk at det skal kun være numeriske variabler og angiv scale=TRUE indenfor selve funktion. Lav et summary af resultaterne. Hvad er proportionen af variansen, som er forklaret af den første principal component? Hvad er proportionen af variansen, som er forklaret af de første to principal components tilsammen? Problem 4) Augment og plot Anvend augment til at tilføje dit rå datasæt til ovenstående resultater fra prcomp. Brug den til at lave et scatter plot af de første to principal components Giv farver efter diagnosis Skriv kort om man kan skelne imellem “M” og “B” fra variablen diagnosis ud fra de første to principal components. Problem 5) Integrere kmeans clustering. Lav et clustering med kmeans på datasættet, med to clusters (husk at udvælge numeriske variabler og scale inden du anvender funktionen kmeans). Augment resultaterne af kmeans til dit datasæt, der allerede har prcomp resultater tilføjet. Lav et plot og give farver efter .cluster og former efter diagnosis. Sammenligne dine to clusters med diagnosis. Problem 6) tidy form og variansen Anvende tidy(matrix = \"eigenvalues\") på din PCA resultater til at få bidragen af de forskellige components til den overordnet varianse i datasættet. Lav et barplot som viser de components på x-aksen og percent på y-aksen. Problem 7) tidy form og rotation matrix Anvende tidy(matrix = \"rotation\") til at få den rotation matrix. Anvend funktionen pivot_wider til at få den til wide form Lav et scatter plot som viser de forskellige variabler relativ til hinanden Anvend geom_text_repel til at give labels til de variabler (kan være en god idé at anvend show.legend=F) Problem 8) Ekstra Udvidelse af Problem 5): Fra din augmented resultater med både dine principal components og clusters: Beregne middelværdierne af din første to principal components for hver af de to clusters. Tilføj dine beregnede middelværdierne til plottet som “x.” 10.6 Ekstra læsning Step by step explanation: https://builtin.com/data-science/step-step-explanation-principal-component-analysis PCA tidyverse style fra claus wilke: https://clauswilke.com/blog/2020/09/07/pca-tidyverse-style/ More PCA in tidyverse framework: https://tbradley1013.github.io/2018/02/01/pca-in-a-tidy-verse-framework/ "],["emner-fra-eksperimental-design.html", "Chapter 11 Emner fra eksperimental design 11.1 Inledning og læringsmålene 11.2 Grundlæggende principper i eksperimental design 11.3 Case studies: Simpson’s paradox 11.4 Case studies: Anscombe’s quartet 11.5 Undersøgelse af “batch-effects” 11.6 Problemstillinger 11.7 Yderligere læsning", " Chapter 11 Emner fra eksperimental design library(tidyverse) library(broom) “Amatører sidder og venter på inspiration, resten af os står bare op og går på arbejde.” - Stephen King 11.1 Inledning og læringsmålene 11.1.1 Læringsmålene I skal være i stand til at Beskrive randomimisation, replication and blocking Beskrive Simpson’s paradox Beskrive Anscombes quartet Tjekke efter batch effects med PCA 11.1.2 Inledning til chapter Formålet med dette kapitel er at spørge: hvordan kan vi anvende værktøjerne som vi har lært i kurset til at kigge nærmere på forskellige emner i eksperimental design? Det er slet ikke en grundig introduktion til eksperimental design, men nogle nyttige og også interesseret emner som godt viser hvorfor det er vigtigt at lave hensigtsmæssige visualiseringer af dit data. Forståelsen af hvordan batch effekts påvirker en analyse er særlig vigtig indenfor biologi-fag, hvor mange store sekvensering projektor involverer data samlede eller sekvenseret over forskellige batches, sekvensering maskiner eller forskellige forberedelsesmetoder. 11.1.3 Video ressourcer Part 1: randomisation, replikation, blocking + confounding Ingen video: læs gerne notaterne nedenfor Part 2: Simpson’s paradox Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556581563 Part 3: Anscombe’s quartet Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556581540 Part 4: Batch effects and principal component analysis. OBS Man kan selvfølgelige også anvende map_if() til at log-transformere. Link her hvis det ikke virker nedenunder: https://player.vimeo.com/video/556581521 11.2 Grundlæggende principper i eksperimental design 11.2.1 Randomisation and replication Man laver et eksperiment for at få svar på et bestemt spørgsmål, eller hypotese. Og man designer eksperimentet ud fra principper som gøre det gyldigt at fortolke resultaterne fra analysen af datasættet bagefter. For et eksperiment at være gyldigt skal det kunne demonstrere hensigtsmæssige replikation og randomisation. Randomisation Man vil gerne udelukke, at konklusionerne kan bare skyldes variansen pga. en faktor som ikke direkte er interessant i eksperimentet. Derfor bruger man randomisation til at få disse faktorer fordelte over de forskellige treatment grupper. Et eksempel kan være ‘double-blinding’ i kliniske eksperimenter - både lægen og patienten har ikke kenskab til, hvem der hører til de forskellige grupper, og så kan man undgår forskelsbehandling indenfor grupperne, som kan påvirker de endelige resultater. Replikation Når man gentager et eksperiment flere gange - for eksempel ved at have flere patienter i hver treatment gruppe. Det tillader os at kunne beregne variabiliteten i data, som er nødvendig for at konkludere om der er en forskel mellem de grupper. Man kan altså ikke generalisere resultater som er blevet målt på kun én person. Figure 11.1: randomisation og replikation I ovenstående figur er der 6 replikater i hver gruppe, som er enten “treatment” eller “control.” I tilfældet “Good randomisation” er genstande som er taget tilfældige fra populationen vel matchet mellem de to grupper, mens i andet tilfældet “Poor randomisatin,” kan man se, at farverne af genstandene er vel matchet indenfor samme grupper. Det gøre det derfor umuligt at fortæl, om en eventuelle forskel mellem “treatment” og “control” er i virkeligheden resultatet af farven i stedet for målingerne, at man gerne vil sammenligne. Confounding Figuren nedenfor illustratorer age som counfounding variabel i et eksperiment hvor man prøver at forstå sammenhæng mellem aktivitet niveau og vægtøgning. Det kan være, at det ser umiddelbart ud til at være, at et lavt aktivitetsniveau (afhængig variabel) forklarer vægtøgning (unaghængig variabel), men man er nødt til at tage ændre variabler i betragtning for at sikre, at sammenhængen ikke skyldes noget andet. For eksempel, gruppen med det højt aktivitetsniveau kunne bestå af personer, der er yngre end personerne i gruppen med det lavt aktivitetsniveau, og deres alder kan påvirke deres vægtøgning (måske på grund af forskelligeheder i stress niveauer, kost osv.). Blocking Man kan prøve at kontrollere for ekstra variabler som vi ikke er interesseret i gennem “blocking.” Man laver “blocking” ved først at identificere grupper af individuelle som ligner hinanden så meget som muligt. Det kan være for eksempel at tre forskellige forsker var med til at lave et stort eksperiment med mange patienter og forskellige treatment grupper. Vi er interesseret i om der er forskellen mellem de treatment grupper, men ikke om der er en forskel mellem forskernes behandling af patienterne. Derfor vil vi gerne ‘block’ efter forsker - kontrollere for dem som en “batch” effect. Man kan også block efter fk. sex, for at sikre at forskellen i treatment grupper skyldes ikke forskelligheder mellem mænd og kvinder. Man laver “blocking” som del af en lineær model efter data er samlet, men det er nyttige at tænke over det fra starten. 11.2.2 Eksempel med datasættet ToothGrowth Et god eksempel på et godt eksperimental design er datasættet ToothGrowth, som er baserende på marsvin - de fik forskellige kosttilskud og doser og så fik de målte længden af deres tænder. data(ToothGrowth) ToothGrowth &lt;- ToothGrowth %&gt;% as_tibble() %&gt;% mutate(dose = as.factor(dose)) summary(ToothGrowth) ## len supp dose ## Min. : 4.20 OJ:30 0.5:20 ## 1st Qu.:13.07 VC:30 1 :20 ## Median :19.25 2 :20 ## Mean :18.81 ## 3rd Qu.:25.27 ## Max. :33.90 Her kan man se, at for hver gruppe (efter supp og dose) er der 10 marsvin - vi har således replikation over de grupper, og hver supp (supplement) har hver af de tre mulige værdier for “dose.” Hvis vi for eksempel ikke var interesseret i supp men kun dose, så kan man ‘block’ efter supp for at afbøde forskelligheder i effekten af de to supplements i supp. ToothGrowth %&gt;% dplyr::count(supp,dose) %&gt;% ggplot(aes(x=factor(dose),y=n,fill=factor(dose))) + geom_bar(stat=&quot;identity&quot;) + ylab(&quot;Number of guinea pigs&quot;) + xlab(&quot;Dosage&quot;) + facet_grid(~supp) + theme_bw() Man må dog passe på, fordi vi vide ikke om, hvordan de marsvin blev tilknyttet til de forskellige grupper. For eksempel, hvis male og female marsvin er ikke tilknyttet ved tilfælde, kan det opstå, at supp “OJ” og dose “0.5” har kun male guinea pigs og supp “OJ” med dose “1.0” har kun female guninea pigs. Så kunne vi ikke fortæl, om forskellen i dose “0.5” vs “1.0” er resultatet af de dose eller kønnet. 11.3 Case studies: Simpson’s paradox (Se også videoressourcer Part 2). Simpson’s paradox opstår når man drager to modsætte konklusioner fra det samme datasæt - på den ene side når man kigger på de data samlede, og på den anden side når man tager nogle grupper i betragtning. Vi kan visualisere Simpson’s paradox gennem eksemplet nedenfor - her har vi to variabler x og y som vi kan avende til at lave et scatter plot, samt nogle forskellige grupper indenfor variablen group. #library(datasauRus) simpsons_paradox &lt;- read.table(&quot;https://www.dropbox.com/s/ysh3qpc7qv0ceut/simpsons_paradox_groups.txt?dl=1&quot;,header=T) simpsons_paradox &lt;- simpsons_paradox %&gt;% as_tibble(simpsons_paradox) simpsons_paradox FALSE # A tibble: 222 × 3 FALSE x y group FALSE &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; FALSE 1 62.2 70.6 D FALSE 2 52.3 14.7 B FALSE 3 56.4 46.4 C FALSE 4 66.8 66.2 D FALSE 5 66.5 89.2 E FALSE 6 62.4 91.5 E FALSE 7 38.9 6.76 A FALSE 8 39.4 63.1 C FALSE 9 60.9 92.6 E FALSE 10 56.6 45.8 C FALSE # … with 212 more rows Hvis vi bare ignorere group og ser på de data samlet, kan vi se at der er en stærk positiv sammenhæng mellem x og y. Men når vi opdele efter de forskellige grupper, ved at skrive colour = group, få vi faktisk en negativ sammenhæng indenfor hver af de grupper. p1 &lt;- simpsons_paradox %&gt;% ggplot(aes(x,y)) + geom_point() + geom_smooth(method=&quot;lm&quot;,se=FALSE) + theme_classic() p2 &lt;- simpsons_paradox %&gt;% ggplot(aes(x,y,colour=group)) + geom_point() + geom_smooth(method=&quot;lm&quot;,aes(group=group),colour=&quot;black&quot;,se=FALSE) + theme_classic() library(gridExtra) grid.arrange(p1,p2,ncol=2) Simpson’s paradoks sker mere ofte end man skulle tror, og derfor er det vigtigt at tænke over hvad for nogen ændre variabler man også er nødt til at tage i betragtning. 11.3.1 Berkerly admissions Det meste berømte eksempel af Simpson’s Paradox drejer sig om optagelsen til universitetet i Berkely i 1973. Følgende table fra Wikipedia (https://en.wikipedia.org/wiki/Simpson%27s_paradox) viser statistikker om antallet som ansøgt samt procenttallet som blev optaget overordnet i universitet efter kønnet. Figure 11.2: source: wikipedia Hvis vi lave et barplot af tallerne, kan man se, at der er en højere procenttal af mænd end kvinder som var blevet optaget på universitet (sagen medførte en retsag mod universitet). admissions_all &lt;- tibble(&quot;sex&quot;=c(&quot;all&quot;,&quot;men&quot;,&quot;woman&quot;),admitted=c(&quot;41&quot;,&quot;44&quot;,&quot;35&quot;)) admissions_all %&gt;% ggplot(aes(x=sex,y=admitted,fill=sex)) + geom_bar(stat=&quot;identity&quot;) + theme_minimal() + ylab(&quot;Percent admitted&quot;) + scale_x_discrete(limits = c(&quot;woman&quot;,&quot;men&quot;,&quot;all&quot;)) + coord_flip() Da man dog kiggede lidt nærmere på de samme tal, men opdelte efter de forskellige afdelinger i universitet, fik man en anderledes billede af situationen. I følgende tabel har vi optagelsestallene for mænd og kvinder i hver af de forskellige afdelinger (A til F). admissions_separate &lt;- tribble( ~department, ~all, ~men, ~women, #------------|-------|-------|--------# &quot;A&quot;, 64, 62, 82, &quot;B&quot;, 63, 63, 68, &quot;C&quot;, 35, 37, 34, &quot;D&quot;, 34, 33, 35, &quot;E&quot;, 25, 28, 24, &quot;F&quot;, 6, 6, 7 ) Man kan man se, at for de fleste af afdelingerne, er der ikke en signifikant forskel mellem mænd og kvinder, og i nogle tilfælde havde kvinder faktisk en større chance for at blive optaget. admissions_separate %&gt;% pivot_longer(-department,names_to=&quot;sex&quot;,values_to=&quot;admitted&quot;) %&gt;% ggplot(aes(x=department,y=admitted,fill=sex)) + ylab(&quot;Percent admitted&quot;) + geom_bar(stat=&quot;identity&quot;,position = &quot;dodge&quot;,colour=&quot;black&quot;) + theme_minimal() Hvad skyldes sammenhængen? Det viste sig, at kvinder havde en tendens til, at ansøge indenfor afdelingerne, som var sværeste at komme ind i. For eksempel, kan man se her, at department E har en relativt lav optagelses procent. Den samme afdeling var dog en af dem, hvor langt flere kvinder ansøgt end mænd. applications_E &lt;- tibble(&quot;sex&quot;=c(&quot;all&quot;,&quot;men&quot;,&quot;woman&quot;),applications=c(&quot;584&quot;,&quot;191&quot;,&quot;393&quot;)) applications_E %&gt;% ggplot(aes(x=sex,y=applications,fill=sex)) + geom_bar(stat=&quot;identity&quot;) + theme_minimal() + ylab(&quot;Number of applications to dep. E&quot;) + scale_x_discrete(limits = c(&quot;woman&quot;,&quot;men&quot;,&quot;all&quot;)) + coord_flip() Derfor, selvom kvinder ikke havde en lavere sandsynlighed af at blive optaget end mænd i deres fortrukne fag, var antallet af kvinder der blev optaget i helhed over alle afdelinger faktisk lavere end antallet af mænd. 11.4 Case studies: Anscombe’s quartet (Se også videoressourcer Part 3). Anscombes quartet (se også https://en.wikipedia.org/wiki/Anscombe%27s_quartet) er et meget nyttigt og berømt eksempel, som stammer fra 1973, og som forklarer vigtigheden af at få lavet en visualisering af datasættet. Vi kan få åbnet de data fra linket nedenfor - man har x værdier og y værdier som kan anvendes til at lave et scatter plot, og der er også set, det refererer til fire forskellige datasæt (derfor ‘quartet’). anscombe &lt;- read.table(&quot;https://www.dropbox.com/s/mlt7crdik3eih9a/anscombe_long_format.txt?dl=1&quot;,header=T) anscombe &lt;- as_tibble(anscombe) anscombe ## # A tibble: 44 × 3 ## set x y ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; ## 1 1 10 8.04 ## 2 1 8 6.95 ## 3 1 13 7.58 ## 4 1 9 8.81 ## 5 1 11 8.33 ## 6 1 14 9.96 ## 7 1 6 7.24 ## 8 1 4 4.26 ## 9 1 12 10.8 ## 10 1 7 4.82 ## # … with 34 more rows Formålet med datasættet er, at man gerne vil fitte en lineær regression model for at finde den forventet y afhængig om x (husk lm(y ~ x)). Da vi har fire datasæt, kan man således opdele datasættet efter set og benytter rammen nest og map (se Chapter 7) til at fitte de fire lineær regression modeller. Vi anvender også tidy og glance for at få summary statistikker fra de fire modeller: my_func &lt;- ~lm(y ~ x, data = .x) tidy_anscombe_models &lt;- anscombe %&gt;% group_nest(set) %&gt;% mutate(fit = map(data, my_func), tidy = map(fit, tidy), glance = map(fit, glance)) Man kan anvende unnest på den output fra tidy og kigge på den intercept og den slope af de fire modeller. Man kan se, at de to parametre er næsten identiske for de fire modeller: tidy_anscombe_models %&gt;% unnest(&quot;tidy&quot;) %&gt;% pivot_wider(id_cols = &quot;set&quot;,names_from = &quot;term&quot;,values_from=&quot;estimate&quot;) ## # A tibble: 4 × 3 ## set `(Intercept)` x ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 3.00 0.500 ## 2 2 3.00 0.5 ## 3 3 3.00 0.500 ## 4 4 3.00 0.500 Hvad med de andre parametre fra modellen - lad os kigge for eksempel på r.squared og p.value fra modellerne, som kan findes i output fra glance. Her kan vi igen se, at de er næsten identiske. tidy_anscombe_models %&gt;% unnest(cols = c(glance)) %&gt;% select(set, r.squared,p.value) ## # A tibble: 4 × 3 ## set r.squared p.value ## &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 0.667 0.00217 ## 2 2 0.666 0.00218 ## 3 3 0.666 0.00218 ## 4 4 0.667 0.00216 Hvad med korrelation? Også næsten den samme: my_func &lt;- ~cor(.x$x,.x$y) anscombe %&gt;% group_nest(set) %&gt;% mutate(cor = map(data, my_func)) %&gt;% unnest(cor) %&gt;% select(-data) ## # A tibble: 4 × 2 ## set cor ## &lt;int&gt; &lt;dbl&gt; ## 1 1 0.816 ## 2 2 0.816 ## 3 3 0.816 ## 4 4 0.817 Kan man så konkludere, at de fire datasæt som underligger de forskellige modeller, er identiske? Vi laver et scatter plot af de fire datasæt (som vi faktisk skulle have gjort i starten af vores analyse). anscombe %&gt;% ggplot(aes(x = x, y = y,colour=factor(set))) + geom_point() + facet_wrap(~set) + geom_smooth(method = &quot;lm&quot;, se = FALSE) + theme_minimal() De fire datasæt er meget forskellige. Vi ved, at de har alle samme de samme beste rette linjer, men underliggende data er slet ikke de samme. Den første datasæt ser egnet til en lineær regression analyse men vi kan se i datasæt nummer to, at der ikke engang er en linæer sammenhæng. Og de andre to har outlier værdier, som gør, at den bedste rette linje passer ikke særlig god til punkterne. 11.5 Undersøgelse af “batch-effects” (Se også videoressourcer Part 4). Man kan også anvende visualiseringer til at kigge lidt nærmere på eventuelle batch effekter eller confounding variabler i datasættet. Det er især vigtigt i store eksperimenter, hvor forskellige samples eller dele af datasættet bliver samlede på forskellige tidspunkter, lokationer, eller af forskellige personer. Det er ofte tilfældet i sekvensering-basarede datasæt, at man ser batch effects, og det kan skyldes mange ting, bla.: Sekvensering dybelse Grupper samples lavet på forskellige tidspunkter af forskellige indivduelle Sekvensering maskiner - samples sekvenserne på forskellige maskiner eller ‘lanes.’ Lad os tage udgangspunkt i nogle genekspression sekvensering data lavet i mus (vi så også samme datasæt når vi lært pivot_longer kombineret med left_join). norm.cts &lt;- read.table(&quot;https://www.dropbox.com/s/3vhwnsnhzsy35nd/bottomly_count_table_normalised.txt?dl=1&quot;) coldata &lt;- read.table(&quot;https://www.dropbox.com/s/el3sm9ncvzbq6xf/bottomly_phenodata.txt?dl=1&quot;) coldata &lt;- as_tibble(coldata) norm.cts &lt;- as_tibble(norm.cts,rownames=&quot;gene&quot;) coldata &lt;- as_tibble(coldata) Jeg begynder ved at vælge kun rækker som har mindst 50 counts, for at undgå gener med lave ekspressionsniveauer. Det næste jeg gør er at transformere de data til log form (funktion map_if()) for at opnå en bedre fordeling i datasættet. #normalise and filter the data norm.cts &lt;- norm.cts %&gt;% filter(rowSums(norm.cts %&gt;% select(-gene))&gt;50) %&gt;% map_if(is.numeric,~log(.x+1)) %&gt;% as_tibble() norm.cts ## # A tibble: 10,193 × 22 ## gene SRX033480 SRX033488 SRX033481 SRX033489 SRX033482 SRX033490 SRX033483 ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ENSMUS… 6.35 6.32 6.21 6.29 6.31 6.27 6.30 ## 2 ENSMUS… 3.51 3.56 3.57 3.27 2.99 3.61 3.56 ## 3 ENSMUS… 3.19 3.50 3.08 3.21 3.14 3.09 3.22 ## 4 ENSMUS… 6.69 6.48 6.38 6.35 6.39 6.34 6.50 ## 5 ENSMUS… 6.05 6.37 6.17 6.26 6.16 6.06 6.13 ## 6 ENSMUS… 2.89 2.94 3.16 3.21 3.77 3.30 3.11 ## 7 ENSMUS… 3.42 3.12 3.86 4.36 3.77 3.99 4.24 ## 8 ENSMUS… 3.42 2.94 3.52 3.41 3.57 3.60 2.99 ## 9 ENSMUS… 5.02 4.98 4.49 4.27 4.67 4.35 4.81 ## 10 ENSMUS… 5.13 4.88 4.97 4.76 4.82 4.79 4.96 ## # … with 10,183 more rows, and 14 more variables: SRX033476 &lt;dbl&gt;, ## # SRX033478 &lt;dbl&gt;, SRX033479 &lt;dbl&gt;, SRX033472 &lt;dbl&gt;, SRX033473 &lt;dbl&gt;, ## # SRX033474 &lt;dbl&gt;, SRX033475 &lt;dbl&gt;, SRX033491 &lt;dbl&gt;, SRX033484 &lt;dbl&gt;, ## # SRX033492 &lt;dbl&gt;, SRX033485 &lt;dbl&gt;, SRX033493 &lt;dbl&gt;, SRX033486 &lt;dbl&gt;, ## # SRX033494 &lt;dbl&gt; Så der er omkring 10,000 genes i rækkerne og så 21 forskellige samples som spreder sig over kolonnerne. Vi har også nogle sample oplysninger - der er to foskellige strains af mus og også forskellige batches, som vi gerne vil kigge nærme på. coldata ## # A tibble: 21 × 5 ## column num.tech.reps strain batch lane.number ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; ## 1 SRX033480 1 C57BL.6J 6 1 ## 2 SRX033488 1 C57BL.6J 7 1 ## 3 SRX033481 1 C57BL.6J 6 2 ## 4 SRX033489 1 C57BL.6J 7 2 ## 5 SRX033482 1 C57BL.6J 6 3 ## 6 SRX033490 1 C57BL.6J 7 3 ## 7 SRX033483 1 C57BL.6J 6 5 ## 8 SRX033476 1 C57BL.6J 4 6 ## 9 SRX033478 1 C57BL.6J 4 7 ## 10 SRX033479 1 C57BL.6J 4 8 ## # … with 11 more rows Vi kan kigger på hvor mange samples efter hver kombination af stain og batch vi har i datasættet: table(coldata$strain, coldata$batch) ## ## 4 6 7 ## C57BL.6J 3 4 3 ## DBA.2J 4 3 4 Så kan man se, at både strain har repræsenteret tre eller fire samples i hver af de tre batches. Der er derfor replication og da vi har fået repræsenteret hver kombination af strain og batch, kan man eventuelle block efter batch for at få fjernet dens effekt. Her har vi ikke tid til at kigge på metoder for at fjerne batch-effekts, men det er vigtigt at vi er i stand til at opdage dem. 11.5.1 Principal component tilgang Man kan undersøge mulige batch effekter via prinicpal component analysis. pca_fit &lt;- norm.cts %&gt;% select(where(is.numeric)) %&gt;% # retain only numeric columns prcomp(scale = TRUE) # do PCA on scaled data Husk at når man lave en principal compononent analysis, kan man får den rotation matrix, der anvendes til at se hvor de forskellige samples ligger relative til hinanden over de forskellige principal components - dvs. at samples der ligner hinanden vises på samme sted på plottet. Den rotation matrix udtrækkes med funktionen tidy(): rot_matrix &lt;- pca_fit %&gt;% tidy(matrix = &quot;rotation&quot;) Vi vil gerne lave et plot af de rotation matrix, men første vil vi gerne tilføje de sample oplysninger med left_join, så at vi kan se de forskellige batches eller strains. Både dataframes har en kolon som hedder column, der refereres til de sample navne, så jeg forbinde efter column her. rot_matrix &lt;- rot_matrix %&gt;% left_join(coldata,by=&quot;column&quot;) Anvende pivot_wider() til at få den i wide form, så vi kan plotte “PC1” og “PC2” i et scatter plot: rot_matrix_wide &lt;- rot_matrix %&gt;% pivot_wider(names_from = &quot;PC&quot;, names_prefix = &quot;PC&quot;, values_from = &quot;value&quot;) rot_matrix_wide ## # A tibble: 21 × 26 ## column num.tech.reps strain batch lane.number PC1 PC2 PC3 PC4 ## &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 SRX03… 1 C57BL… 6 1 -0.217 0.262 0.0200 -0.508 ## 2 SRX03… 1 C57BL… 7 1 -0.219 0.243 0.00586 0.166 ## 3 SRX03… 1 C57BL… 6 2 -0.217 0.303 0.0153 -0.237 ## 4 SRX03… 1 C57BL… 7 2 -0.219 0.246 0.00799 0.178 ## 5 SRX03… 1 C57BL… 6 3 -0.217 0.259 0.0974 -0.113 ## 6 SRX03… 1 C57BL… 7 3 -0.219 0.234 0.00385 0.209 ## 7 SRX03… 1 C57BL… 6 5 -0.218 0.237 0.0303 -0.179 ## 8 SRX03… 1 C57BL… 4 6 -0.217 0.00524 0.463 0.376 ## 9 SRX03… 1 C57BL… 4 7 -0.218 0.0901 0.305 0.0651 ## 10 SRX03… 1 C57BL… 4 8 -0.218 -0.110 0.434 -0.161 ## # … with 11 more rows, and 17 more variables: PC5 &lt;dbl&gt;, PC6 &lt;dbl&gt;, PC7 &lt;dbl&gt;, ## # PC8 &lt;dbl&gt;, PC9 &lt;dbl&gt;, PC10 &lt;dbl&gt;, PC11 &lt;dbl&gt;, PC12 &lt;dbl&gt;, PC13 &lt;dbl&gt;, ## # PC14 &lt;dbl&gt;, PC15 &lt;dbl&gt;, PC16 &lt;dbl&gt;, PC17 &lt;dbl&gt;, PC18 &lt;dbl&gt;, PC19 &lt;dbl&gt;, ## # PC20 &lt;dbl&gt;, PC21 &lt;dbl&gt; Jeg giver farver og former efter de tre batches. Man kan se, at jeg har fået alle samples fra batch nummer 2 på samme sted i plottet. rot_matrix_wide %&gt;% ggplot(aes(PC1,PC2,shape=factor(batch),colour=factor(batch))) + geom_point(size=3) + theme_minimal() Jeg kan også give farver efter strain, hvor man kan se at der nok er en forskellen mellem de to strains her. rot_matrix_wide %&gt;% ggplot(aes(PC1,PC2,shape=factor(strain),colour=factor(strain))) + geom_point(size=3) + theme_minimal() Man kan også se de data på en anden måde ved at lave boxplots for to første to principal comonponets opdelte efter batch. Vi få bekræftet vores observation at der er en stærk forskel mellem match 7 og de andre to batches langt den første principal component, og det er et problem som muligvis skal korrigeres før man laver yderligere analyser på de data. p1 &lt;- rot_matrix_wide %&gt;% ggplot(aes(x=factor(batch),y=PC1,fill=factor(batch))) + geom_boxplot(show.legend = F) + geom_jitter(show.legend = F) + theme_minimal() p2 &lt;- rot_matrix_wide %&gt;% ggplot(aes(x=factor(batch),y=PC2,fill=factor(batch))) + geom_boxplot(show.legend = F) + geom_jitter(show.legend = F) + theme_minimal() library(gridExtra) grid.arrange(p1,p2,ncol=2) 11.6 Problemstillinger Problem 1) Quiz på Absalon - experimental Problem 2) Eksperimental design Jeg laver et eksperiment hvor patienter få en af tre forskellige kosttilskud (Gruppe 1, 2 og 3). Der er 5 patienter i hver gruppe og jeg vil gerne se, om patienternes energi niveau i gennemsnit er forskellige mellem de tre grupper. Alderne af patienterne i hver af de tre grupper er: Gruppe 1: 18, 23, 31, 25, 19 Gruppe 2: 24, 29, 35, 21, 30 Gruppe 3: 43, 52, 33, 39, 40 Hvad er problemet her med det eksperimental design? Lav boxplots for at viser fordelingen af alderne for hver af de tre grupper. Hvis man finder en signifikant forskel mellem de tre kosttilskud, kan man stoler på resultaterne? Hvad andre variabler end alder kunne skyldes en eventuelle forskel mellem de tre kosttilskud, og som måske skulle tages i betragtning? Hvad kan man gøre med den ovenstående eksperiment design for at løse problemet? Problem 3) Simpson’s paradoks Lung Cap data revisited Indlæse LungCapData og tilføj kategorisk variabel Age.Group: LungCapData &lt;- read.csv(&quot;https://www.dropbox.com/s/ke27fs5d37ks1hm/LungCapData.csv?dl=1&quot;) LungCapData$Age.Group &lt;- cut(LungCapData$Age,breaks=c(1,13,15,17,19),right=FALSE,include.lowest = TRUE) levels(LungCapData$Age.Group) &lt;- c(&quot;&lt;13&quot;,&quot;13-14&quot;,&quot;15-16&quot;,&quot;17+&quot;) a) Lav boxplots med smoke på x-aksen og LungCap på y-aksen. + Notere hvilke gruppe har den højeste lungkapacitet. b) Lav samme plot men adskilte efter Age.Group og beskriv, hvordan det er et eksempel på Simpson’s Paradoks. c) Lav et boxplot med Age på y-aksen og Smoke på x-aksen for at støtte hvorfor man ser Simpson’s Paradoks i datasættet. Problem 4) Anscombes analyse Gentage Anscombes analyse med dinosaurus datasæt: library(datasauRus) data_dozen &lt;- datasauRus::datasaurus_dozen data_dozen FALSE # A tibble: 1,846 × 3 FALSE dataset x y FALSE &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; FALSE 1 dino 55.4 97.2 FALSE 2 dino 51.5 96.0 FALSE 3 dino 46.2 94.5 FALSE 4 dino 42.8 91.4 FALSE 5 dino 40.8 88.3 FALSE 6 dino 38.7 84.9 FALSE 7 dino 35.6 79.9 FALSE 8 dino 33.1 77.6 FALSE 9 dino 29.0 74.5 FALSE 10 dino 26.2 71.4 FALSE # … with 1,836 more rows a) Fit en lineær regression model for hver af de datasæt (anvende group_by, nest og map ramme med en custom funktion), hvor man har y som afhængig variabel og x som uafhængig variabel. Anvend også tidy og glance på samtlige modeller b) Anvend resultaterne fra tidy til at kigge på den slope og intercept for de forskellige modeller - ligner de hinhanden? c) Anvende også resultaterne fra glance til at kigge på r.squared og p.value. d) Er de alle det samme datasæt? Lav et scatter plot adskilte efter de forskellige datasæt. Hvordan ser de bedste rette linjer ud på plotterne? Problem 5) Vi vil gerne undersøge eventuelle batch effects i følgende datasæt. Det er simuleret “single cell” sekvensering count data (dataframen cse50) samt dataframen batches, som angiver hvilken batch hver af de 500 cells tilhører. cse50 &lt;- read.table(&quot;https://www.dropbox.com/s/o0wzojpcsekeg6z/cell_mix_50_counts.txt?dl=1&quot;) batches &lt;- read.table(&quot;https://www.dropbox.com/s/4t382bfgro46ka5/cell_mix_50_batches.txt?dl=1&quot;) batches &lt;- as_tibble(batches) cse50 &lt;- as_tibble(cse50) a) Anvend map_df til at få transformeret de data til log scale (plus 1 først og tag log bagefter). b) Lav PCA på det transformeret datasæt. c) Anvend din PCA resultater til at få den rotation matrix d) Forbinde oplysningerne fra dataframen batches til din rotation matrix (første tilføj en ny kolonne “column” til batches som er lig med names(cse50). e) Anvend pivot_wider og lav et plot af den første to principal components, hvor du angiver farve efter batch. f) Lav også boxplots for de første to prinpical components fordelt efter batch og kommenter kort på eventuelle batch effekts i de data. Problem 6 Mere Simpson’s Paradox Kør følgende kode til at indlæs og bearbejde følgende datasæt airlines. airlines &lt;- read.table(&quot;http://www.utsc.utoronto.ca/~butler/d29/airlines.txt&quot;,header=T) airlines &lt;- airlines %&gt;% pivot_longer(-airport) %&gt;% separate(name,sep=&quot;_&quot;,into = c(&quot;airline&quot;,&quot;status&quot;)) %&gt;% mutate(airline = recode(airline, aa = &quot;Alaska&quot;, aw = &quot;American&quot;)) %&gt;% pivot_wider(names_from=status,values_from=value) %&gt;% mutate(&quot;ontime&quot; = ontime + delayed) %&gt;% rename(flights = ontime) a) Opsummer antal flights og antal delayed over de forskellige airports for at få et samlet tal til hver airline. b) Beregn også proportionen af flights som er delayed i hver airline (igen samlede over alle airports). Lav et barplot til at vise proportionerne. c) Denne gange opsummer over de to airlines for at få et samlet tal til hvert airline. Beregen også proportionen af flights som er delayed og lave et plot. d) Denne gange beregne proportionen af flights som er delayed til hver kombination af både airport og airline. Igen omsæt til et plot. e) Kan du forklare? Hint: tag for eksempel en kig på de rå data og bla. airport “Phoenix.” 11.7 Yderligere læsning Simpson’s paradox og airlines: http://ritsokiguess.site/docs/2018/04/07/simpson-s-paradox-log-linear-modelling-and-the-tidyverse/ Batch effekt correction: https://en.wikipedia.org/wiki/Batch_effect#Correction "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
